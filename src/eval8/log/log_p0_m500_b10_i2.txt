
---------------------------------------------------------




Number of bags : 877    Number of single instances: 2499

2016-04-29 00:47:42




---------------------------------------------------------

sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.98      0.98       483
        1.0       0.31      0.24      0.27        17

avg / total       0.95      0.96      0.95       500

[[474   9]
 [ 13   4]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.97      0.95       500

[[483   0]
 [ 17   0]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.67      0.06      0.12        31

avg / total       0.92      0.94      0.92       499

[[467   1]
 [ 29   2]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       452
        1.0       0.00      0.00      0.00        48

avg / total       0.82      0.90      0.86       500

[[452   0]
 [ 48   0]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       447
        1.0       0.00      0.00      0.00        53

avg / total       0.80      0.89      0.84       500

[[447   0]
 [ 53   0]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       423
        1.0       0.00      0.00      0.00        77

avg / total       0.72      0.85      0.78       500

[[423   0]
 [ 77   0]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.98      0.92       423
        1.0       0.59      0.17      0.26        77

avg / total       0.82      0.85      0.82       500

[[414   9]
 [ 64  13]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.97       468
        1.0       0.40      0.13      0.20        31

avg / total       0.91      0.93      0.92       499

[[462   6]
 [ 27   4]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.86      0.92       483
        1.0       0.14      0.65      0.23        17

avg / total       0.96      0.85      0.90       500

[[416  67]
 [  6  11]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.94      0.93       447
        1.0       0.38      0.32      0.35        53

avg / total       0.86      0.87      0.87       500

[[419  28]
 [ 36  17]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.98      0.95       452
        1.0       0.44      0.15      0.22        48

avg / total       0.87      0.90      0.88       500

[[443   9]
 [ 41   7]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.66      0.75       423
        1.0       0.20      0.48      0.29        77

avg / total       0.77      0.63      0.68       500

[[278 145]
 [ 40  37]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.85      0.89       452
        1.0       0.23      0.42      0.29        48

avg / total       0.86      0.81      0.83       500

[[384  68]
 [ 28  20]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.62      0.76       447
        1.0       0.20      0.81      0.32        53

avg / total       0.88      0.64      0.71       500

[[278 169]
 [ 10  43]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.71      0.81       468
        1.0       0.11      0.55      0.18        31

avg / total       0.91      0.70      0.78       499

[[331 137]
 [ 14  17]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.97      0.95       500

[[483   0]
 [ 17   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       452
        1.0       0.00      0.00      0.00        48

avg / total       0.82      0.90      0.86       500

[[452   0]
 [ 48   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       423
        1.0       0.00      0.00      0.00        77

avg / total       0.72      0.85      0.78       500

[[423   0]
 [ 77   0]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.33      0.06      0.10        17

avg / total       0.95      0.96      0.95       500

[[481   2]
 [ 16   1]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       447
        1.0       0.00      0.00      0.00        53

avg / total       0.80      0.89      0.84       500

[[447   0]
 [ 53   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       1.00      0.03      0.06        31

avg / total       0.94      0.94      0.91       499

[[468   0]
 [ 30   1]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      1.00      0.95       452
        1.0       0.67      0.04      0.08        48

avg / total       0.88      0.91      0.87       500

[[451   1]
 [ 46   2]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.95      0.91       423
        1.0       0.45      0.25      0.32        77

avg / total       0.81      0.84      0.82       500

[[400  23]
 [ 58  19]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.90      0.92       447
        1.0       0.34      0.43      0.38        53

avg / total       0.87      0.85      0.86       500

[[403  44]
 [ 30  23]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.97      0.96       468
        1.0       0.24      0.16      0.19        31

avg / total       0.90      0.92      0.91       499

[[452  16]
 [ 26   5]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.97      0.95       500

[[483   0]
 [ 17   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      1.00      0.95       452
        1.0       0.67      0.04      0.08        48

avg / total       0.88      0.91      0.87       500

[[451   1]
 [ 46   2]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.85      0.91       483
        1.0       0.13      0.65      0.22        17

avg / total       0.96      0.85      0.89       500

[[412  71]
 [  6  11]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.99      0.92       423
        1.0       0.57      0.05      0.10        77

avg / total       0.81      0.85      0.79       500

[[420   3]
 [ 73   4]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       447
        1.0       0.00      0.00      0.00        53

avg / total       0.80      0.89      0.84       500

[[447   0]
 [ 53   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.71      0.79       423
        1.0       0.24      0.51      0.33        77

avg / total       0.79      0.68      0.72       500

[[300 123]
 [ 38  39]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.86      0.89       452
        1.0       0.20      0.33      0.25        48

avg / total       0.85      0.81      0.83       500

[[387  65]
 [ 32  16]]
sbMIL(C=256.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.90      0.94       483
        1.0       0.14      0.47      0.21        17

avg / total       0.95      0.88      0.91       500

[[433  50]
 [  9   8]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.73      0.83       468
        1.0       0.10      0.45      0.16        31

avg / total       0.90      0.72      0.79       499

[[343 125]
 [ 17  14]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.65      0.78       447
        1.0       0.21      0.77      0.33        53

avg / total       0.88      0.66      0.73       500

[[291 156]
 [ 12  41]]
sbMIL(C=256.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.70      0.78       423
        1.0       0.23      0.49      0.31        77

avg / total       0.78      0.66      0.71       500

[[294 129]
 [ 39  38]]
sbMIL(C=256.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.87      0.90       452
        1.0       0.25      0.40      0.30        48

avg / total       0.87      0.83      0.84       500

[[394  58]
 [ 29  19]]
sbMIL(C=256.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.77      0.85       468
        1.0       0.13      0.52      0.21        31

avg / total       0.91      0.75      0.81       499

[[360 108]
 [ 15  16]]
sbMIL(C=256.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.68      0.80       447
        1.0       0.21      0.72      0.33        53

avg / total       0.87      0.69      0.75       500

[[306 141]
 [ 15  38]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.85      0.91       483
        1.0       0.12      0.59      0.20        17

avg / total       0.95      0.84      0.89       500

[[412  71]
 [  7  10]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.67      0.76       423
        1.0       0.20      0.47      0.28        77

avg / total       0.77      0.64      0.68       500

[[283 140]
 [ 41  36]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.85      0.89       452
        1.0       0.22      0.40      0.28        48

avg / total       0.86      0.81      0.83       500

[[384  68]
 [ 29  19]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.62      0.76       447
        1.0       0.20      0.79      0.32        53

avg / total       0.88      0.64      0.71       500

[[279 168]
 [ 11  42]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.70      0.81       468
        1.0       0.11      0.55      0.18        31

avg / total       0.91      0.69      0.77       499

[[329 139]
 [ 14  17]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       483
        1.0       0.13      0.53      0.20        17

avg / total       0.95      0.86      0.90       500

[[421  62]
 [  8   9]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.46      0.62       423
        1.0       0.21      0.81      0.34        77

avg / total       0.82      0.52      0.58       500

[[196 227]
 [ 15  62]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.79      0.87       452
        1.0       0.26      0.69      0.38        48

avg / total       0.89      0.78      0.82       500

[[358  94]
 [ 15  33]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.51      0.68       468
        1.0       0.11      0.87      0.19        31

avg / total       0.93      0.54      0.65       499

[[241 227]
 [  4  27]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.71      0.82       447
        1.0       0.24      0.77      0.37        53

avg / total       0.89      0.72      0.77       500

[[319 128]
 [ 12  41]]
Best parameters set found on development set:

{'C': 65536.0, 'eta': 0.75}

Grid scores on development set:

0.023 (+/-0.094) for {'C': 128.0, 'eta': 0.0}
0.258 (+/-0.104) for {'C': 4096.0, 'eta': 0.25}
0.264 (+/-0.100) for {'C': 8192.0, 'eta': 1.0}
0.012 (+/-0.050) for {'C': 64.0, 'eta': 0.0}
0.215 (+/-0.239) for {'C': 256.0, 'eta': 0.375}
0.035 (+/-0.086) for {'C': 64.0, 'eta': 0.25}
0.258 (+/-0.125) for {'C': 256.0, 'eta': 1.0}
0.273 (+/-0.104) for {'C': 256.0, 'eta': 0.875}
0.254 (+/-0.105) for {'C': 4096.0, 'eta': 1.0}
0.296 (+/-0.164) for {'C': 65536.0, 'eta': 0.75}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.99      0.41      0.58       676
        1.0       0.22      0.97      0.36       114

avg / total       0.88      0.49      0.55       790


Time elapsed: 17166.70 seconds.
Confusion matrix on the test data:
[[277 399]
 [  3 111]]
Precision on the test data: 21.76%
Recall on the test data: 97.37%
F1 Score on the test data: 35.58%

Saving results to eval8/res/lopo_p0_m500_b10_i2.pickle ...
