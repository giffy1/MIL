
---------------------------------------------------------




Number of bags : 877    Number of single instances: 2499

2016-04-29 00:30:27




---------------------------------------------------------

sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       483
        1.0       0.15      0.53      0.23        17

avg / total       0.95      0.88      0.91       500

[[430  53]
 [  8   9]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.97      0.95       500

[[483   0]
 [ 17   0]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       452
        1.0       0.00      0.00      0.00        48

avg / total       0.82      0.90      0.86       500

[[451   1]
 [ 48   0]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.67      0.06      0.12        31

avg / total       0.92      0.94      0.92       499

[[467   1]
 [ 29   2]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       448
        1.0       1.00      0.02      0.04        52

avg / total       0.91      0.90      0.85       500

[[448   0]
 [ 51   1]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       427
        1.0       0.00      0.00      0.00        73

avg / total       0.73      0.85      0.79       500

[[427   0]
 [ 73   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.68      0.76       427
        1.0       0.17      0.40      0.24        73

avg / total       0.77      0.64      0.68       500

[[289 138]
 [ 44  29]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.89      0.91       452
        1.0       0.30      0.44      0.36        48

avg / total       0.88      0.85      0.86       500

[[403  49]
 [ 27  21]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.77      0.86       468
        1.0       0.14      0.55      0.22        31

avg / total       0.91      0.76      0.82       499

[[360 108]
 [ 14  17]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.66      0.78       448
        1.0       0.21      0.77      0.33        52

avg / total       0.88      0.67      0.74       500

[[296 152]
 [ 12  40]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.86      0.92       483
        1.0       0.14      0.65      0.22        17

avg / total       0.96      0.85      0.89       500

[[413  70]
 [  6  11]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.69      0.77       427
        1.0       0.17      0.37      0.23        73

avg / total       0.76      0.64      0.69       500

[[294 133]
 [ 46  27]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.85      0.89       452
        1.0       0.24      0.44      0.31        48

avg / total       0.87      0.81      0.84       500

[[386  66]
 [ 27  21]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.62      0.75       448
        1.0       0.20      0.83      0.32        52

avg / total       0.89      0.64      0.71       500

[[276 172]
 [  9  43]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.70      0.81       468
        1.0       0.11      0.58      0.19        31

avg / total       0.91      0.69      0.77       499

[[327 141]
 [ 13  18]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       483
        1.0       0.20      0.06      0.09        17

avg / total       0.94      0.96      0.95       500

[[479   4]
 [ 16   1]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       452
        1.0       0.00      0.00      0.00        48

avg / total       0.82      0.90      0.86       500

[[451   1]
 [ 48   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       427
        1.0       1.00      0.01      0.03        73

avg / total       0.88      0.86      0.79       500

[[427   0]
 [ 72   1]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.95      0.96       483
        1.0       0.14      0.24      0.17        17

avg / total       0.94      0.92      0.93       500

[[458  25]
 [ 13   4]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.79      0.83       427
        1.0       0.22      0.34      0.26        73

avg / total       0.78      0.72      0.75       500

[[336  91]
 [ 48  25]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.99      0.94       448
        1.0       0.33      0.04      0.07        52

avg / total       0.84      0.89      0.85       500

[[444   4]
 [ 50   2]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.75      0.10      0.17        31

avg / total       0.93      0.94      0.92       499

[[467   1]
 [ 28   3]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.94      0.94       452
        1.0       0.38      0.31      0.34        48

avg / total       0.88      0.88      0.88       500

[[427  25]
 [ 33  15]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.85      0.89       448
        1.0       0.27      0.48      0.35        52

avg / total       0.86      0.81      0.83       500

[[381  67]
 [ 27  25]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.93      0.94       468
        1.0       0.15      0.19      0.17        31

avg / total       0.90      0.88      0.89       499

[[433  35]
 [ 25   6]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       483
        1.0       0.20      0.06      0.09        17

avg / total       0.94      0.96      0.95       500

[[479   4]
 [ 16   1]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       427
        1.0       0.80      0.05      0.10        73

avg / total       0.85      0.86      0.80       500

[[426   1]
 [ 69   4]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.99      0.95       452
        1.0       0.62      0.10      0.18        48

avg / total       0.88      0.91      0.88       500

[[449   3]
 [ 43   5]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.93      0.95       483
        1.0       0.15      0.35      0.21        17

avg / total       0.95      0.91      0.93       500

[[448  35]
 [ 11   6]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.97       468
        1.0       0.43      0.10      0.16        31

avg / total       0.91      0.94      0.92       499

[[464   4]
 [ 28   3]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.97      0.94       448
        1.0       0.40      0.15      0.22        52

avg / total       0.86      0.89      0.87       500

[[436  12]
 [ 44   8]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.82      0.85       427
        1.0       0.25      0.36      0.30        73

avg / total       0.79      0.75      0.77       500

[[351  76]
 [ 47  26]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.91      0.92       452
        1.0       0.30      0.35      0.32        48

avg / total       0.87      0.86      0.86       500

[[412  40]
 [ 31  17]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.75      0.84       448
        1.0       0.23      0.63      0.34        52

avg / total       0.87      0.74      0.78       500

[[336 112]
 [ 19  33]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.88      0.92       468
        1.0       0.14      0.29      0.19        31

avg / total       0.90      0.85      0.87       499

[[414  54]
 [ 22   9]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       483
        1.0       0.25      0.06      0.10        17

avg / total       0.94      0.96      0.95       500

[[480   3]
 [ 16   1]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       427
        1.0       1.00      0.04      0.08        73

avg / total       0.88      0.86      0.80       500

[[427   0]
 [ 70   3]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.98      0.95       452
        1.0       0.45      0.19      0.26        48

avg / total       0.87      0.90      0.88       500

[[441  11]
 [ 39   9]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.67      0.06      0.12        31

avg / total       0.92      0.94      0.92       499

[[467   1]
 [ 29   2]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       483
        1.0       0.14      0.06      0.08        17

avg / total       0.94      0.96      0.95       500

[[477   6]
 [ 16   1]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.93      0.92       448
        1.0       0.32      0.27      0.29        52

avg / total       0.85      0.86      0.86       500

[[418  30]
 [ 38  14]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.99      0.93       427
        1.0       0.69      0.15      0.25        73

avg / total       0.84      0.87      0.83       500

[[422   5]
 [ 62  11]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.93      0.93       448
        1.0       0.34      0.31      0.32        52

avg / total       0.86      0.87      0.86       500

[[417  31]
 [ 36  16]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.97      0.95       452
        1.0       0.43      0.21      0.28        48

avg / total       0.87      0.90      0.88       500

[[439  13]
 [ 38  10]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       468
        1.0       0.30      0.10      0.15        31

avg / total       0.90      0.93      0.91       499

[[461   7]
 [ 28   3]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       483
        1.0       0.17      0.06      0.09        17

avg / total       0.94      0.96      0.95       500

[[478   5]
 [ 16   1]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.99      0.92       427
        1.0       0.70      0.10      0.17        73

avg / total       0.84      0.86      0.81       500

[[424   3]
 [ 66   7]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.99      0.95       452
        1.0       0.67      0.12      0.21        48

avg / total       0.89      0.91      0.88       500

[[449   3]
 [ 42   6]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.97       468
        1.0       0.43      0.10      0.16        31

avg / total       0.91      0.94      0.92       499

[[464   4]
 [ 28   3]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.97      0.94       448
        1.0       0.37      0.13      0.20        52

avg / total       0.85      0.89      0.86       500

[[436  12]
 [ 45   7]]
Best parameters set found on development set:

{'C': 1024.0, 'eta': 0.875}

Grid scores on development set:

0.031 (+/-0.091) for {'C': 256.0, 'eta': 0.125}
0.274 (+/-0.113) for {'C': 1024.0, 'eta': 0.875}
0.256 (+/-0.104) for {'C': 32768.0, 'eta': 1.0}
0.072 (+/-0.118) for {'C': 512.0, 'eta': 0.0}
0.259 (+/-0.156) for {'C': 128.0, 'eta': 0.625}
0.150 (+/-0.097) for {'C': 2048.0, 'eta': 0.125}
0.271 (+/-0.120) for {'C': 4096.0, 'eta': 0.625}
0.170 (+/-0.180) for {'C': 256.0, 'eta': 0.25}
0.216 (+/-0.177) for {'C': 2048.0, 'eta': 0.25}
0.164 (+/-0.086) for {'C': 16384.0, 'eta': 0.125}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.96      0.62      0.75       676
        1.0       0.28      0.86      0.42       114

avg / total       0.86      0.65      0.71       790


Time elapsed: 16306.47 seconds.
Confusion matrix on the test data:
[[419 257]
 [ 16  98]]
Precision on the test data: 27.61%
Recall on the test data: 85.96%
F1 Score on the test data: 41.79%

Saving results to eval8/res/lopo_p0_m500_b10_i0.pickle ...
