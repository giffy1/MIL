
---------------------------------------------------------




Number of bags : 877    Number of single instances: 1250

2016-04-28 18:33:42




---------------------------------------------------------

sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.76      0.83       221
        1.0       0.22      0.52      0.31        29

avg / total       0.84      0.73      0.77       250

[[167  54]
 [ 14  15]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.88      0.91       231
        1.0       0.21      0.37      0.26        19

avg / total       0.89      0.84      0.86       250

[[204  27]
 [ 12   7]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.94      0.96       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       250

[[232  14]
 [  4   0]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.98      0.91       206
        1.0       0.62      0.18      0.28        44

avg / total       0.81      0.84      0.80       250

[[201   5]
 [ 36   8]]
sbMIL(C=2048.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.85      0.92       246
        1.0       0.10      1.00      0.18         4

avg / total       0.99      0.86      0.91       250

[[210  36]
 [  0   4]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.90      0.94       239
        1.0       0.15      0.36      0.21        11

avg / total       0.93      0.88      0.90       250

[[216  23]
 [  7   4]]
sbMIL(C=2048.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.67      0.75       206
        1.0       0.24      0.50      0.33        44

avg / total       0.75      0.64      0.68       250

[[137  69]
 [ 22  22]]
sbMIL(C=2048.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.59      0.73       221
        1.0       0.21      0.83      0.33        29

avg / total       0.88      0.62      0.68       250

[[130  91]
 [  5  24]]
sbMIL(C=2048.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.85      0.89       231
        1.0       0.15      0.32      0.20        19

avg / total       0.88      0.81      0.84       250

[[197  34]
 [ 13   6]]
sbMIL(C=2048.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.67      0.79       239
        1.0       0.08      0.64      0.14        11

avg / total       0.94      0.66      0.76       250

[[159  80]
 [  4   7]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.97      0.90       206
        1.0       0.50      0.14      0.21        44

avg / total       0.78      0.82      0.78       250

[[200   6]
 [ 38   6]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.97      0.98       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       250

[[239   7]
 [  4   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.94      0.94       231
        1.0       0.24      0.21      0.22        19

avg / total       0.88      0.89      0.89       250

[[218  13]
 [ 15   4]]
sbMIL(C=16384.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.84      0.91       246
        1.0       0.07      0.75      0.13         4

avg / total       0.98      0.84      0.90       250

[[206  40]
 [  1   3]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.98      0.97       239
        1.0       0.20      0.09      0.13        11

avg / total       0.93      0.94      0.93       250

[[235   4]
 [ 10   1]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.83      0.87       221
        1.0       0.23      0.38      0.29        29

avg / total       0.83      0.78      0.80       250

[[184  37]
 [ 18  11]]
sbMIL(C=16384.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.81      0.83       206
        1.0       0.29      0.36      0.32        44

avg / total       0.76      0.73      0.74       250

[[166  40]
 [ 28  16]]
sbMIL(C=16384.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.86      0.90       231
        1.0       0.15      0.32      0.21        19

avg / total       0.88      0.82      0.84       250

[[198  33]
 [ 13   6]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.90      0.88       206
        1.0       0.38      0.27      0.32        44

avg / total       0.77      0.79      0.78       250

[[186  20]
 [ 32  12]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.95      0.97       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       250

[[234  12]
 [  4   0]]
sbMIL(C=16384.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.63      0.76       221
        1.0       0.22      0.79      0.34        29

avg / total       0.87      0.65      0.71       250

[[139  82]
 [  6  23]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.89      0.92       231
        1.0       0.19      0.32      0.24        19

avg / total       0.88      0.85      0.86       250

[[206  25]
 [ 13   6]]
sbMIL(C=16384.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.81      0.89       239
        1.0       0.13      0.64      0.22        11

avg / total       0.94      0.80      0.86       250

[[194  45]
 [  4   7]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.77      0.84       221
        1.0       0.22      0.48      0.30        29

avg / total       0.84      0.74      0.77       250

[[170  51]
 [ 15  14]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.92      0.94       239
        1.0       0.10      0.18      0.13        11

avg / total       0.92      0.89      0.91       250

[[221  18]
 [  9   2]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.85      0.92       246
        1.0       0.10      1.00      0.17         4

avg / total       0.99      0.85      0.90       250

[[208  38]
 [  0   4]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.67      0.75       206
        1.0       0.25      0.52      0.34        44

avg / total       0.76      0.64      0.68       250

[[137  69]
 [ 21  23]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.85      0.89       231
        1.0       0.15      0.32      0.20        19

avg / total       0.88      0.81      0.84       250

[[196  35]
 [ 13   6]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.58      0.72       221
        1.0       0.20      0.79      0.32        29

avg / total       0.87      0.61      0.68       250

[[129  92]
 [  6  23]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.64      0.77       239
        1.0       0.08      0.73      0.15        11

avg / total       0.94      0.64      0.74       250

[[152  87]
 [  3   8]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.89      0.94       246
        1.0       0.04      0.25      0.06         4

avg / total       0.97      0.88      0.92       250

[[220  26]
 [  3   1]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.77      0.82       206
        1.0       0.30      0.45      0.36        44

avg / total       0.77      0.72      0.74       250

[[159  47]
 [ 24  20]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.87      0.91       231
        1.0       0.19      0.37      0.25        19

avg / total       0.89      0.83      0.86       250

[[201  30]
 [ 12   7]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.68      0.79       221
        1.0       0.22      0.69      0.33        29

avg / total       0.86      0.68      0.74       250

[[150  71]
 [  9  20]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.81      0.89       239
        1.0       0.15      0.73      0.25        11

avg / total       0.95      0.80      0.86       250

[[193  46]
 [  3   8]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.93      0.96       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.94       250

[[230  16]
 [  4   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.94      0.89       206
        1.0       0.43      0.23      0.30        44

avg / total       0.78      0.81      0.79       250

[[193  13]
 [ 34  10]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.90      0.92       231
        1.0       0.19      0.26      0.22        19

avg / total       0.88      0.86      0.87       250

[[209  22]
 [ 14   5]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.91      0.94       239
        1.0       0.15      0.36      0.22        11

avg / total       0.93      0.88      0.91       250

[[217  22]
 [  7   4]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.79      0.85       221
        1.0       0.22      0.45      0.30        29

avg / total       0.84      0.75      0.79       250

[[175  46]
 [ 16  13]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      1.00      0.99       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       250

[[246   0]
 [  4   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.82      1.00      0.90       206
        1.0       0.00      0.00      0.00        44

avg / total       0.68      0.82      0.74       250

[[206   0]
 [ 44   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       231
        1.0       0.00      0.00      0.00        19

avg / total       0.85      0.92      0.89       250

[[231   0]
 [ 19   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      1.00      0.94       221
        1.0       0.00      0.00      0.00        29

avg / total       0.78      0.88      0.83       250

[[221   0]
 [ 29   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       239
        1.0       0.00      0.00      0.00        11

avg / total       0.91      0.96      0.93       250

[[239   0]
 [ 11   0]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.98      0.98       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       250

[[240   6]
 [  4   0]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.97      0.90       206
        1.0       0.54      0.16      0.25        44

avg / total       0.79      0.83      0.79       250

[[200   6]
 [ 37   7]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.94      0.94       231
        1.0       0.24      0.21      0.22        19

avg / total       0.88      0.89      0.89       250

[[218  13]
 [ 15   4]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.85      0.88       221
        1.0       0.24      0.38      0.30        29

avg / total       0.83      0.79      0.81       250

[[187  34]
 [ 18  11]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.98      0.97       239
        1.0       0.20      0.09      0.13        11

avg / total       0.93      0.94      0.93       250

[[235   4]
 [ 10   1]]
Best parameters set found on development set:

{'C': 1024.0, 'eta': 0.75}

Grid scores on development set:

0.212 (+/-0.221) for {'C': 128.0, 'eta': 0.625}
0.237 (+/-0.155) for {'C': 2048.0, 'eta': 1.0}
0.169 (+/-0.198) for {'C': 65536.0, 'eta': 0.25}
0.244 (+/-0.158) for {'C': 16384.0, 'eta': 0.75}
0.197 (+/-0.236) for {'C': 1024.0, 'eta': 0.5}
0.237 (+/-0.154) for {'C': 8192.0, 'eta': 1.0}
0.251 (+/-0.207) for {'C': 1024.0, 'eta': 0.75}
0.206 (+/-0.218) for {'C': 32768.0, 'eta': 0.375}
0.000 (+/-0.000) for {'C': 64.0, 'eta': 0.25}
0.178 (+/-0.210) for {'C': 16384.0, 'eta': 0.25}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.93      0.65      0.77       676
        1.0       0.26      0.72      0.38       114

avg / total       0.84      0.66      0.71       790


Time elapsed: 13599.66 seconds.
Confusion matrix on the test data:
[[442 234]
 [ 32  82]]
Precision on the test data: 25.95%
Recall on the test data: 71.93%
F1 Score on the test data: 38.14%

Saving results to eval8/res/lopo_p0_m250_b10_i2.pickle ...
