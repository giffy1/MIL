
---------------------------------------------------------




Number of bags : 51    Number of single instances: 1250

2016-04-28 22:29:57




---------------------------------------------------------

sbMIL(C=16384.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.70      0.81       234
        1.0       0.14      0.69      0.23        16

avg / total       0.92      0.70      0.78       250

[[164  70]
 [  5  11]]
sbMIL(C=16384.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.76      0.84       232
        1.0       0.11      0.39      0.18        18

avg / total       0.88      0.74      0.79       250

[[177  55]
 [ 11   7]]
sbMIL(C=16384.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.68      0.77       214
        1.0       0.22      0.53      0.31        36

avg / total       0.80      0.66      0.70       250

[[145  69]
 [ 17  19]]
sbMIL(C=16384.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.68      0.79       223
        1.0       0.23      0.78      0.35        27

avg / total       0.88      0.69      0.75       250

[[151  72]
 [  6  21]]
sbMIL(C=16384.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.85      0.91       241
        1.0       0.08      0.33      0.13         9

avg / total       0.94      0.84      0.88       250

[[206  35]
 [  6   3]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.81      0.89       241
        1.0       0.12      0.67      0.20         9

avg / total       0.95      0.81      0.87       250

[[196  45]
 [  3   6]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.71      0.82       241
        1.0       0.07      0.56      0.12         9

avg / total       0.94      0.70      0.79       250

[[170  71]
 [  4   5]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.31      0.45       214
        1.0       0.14      0.67      0.23        36

avg / total       0.74      0.36      0.42       250

[[ 66 148]
 [ 12  24]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.55      0.68       214
        1.0       0.19      0.64      0.30        36

avg / total       0.80      0.56      0.63       250

[[118  96]
 [ 13  23]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.59      0.74       234
        1.0       0.11      0.75      0.20        16

avg / total       0.92      0.60      0.70       250

[[139  95]
 [  4  12]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.67      0.79       232
        1.0       0.13      0.67      0.22        18

avg / total       0.90      0.67      0.75       250

[[155  77]
 [  6  12]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.56      0.71       223
        1.0       0.20      0.89      0.32        27

avg / total       0.89      0.59      0.67       250

[[124  99]
 [  3  24]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.46      0.62       234
        1.0       0.09      0.81      0.17        16

avg / total       0.92      0.48      0.59       250

[[107 127]
 [  3  13]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.36      0.52       223
        1.0       0.13      0.78      0.22        27

avg / total       0.84      0.41      0.49       250

[[ 81 142]
 [  6  21]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.57      0.71       232
        1.0       0.10      0.61      0.17        18

avg / total       0.89      0.57      0.67       250

[[132 100]
 [  7  11]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.92      0.95       241
        1.0       0.14      0.33      0.19         9

avg / total       0.94      0.90      0.92       250

[[222  19]
 [  6   3]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.72      0.79       214
        1.0       0.16      0.31      0.21        36

avg / total       0.76      0.66      0.70       250

[[155  59]
 [ 25  11]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.90      0.93       234
        1.0       0.18      0.31      0.23        16

avg / total       0.90      0.86      0.88       250

[[211  23]
 [ 11   5]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.88      0.91       232
        1.0       0.18      0.33      0.23        18

avg / total       0.89      0.84      0.86       250

[[204  28]
 [ 12   6]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.82      0.87       223
        1.0       0.23      0.44      0.30        27

avg / total       0.85      0.78      0.81       250

[[182  41]
 [ 15  12]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.97      0.97       241
        1.0       0.12      0.11      0.12         9

avg / total       0.94      0.94      0.94       250

[[234   7]
 [  8   1]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       234
        1.0       0.00      0.00      0.00        16

avg / total       0.88      0.93      0.90       250

[[232   2]
 [ 16   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.99      0.98       241
        1.0       0.00      0.00      0.00         9

avg / total       0.93      0.96      0.94       250

[[239   2]
 [  9   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       214
        1.0       0.00      0.00      0.00        36

avg / total       0.73      0.86      0.79       250

[[214   0]
 [ 36   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.99      0.94       223
        1.0       0.00      0.00      0.00        27

avg / total       0.79      0.88      0.84       250

[[220   3]
 [ 27   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.92      0.89       250

[[230   2]
 [ 18   0]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.95      0.94       232
        1.0       0.08      0.06      0.06        18

avg / total       0.87      0.88      0.88       250

[[220  12]
 [ 17   1]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.91      0.90       223
        1.0       0.19      0.19      0.19        27

avg / total       0.83      0.83      0.83       250

[[202  21]
 [ 22   5]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.96      0.96       234
        1.0       0.33      0.31      0.32        16

avg / total       0.91      0.92      0.91       250

[[224  10]
 [ 11   5]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.92      0.89       214
        1.0       0.22      0.14      0.17        36

avg / total       0.77      0.80      0.79       250

[[196  18]
 [ 31   5]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       241
        1.0       0.00      0.00      0.00         9

avg / total       0.93      0.96      0.94       250

[[240   1]
 [  9   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.96       234
        1.0       0.00      0.00      0.00        16

avg / total       0.88      0.93      0.90       250

[[233   1]
 [ 16   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      1.00      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.93      0.89       250

[[232   0]
 [ 18   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       214
        1.0       0.00      0.00      0.00        36

avg / total       0.73      0.85      0.79       250

[[213   1]
 [ 36   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       223
        1.0       0.00      0.00      0.00        27

avg / total       0.80      0.89      0.84       250

[[223   0]
 [ 27   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       241
        1.0       0.00      0.00      0.00         9

avg / total       0.93      0.96      0.94       250

[[240   1]
 [  9   0]]
sbMIL(C=64.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.79      0.87       241
        1.0       0.07      0.44      0.13         9

avg / total       0.94      0.78      0.85       250

[[191  50]
 [  5   4]]
sbMIL(C=64.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.43      0.58       214
        1.0       0.15      0.61      0.25        36

avg / total       0.77      0.46      0.53       250

[[ 93 121]
 [ 14  22]]
sbMIL(C=64.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.64      0.77       234
        1.0       0.12      0.69      0.20        16

avg / total       0.91      0.64      0.73       250

[[150  84]
 [  5  11]]
sbMIL(C=64.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.57      0.71       223
        1.0       0.17      0.74      0.28        27

avg / total       0.86      0.58      0.66       250

[[126  97]
 [  7  20]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      1.00      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.93      0.89       250

[[232   0]
 [ 18   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       214
        1.0       0.00      0.00      0.00        36

avg / total       0.73      0.85      0.79       250

[[213   1]
 [ 36   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.96       234
        1.0       0.00      0.00      0.00        16

avg / total       0.88      0.93      0.90       250

[[233   1]
 [ 16   0]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       241
        1.0       0.04      1.00      0.07         9

avg / total       0.00      0.04      0.00       250

[[  0 241]
 [  0   9]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       223
        1.0       0.00      0.00      0.00        27

avg / total       0.80      0.89      0.84       250

[[222   1]
 [ 27   0]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       214
        1.0       0.14      1.00      0.25        36

avg / total       0.02      0.14      0.04       250

[[  0 214]
 [  0  36]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       234
        1.0       0.06      1.00      0.12        16

avg / total       0.00      0.06      0.01       250

[[  0 234]
 [  0  16]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       223
        1.0       0.11      1.00      0.19        27

avg / total       0.01      0.11      0.02       250

[[  0 223]
 [  0  27]]
sbMIL(C=64.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.64      0.76       232
        1.0       0.10      0.50      0.16        18

avg / total       0.88      0.63      0.72       250

[[148  84]
 [  9   9]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       232
        1.0       0.07      1.00      0.13        18

avg / total       0.01      0.07      0.01       250

[[  0 232]
 [  0  18]]
Best parameters set found on development set:

{'C': 65536.0, 'eta': 0.5}

Grid scores on development set:

0.237 (+/-0.164) for {'C': 16384.0, 'eta': 0.375}
0.247 (+/-0.103) for {'C': 65536.0, 'eta': 0.5}
0.181 (+/-0.082) for {'C': 64.0, 'eta': 0.625}
0.232 (+/-0.073) for {'C': 64.0, 'eta': 0.25}
0.000 (+/-0.000) for {'C': 65536.0, 'eta': 0.0}
0.173 (+/-0.173) for {'C': 64.0, 'eta': 0.125}
0.000 (+/-0.000) for {'C': 512.0, 'eta': 0.0}
0.000 (+/-0.000) for {'C': 1024.0, 'eta': 0.0}
0.202 (+/-0.109) for {'C': 64.0, 'eta': 0.5}
0.154 (+/-0.126) for {'C': 512.0, 'eta': 1.0}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.98      0.37      0.54       676
        1.0       0.20      0.95      0.33       114

avg / total       0.87      0.46      0.51       790


Time elapsed: 9029.56 seconds.
Confusion matrix on the test data:
[[253 423]
 [  6 108]]
Precision on the test data: 20.34%
Recall on the test data: 94.74%
F1 Score on the test data: 33.49%

Saving results to eval8/res/lopo_p0_m250_b200_i1.pickle ...
