
---------------------------------------------------------




Number of bags : 181    Number of single instances: 2499

2016-04-29 07:31:58




---------------------------------------------------------

sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.94      0.95       483
        1.0       0.07      0.12      0.09        17

avg / total       0.94      0.91      0.93       500

[[455  28]
 [ 15   2]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.75      0.84       448
        1.0       0.23      0.63      0.34        52

avg / total       0.87      0.74      0.78       500

[[336 112]
 [ 19  33]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.91      0.94       483
        1.0       0.09      0.24      0.12        17

avg / total       0.94      0.89      0.91       500

[[440  43]
 [ 13   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.89      0.89       427
        1.0       0.32      0.32      0.32        73

avg / total       0.80      0.80      0.80       500

[[379  48]
 [ 50  23]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.88      0.91       468
        1.0       0.14      0.29      0.19        31

avg / total       0.90      0.85      0.87       499

[[413  55]
 [ 22   9]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.82      0.88       452
        1.0       0.25      0.54      0.34        48

avg / total       0.88      0.80      0.83       500

[[372  80]
 [ 22  26]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.94      0.91       427
        1.0       0.41      0.25      0.31        73

avg / total       0.81      0.84      0.82       500

[[401  26]
 [ 55  18]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.81      0.87       448
        1.0       0.23      0.50      0.32        52

avg / total       0.86      0.78      0.81       500

[[363  85]
 [ 26  26]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.98      0.97       483
        1.0       0.25      0.24      0.24        17

avg / total       0.95      0.95      0.95       500

[[471  12]
 [ 13   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.91      0.92       452
        1.0       0.30      0.35      0.32        48

avg / total       0.87      0.86      0.86       500

[[412  40]
 [ 31  17]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       468
        1.0       0.13      0.35      0.19        31

avg / total       0.90      0.81      0.85       499

[[393  75]
 [ 20  11]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.85      0.85       427
        1.0       0.14      0.14      0.14        73

avg / total       0.75      0.75      0.75       500

[[363  64]
 [ 63  10]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       483
        1.0       0.11      0.41      0.18        17

avg / total       0.95      0.87      0.90       500

[[428  55]
 [ 10   7]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.87      0.90       448
        1.0       0.24      0.35      0.28        52

avg / total       0.85      0.82      0.83       500

[[391  57]
 [ 34  18]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.90      0.91       468
        1.0       0.00      0.00      0.00        31

avg / total       0.87      0.84      0.86       499

[[419  49]
 [ 31   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.98      0.95       452
        1.0       0.50      0.19      0.27        48

avg / total       0.88      0.90      0.88       500

[[443   9]
 [ 39   9]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.85      0.90       452
        1.0       0.27      0.50      0.35        48

avg / total       0.88      0.82      0.84       500

[[386  66]
 [ 24  24]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.80      0.84       427
        1.0       0.27      0.44      0.34        73

avg / total       0.80      0.75      0.77       500

[[341  86]
 [ 41  32]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       468
        1.0       0.12      0.35      0.18        31

avg / total       0.90      0.81      0.85       499

[[391  77]
 [ 20  11]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.70      0.81       448
        1.0       0.21      0.71      0.33        52

avg / total       0.88      0.70      0.76       500

[[312 136]
 [ 15  37]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.91      0.94       483
        1.0       0.08      0.24      0.12        17

avg / total       0.94      0.89      0.91       500

[[439  44]
 [ 13   4]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.90      0.92       452
        1.0       0.31      0.42      0.36        48

avg / total       0.88      0.86      0.86       500

[[408  44]
 [ 28  20]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.88      0.88       427
        1.0       0.31      0.32      0.31        73

avg / total       0.80      0.80      0.80       500

[[376  51]
 [ 50  23]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.75      0.84       448
        1.0       0.23      0.63      0.34        52

avg / total       0.87      0.74      0.79       500

[[338 110]
 [ 19  33]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.90      0.92       468
        1.0       0.16      0.29      0.20        31

avg / total       0.90      0.86      0.88       499

[[419  49]
 [ 22   9]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.95      0.96       483
        1.0       0.04      0.06      0.05        17

avg / total       0.93      0.92      0.93       500

[[458  25]
 [ 16   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.81      0.87       448
        1.0       0.23      0.48      0.31        52

avg / total       0.86      0.78      0.81       500

[[365  83]
 [ 27  25]]

---------------------------------------------------------




Number of bags : 181    Number of single instances: 2499

2016-04-29 11:06:58




---------------------------------------------------------

sbMIL(C=8192.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.83      0.90       483
        1.0       0.12      0.65      0.20        17

avg / total       0.96      0.83      0.88       500

[[402  81]
 [  6  11]]
sbMIL(C=8192.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.59      0.70       427
        1.0       0.18      0.52      0.26        73

avg / total       0.78      0.58      0.64       500

[[251 176]
 [ 35  38]]
sbMIL(C=8192.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.77      0.85       452
        1.0       0.24      0.67      0.35        48

avg / total       0.89      0.76      0.81       500

[[349 103]
 [ 16  32]]
sbMIL(C=8192.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.61      0.75       448
        1.0       0.20      0.83      0.32        52

avg / total       0.89      0.64      0.71       500

[[275 173]
 [  9  43]]
sbMIL(C=8192.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.67      0.79       468
        1.0       0.13      0.77      0.23        31

avg / total       0.93      0.67      0.76       499

[[312 156]
 [  7  24]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.97      0.95       500

[[483   0]
 [ 17   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.97      0.92       427
        1.0       0.39      0.10      0.15        73

avg / total       0.79      0.85      0.80       500

[[416  11]
 [ 66   7]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.99      0.95       452
        1.0       0.62      0.10      0.18        48

avg / total       0.88      0.91      0.88       500

[[449   3]
 [ 43   5]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.92      0.91       448
        1.0       0.22      0.19      0.21        52

avg / total       0.84      0.85      0.84       500

[[413  35]
 [ 42  10]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.93      0.90       499

[[464   4]
 [ 31   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.97      0.95       500

[[483   0]
 [ 17   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       427
        1.0       0.00      0.00      0.00        73

avg / total       0.73      0.85      0.79       500

[[427   0]
 [ 73   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       452
        1.0       0.00      0.00      0.00        48

avg / total       0.82      0.90      0.86       500

[[452   0]
 [ 48   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.99      0.94       448
        1.0       0.20      0.02      0.04        52

avg / total       0.82      0.89      0.85       500

[[444   4]
 [ 51   1]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.93      0.90       499

[[463   5]
 [ 31   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.88      0.93       483
        1.0       0.10      0.35      0.15        17

avg / total       0.95      0.87      0.90       500

[[427  56]
 [ 11   6]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.76      0.82       427
        1.0       0.25      0.47      0.33        73

avg / total       0.80      0.72      0.75       500

[[325 102]
 [ 39  34]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.87      0.90       452
        1.0       0.28      0.50      0.36        48

avg / total       0.88      0.83      0.85       500

[[391  61]
 [ 24  24]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.70      0.81       448
        1.0       0.21      0.69      0.32        52

avg / total       0.87      0.70      0.76       500

[[313 135]
 [ 16  36]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.86      0.91       468
        1.0       0.16      0.39      0.22        31

avg / total       0.91      0.83      0.86       499

[[403  65]
 [ 19  12]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.97       483
        1.0       0.06      0.06      0.06        17

avg / total       0.94      0.93      0.93       500

[[466  17]
 [ 16   1]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.94      0.91       427
        1.0       0.39      0.23      0.29        73

avg / total       0.81      0.83      0.82       500

[[400  27]
 [ 56  17]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.95      0.94       452
        1.0       0.34      0.25      0.29        48

avg / total       0.87      0.88      0.87       500

[[429  23]
 [ 36  12]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.84      0.89       448
        1.0       0.28      0.52      0.36        52

avg / total       0.87      0.81      0.83       500

[[377  71]
 [ 25  27]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.95      0.95       468
        1.0       0.15      0.13      0.14        31

avg / total       0.89      0.90      0.90       499

[[445  23]
 [ 27   4]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.96      0.95       500

[[480   3]
 [ 17   0]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       427
        1.0       0.00      0.00      0.00        73

avg / total       0.73      0.85      0.79       500

[[427   0]
 [ 73   0]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      1.00      0.95       452
        1.0       1.00      0.04      0.08        48

avg / total       0.92      0.91      0.87       500

[[452   0]
 [ 46   2]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.97      0.93       448
        1.0       0.18      0.06      0.09        52

avg / total       0.82      0.87      0.84       500

[[434  14]
 [ 49   3]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[467   1]
 [ 31   0]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.78      0.87       483
        1.0       0.09      0.65      0.16        17

avg / total       0.95      0.78      0.85       500

[[377 106]
 [  6  11]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.82      0.36      0.50       427
        1.0       0.12      0.52      0.20        73

avg / total       0.71      0.39      0.46       500

[[155 272]
 [ 35  38]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.75      0.84       452
        1.0       0.21      0.62      0.31        48

avg / total       0.88      0.74      0.79       500

[[338 114]
 [ 18  30]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.58      0.73       448
        1.0       0.19      0.85      0.31        52

avg / total       0.89      0.61      0.68       500

[[260 188]
 [  8  44]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.59      0.74       468
        1.0       0.14      0.97      0.24        31

avg / total       0.94      0.62      0.71       499

[[277 191]
 [  1  30]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.86      0.92       483
        1.0       0.12      0.53      0.19        17

avg / total       0.95      0.85      0.89       500

[[415  68]
 [  8   9]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.67      0.76       427
        1.0       0.20      0.49      0.29        73

avg / total       0.79      0.64      0.69       500

[[286 141]
 [ 37  36]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       452
        1.0       0.28      0.56      0.37        48

avg / total       0.88      0.82      0.84       500

[[381  71]
 [ 21  27]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.66      0.79       448
        1.0       0.21      0.79      0.34        52

avg / total       0.89      0.68      0.74       500

[[297 151]
 [ 11  41]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.75      0.84       468
        1.0       0.11      0.48      0.18        31

avg / total       0.90      0.73      0.80       499

[[350 118]
 [ 16  15]]
sbMIL(C=8192.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       483
        1.0       0.11      0.41      0.18        17

avg / total       0.95      0.87      0.91       500

[[429  54]
 [ 10   7]]
sbMIL(C=8192.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.78      0.83       427
        1.0       0.26      0.45      0.33        73

avg / total       0.80      0.73      0.76       500

[[334  93]
 [ 40  33]]
sbMIL(C=8192.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.85      0.90       452
        1.0       0.27      0.52      0.36        48

avg / total       0.88      0.82      0.85       500

[[386  66]
 [ 23  25]]
sbMIL(C=8192.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.69      0.80       448
        1.0       0.21      0.71      0.33        52

avg / total       0.88      0.69      0.75       500

[[310 138]
 [ 15  37]]
sbMIL(C=8192.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.85      0.90       468
        1.0       0.14      0.35      0.20        31

avg / total       0.90      0.82      0.86       499

[[399  69]
 [ 20  11]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       483
        1.0       0.00      0.00      0.00        17

avg / total       0.93      0.96      0.95       500

[[482   1]
 [ 17   0]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.95      0.90       427
        1.0       0.05      0.01      0.02        73

avg / total       0.73      0.82      0.77       500

[[407  20]
 [ 72   1]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       452
        1.0       0.00      0.00      0.00        48

avg / total       0.82      0.90      0.86       500

[[452   0]
 [ 48   0]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.96      0.93       448
        1.0       0.10      0.04      0.06        52

avg / total       0.81      0.86      0.84       500

[[430  18]
 [ 50   2]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.93      0.91       499

[[466   2]
 [ 31   0]]
Best parameters set found on development set:

{'C': 8192.0, 'eta': 0.5}

Grid scores on development set:

0.273 (+/-0.111) for {'C': 8192.0, 'eta': 0.75}
0.108 (+/-0.179) for {'C': 1024.0, 'eta': 0.125}
0.007 (+/-0.028) for {'C': 64.0, 'eta': 0.0}
0.277 (+/-0.155) for {'C': 2048.0, 'eta': 0.5}
0.227 (+/-0.223) for {'C': 1024.0, 'eta': 0.25}
0.033 (+/-0.082) for {'C': 4096.0, 'eta': 0.0}
0.245 (+/-0.118) for {'C': 128.0, 'eta': 1.0}
0.274 (+/-0.151) for {'C': 1024.0, 'eta': 0.625}
0.279 (+/-0.149) for {'C': 8192.0, 'eta': 0.5}
0.015 (+/-0.043) for {'C': 64.0, 'eta': 0.125}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.92      0.62      0.74       676
        1.0       0.23      0.68      0.34       114

avg / total       0.82      0.63      0.68       790


Time elapsed: 46320.25 seconds.
Confusion matrix on the test data:
[[420 256]
 [ 37  77]]
Precision on the test data: 23.12%
Recall on the test data: 67.54%
F1 Score on the test data: 34.45%

Saving results to eval8/res/lopo_p0_m500_b50_i0.pickle ...
