
---------------------------------------------------------




Number of bags : 51    Number of single instances: 1250

2016-04-28 23:26:42




---------------------------------------------------------

sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.85      0.91       250

[[213  33]
 [  4   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.25      0.40       239
        1.0       0.06      1.00      0.11        11

avg / total       0.96      0.28      0.38       250

[[ 59 180]
 [  0  11]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.25       231
        1.0       0.09      1.00      0.16        19

avg / total       0.93      0.21      0.24       250

[[ 33 198]
 [  0  19]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.47      0.64       246
        1.0       0.03      1.00      0.06         4

avg / total       0.98      0.48      0.63       250

[[116 130]
 [  0   4]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.10      0.18       206
        1.0       0.19      1.00      0.32        44

avg / total       0.86      0.26      0.20       250

[[ 20 186]
 [  0  44]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.17      0.29       221
        1.0       0.14      1.00      0.24        29

avg / total       0.90      0.27      0.29       250

[[ 38 183]
 [  0  29]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.66      0.76       206
        1.0       0.30      0.68      0.42        44

avg / total       0.80      0.66      0.70       250

[[136  70]
 [ 14  30]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.67      0.79       231
        1.0       0.14      0.63      0.22        19

avg / total       0.89      0.67      0.75       250

[[155  76]
 [  7  12]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.64      0.76       221
        1.0       0.19      0.62      0.29        29

avg / total       0.84      0.64      0.70       250

[[142  79]
 [ 11  18]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.79      0.88       239
        1.0       0.14      0.73      0.23        11

avg / total       0.95      0.79      0.85       250

[[189  50]
 [  3   8]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.09      0.16       206
        1.0       0.19      1.00      0.32        44

avg / total       0.86      0.25      0.19       250

[[ 18 188]
 [  0  44]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.46      0.63       246
        1.0       0.03      1.00      0.06         4

avg / total       0.98      0.47      0.62       250

[[114 132]
 [  0   4]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.25       231
        1.0       0.09      1.00      0.16        19

avg / total       0.93      0.21      0.24       250

[[ 33 198]
 [  0  19]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.16      0.28       221
        1.0       0.14      1.00      0.24        29

avg / total       0.90      0.26      0.28       250

[[ 36 185]
 [  0  29]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.22      0.36       239
        1.0       0.06      1.00      0.11        11

avg / total       0.96      0.26      0.35       250

[[ 53 186]
 [  0  11]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.46      0.63       246
        1.0       0.03      1.00      0.06         4

avg / total       0.98      0.47      0.62       250

[[114 132]
 [  0   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.09      0.16       206
        1.0       0.19      1.00      0.32        44

avg / total       0.86      0.25      0.19       250

[[ 18 188]
 [  0  44]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.25       231
        1.0       0.09      1.00      0.16        19

avg / total       0.93      0.21      0.24       250

[[ 33 198]
 [  0  19]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.15      0.27       221
        1.0       0.13      1.00      0.24        29

avg / total       0.90      0.25      0.26       250

[[ 34 187]
 [  0  29]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.21      0.34       239
        1.0       0.05      1.00      0.10        11

avg / total       0.96      0.24      0.33       250

[[ 49 190]
 [  0  11]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.99      0.90       206
        1.0       0.25      0.02      0.04        44

avg / total       0.72      0.82      0.75       250

[[203   3]
 [ 43   1]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      1.00      0.99       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       250

[[246   0]
 [  4   0]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       231
        1.0       0.00      0.00      0.00        19

avg / total       0.85      0.92      0.89       250

[[231   0]
 [ 19   0]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      1.00      0.94       221
        1.0       0.00      0.00      0.00        29

avg / total       0.78      0.88      0.83       250

[[221   0]
 [ 29   0]]
sbMIL(C=128.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       239
        1.0       0.00      0.00      0.00        11

avg / total       0.91      0.96      0.93       250

[[239   0]
 [ 11   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.99      0.99       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       250

[[244   2]
 [  4   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       231
        1.0       0.00      0.00      0.00        19

avg / total       0.85      0.92      0.89       250

[[230   1]
 [ 19   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.99      0.93       221
        1.0       0.00      0.00      0.00        29

avg / total       0.78      0.88      0.83       250

[[219   2]
 [ 29   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.99      0.97       239
        1.0       0.00      0.00      0.00        11

avg / total       0.91      0.95      0.93       250

[[237   2]
 [ 11   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.82      0.99      0.90       206
        1.0       0.00      0.00      0.00        44

avg / total       0.68      0.82      0.74       250

[[204   2]
 [ 44   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      1.00      0.99       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       250

[[245   1]
 [  4   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.82      0.99      0.90       206
        1.0       0.00      0.00      0.00        44

avg / total       0.68      0.82      0.74       250

[[204   2]
 [ 44   0]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.47      0.64       246
        1.0       0.03      1.00      0.06         4

avg / total       0.98      0.48      0.63       250

[[116 130]
 [  0   4]]
sbMIL(C=32768.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       231
        1.0       0.00      0.00      0.00        19

avg / total       0.85      0.92      0.89       250

[[230   1]
 [ 19   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       239
        1.0       0.00      0.00      0.00        11

avg / total       0.91      0.95      0.93       250

[[238   1]
 [ 11   0]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.10      0.18       206
        1.0       0.19      1.00      0.32        44

avg / total       0.86      0.26      0.20       250

[[ 20 186]
 [  0  44]]
sbMIL(C=32768.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.99      0.93       221
        1.0       0.00      0.00      0.00        29

avg / total       0.78      0.87      0.82       250

[[218   3]
 [ 29   0]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.25       231
        1.0       0.09      1.00      0.16        19

avg / total       0.93      0.21      0.24       250

[[ 33 198]
 [  0  19]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.93      0.96       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.94       250

[[229  17]
 [  4   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.80      0.86       231
        1.0       0.13      0.37      0.19        19

avg / total       0.88      0.76      0.81       250

[[184  47]
 [ 12   7]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.79      0.83       206
        1.0       0.31      0.43      0.36        44

avg / total       0.77      0.73      0.74       250

[[163  43]
 [ 25  19]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.76      0.84       221
        1.0       0.22      0.52      0.31        29

avg / total       0.84      0.74      0.78       250

[[169  52]
 [ 14  15]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.17      0.29       221
        1.0       0.14      1.00      0.24        29

avg / total       0.90      0.26      0.28       250

[[ 37 184]
 [  0  29]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.23      0.37       239
        1.0       0.06      1.00      0.11        11

avg / total       0.96      0.26      0.36       250

[[ 54 185]
 [  0  11]]
sbMIL(C=1024.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       239
        1.0       0.18      0.55      0.27        11

avg / total       0.94      0.87      0.90       250

[[212  27]
 [  5   6]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.72      0.83       246
        1.0       0.04      0.75      0.08         4

avg / total       0.98      0.72      0.82       250

[[177  69]
 [  1   3]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.43      0.58       206
        1.0       0.24      0.84      0.37        44

avg / total       0.81      0.50      0.55       250

[[ 88 118]
 [  7  37]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.44      0.61       231
        1.0       0.13      1.00      0.23        19

avg / total       0.93      0.48      0.58       250

[[102 129]
 [  0  19]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.49      0.66       239
        1.0       0.08      1.00      0.15        11

avg / total       0.96      0.51      0.64       250

[[117 122]
 [  0  11]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.36      0.52       221
        1.0       0.15      0.86      0.26        29

avg / total       0.86      0.42      0.49       250

[[ 80 141]
 [  4  25]]
Best parameters set found on development set:

{'C': 8192.0, 'eta': 0.375}

Grid scores on development set:

0.178 (+/-0.187) for {'C': 2048.0, 'eta': 0.875}
0.232 (+/-0.270) for {'C': 8192.0, 'eta': 0.375}
0.176 (+/-0.187) for {'C': 32768.0, 'eta': 0.875}
0.176 (+/-0.187) for {'C': 65536.0, 'eta': 0.875}
0.008 (+/-0.033) for {'C': 128.0, 'eta': 0.0}
0.000 (+/-0.000) for {'C': 65536.0, 'eta': 0.0}
0.000 (+/-0.000) for {'C': 32768.0, 'eta': 0.0}
0.177 (+/-0.188) for {'C': 8192.0, 'eta': 0.875}
0.227 (+/-0.252) for {'C': 1024.0, 'eta': 0.25}
0.218 (+/-0.198) for {'C': 256.0, 'eta': 0.625}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.91      0.47      0.62       676
        1.0       0.19      0.74      0.30       114

avg / total       0.81      0.51      0.58       790


Time elapsed: 10012.97 seconds.
Confusion matrix on the test data:
[[318 358]
 [ 30  84]]
Precision on the test data: 19.00%
Recall on the test data: 73.68%
F1 Score on the test data: 30.22%

Saving results to eval8/res/lopo_p0_m250_b200_i2.pickle ...
