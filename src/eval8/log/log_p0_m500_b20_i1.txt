
---------------------------------------------------------




Number of bags : 441    Number of single instances: 2499

2016-04-29 00:54:17




---------------------------------------------------------

sbMIL(C=16384.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       484
        1.0       0.10      0.44      0.17        16

avg / total       0.95      0.86      0.90       500

[[423  61]
 [  9   7]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.97       484
        1.0       0.14      0.19      0.16        16

avg / total       0.95      0.94      0.94       500

[[465  19]
 [ 13   3]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.93      0.93       468
        1.0       0.08      0.10      0.09        31

avg / total       0.89      0.88      0.88       499

[[434  34]
 [ 28   3]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.84      0.88       446
        1.0       0.27      0.48      0.35        54

avg / total       0.86      0.80      0.83       500

[[376  70]
 [ 28  26]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.93      0.93       458
        1.0       0.29      0.31      0.30        42

avg / total       0.88      0.88      0.88       500

[[426  32]
 [ 29  13]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.89      0.88       422
        1.0       0.29      0.24      0.26        78

avg / total       0.77      0.79      0.78       500

[[375  47]
 [ 59  19]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       484
        1.0       0.09      0.38      0.14        16

avg / total       0.95      0.86      0.90       500

[[423  61]
 [ 10   6]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.74      0.80       422
        1.0       0.24      0.45      0.31        78

avg / total       0.78      0.69      0.73       500

[[312 110]
 [ 43  35]]
sbMIL(C=16384.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.86      0.90       458
        1.0       0.24      0.50      0.33        42

avg / total       0.89      0.83      0.85       500

[[393  65]
 [ 21  21]]
sbMIL(C=16384.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.74      0.80       422
        1.0       0.23      0.42      0.30        78

avg / total       0.77      0.69      0.72       500

[[313 109]
 [ 45  33]]
sbMIL(C=16384.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.82      0.88       468
        1.0       0.12      0.35      0.18        31

avg / total       0.90      0.80      0.84       499

[[386  82]
 [ 20  11]]
sbMIL(C=16384.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.64      0.77       446
        1.0       0.22      0.85      0.36        54

avg / total       0.89      0.67      0.73       500

[[287 159]
 [  8  46]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.86      0.90       458
        1.0       0.25      0.50      0.33        42

avg / total       0.89      0.83      0.85       500

[[394  64]
 [ 21  21]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.81      0.87       468
        1.0       0.09      0.29      0.14        31

avg / total       0.89      0.78      0.83       499

[[381  87]
 [ 22   9]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.68      0.80       446
        1.0       0.22      0.74      0.34        54

avg / total       0.88      0.69      0.75       500

[[305 141]
 [ 14  40]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.97       484
        1.0       0.13      0.19      0.15        16

avg / total       0.95      0.93      0.94       500

[[464  20]
 [ 13   3]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.94      0.94       458
        1.0       0.31      0.29      0.30        42

avg / total       0.88      0.89      0.88       500

[[431  27]
 [ 30  12]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.89      0.87       422
        1.0       0.20      0.14      0.16        78

avg / total       0.75      0.78      0.76       500

[[377  45]
 [ 67  11]]
sbMIL(C=512.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.95      0.96       484
        1.0       0.12      0.19      0.15        16

avg / total       0.95      0.93      0.94       500

[[462  22]
 [ 13   3]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.89      0.91       468
        1.0       0.04      0.06      0.05        31

avg / total       0.88      0.84      0.86       499

[[417  51]
 [ 29   2]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.87      0.90       446
        1.0       0.30      0.46      0.36        54

avg / total       0.86      0.82      0.84       500

[[387  59]
 [ 29  25]]
sbMIL(C=512.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.91      0.89       422
        1.0       0.38      0.29      0.33        78

avg / total       0.80      0.81      0.80       500

[[384  38]
 [ 55  23]]
sbMIL(C=512.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.92      0.93       458
        1.0       0.29      0.36      0.32        42

avg / total       0.89      0.87      0.88       500

[[422  36]
 [ 27  15]]
sbMIL(C=512.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.83      0.88       446
        1.0       0.29      0.56      0.38        54

avg / total       0.87      0.80      0.83       500

[[372  74]
 [ 24  30]]
sbMIL(C=512.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.96      0.95       468
        1.0       0.18      0.13      0.15        31

avg / total       0.90      0.91      0.90       499

[[450  18]
 [ 27   4]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[484   0]
 [ 16   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.99      0.96       458
        1.0       0.50      0.10      0.16        42

avg / total       0.89      0.92      0.89       500

[[454   4]
 [ 38   4]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       422
        1.0       0.50      0.01      0.03        78

avg / total       0.79      0.84      0.78       500

[[421   1]
 [ 77   1]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.97      0.93       446
        1.0       0.30      0.11      0.16        54

avg / total       0.84      0.88      0.85       500

[[432  14]
 [ 48   6]]
sbMIL(C=8192.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.96      0.95       500

[[481   3]
 [ 16   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       1.00      0.06      0.12        31

avg / total       0.95      0.94      0.92       499

[[468   0]
 [ 29   2]]
sbMIL(C=8192.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       1.00      0.10      0.18        31

avg / total       0.95      0.94      0.92       499

[[468   0]
 [ 28   3]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.63      0.73       422
        1.0       0.21      0.51      0.29        78

avg / total       0.77      0.61      0.67       500

[[267 155]
 [ 38  40]]
sbMIL(C=8192.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.99      0.92       422
        1.0       0.62      0.06      0.12        78

avg / total       0.82      0.85      0.79       500

[[419   3]
 [ 73   5]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.84      0.91       484
        1.0       0.11      0.62      0.19        16

avg / total       0.96      0.83      0.88       500

[[406  78]
 [  6  10]]
sbMIL(C=8192.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       458
        1.0       0.55      0.14      0.23        42

avg / total       0.89      0.92      0.90       500

[[453   5]
 [ 36   6]]
sbMIL(C=8192.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.96      0.93       446
        1.0       0.26      0.11      0.16        54

avg / total       0.83      0.87      0.85       500

[[429  17]
 [ 48   6]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.68      0.80       468
        1.0       0.12      0.68      0.21        31

avg / total       0.92      0.68      0.77       499

[[320 148]
 [ 10  21]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.97      0.97       484
        1.0       0.06      0.06      0.06        16

avg / total       0.94      0.94      0.94       500

[[469  15]
 [ 15   1]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.98      0.92       422
        1.0       0.58      0.18      0.27        78

avg / total       0.82      0.85      0.82       500

[[412  10]
 [ 64  14]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.61      0.75       446
        1.0       0.21      0.85      0.33        54

avg / total       0.89      0.63      0.70       500

[[271 175]
 [  8  46]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.81      0.88       458
        1.0       0.22      0.60      0.32        42

avg / total       0.89      0.79      0.83       500

[[371  87]
 [ 17  25]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.95      0.94       458
        1.0       0.34      0.26      0.30        42

avg / total       0.88      0.90      0.89       500

[[437  21]
 [ 31  11]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.87      0.90       446
        1.0       0.30      0.48      0.37        54

avg / total       0.86      0.82      0.84       500

[[386  60]
 [ 28  26]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.97      0.96       468
        1.0       0.25      0.13      0.17        31

avg / total       0.90      0.92      0.91       499

[[456  12]
 [ 27   4]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.80      0.88       484
        1.0       0.11      0.75      0.19        16

avg / total       0.96      0.79      0.86       500

[[385  99]
 [  4  12]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.50      0.64       422
        1.0       0.17      0.55      0.26        78

avg / total       0.75      0.51      0.58       500

[[213 209]
 [ 35  43]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.76      0.85       458
        1.0       0.20      0.67      0.31        42

avg / total       0.90      0.75      0.81       500

[[349 109]
 [ 14  28]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.56      0.71       446
        1.0       0.20      0.89      0.32        54

avg / total       0.89      0.59      0.67       500

[[249 197]
 [  6  48]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.59      0.74       468
        1.0       0.12      0.81      0.20        31

avg / total       0.93      0.61      0.70       499

[[277 191]
 [  6  25]]
Best parameters set found on development set:

{'C': 16384.0, 'eta': 0.875}

Grid scores on development set:

0.231 (+/-0.189) for {'C': 256.0, 'eta': 0.375}
0.266 (+/-0.157) for {'C': 16384.0, 'eta': 0.625}
0.254 (+/-0.182) for {'C': 4096.0, 'eta': 0.625}
0.205 (+/-0.223) for {'C': 64.0, 'eta': 0.375}
0.266 (+/-0.196) for {'C': 512.0, 'eta': 0.375}
0.094 (+/-0.137) for {'C': 1024.0, 'eta': 0.0}
0.135 (+/-0.153) for {'C': 8192.0, 'eta': 0.0}
0.271 (+/-0.118) for {'C': 16384.0, 'eta': 0.875}
0.235 (+/-0.215) for {'C': 4096.0, 'eta': 0.25}
0.257 (+/-0.109) for {'C': 32768.0, 'eta': 1.0}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.97      0.49      0.65       676
        1.0       0.23      0.91      0.37       114

avg / total       0.86      0.55      0.61       790


Time elapsed: 24113.10 seconds.
Confusion matrix on the test data:
[[329 347]
 [ 10 104]]
Precision on the test data: 23.06%
Recall on the test data: 91.23%
F1 Score on the test data: 36.81%

Saving results to eval8/res/lopo_p0_m500_b20_i1.pickle ...
