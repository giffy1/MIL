
---------------------------------------------------------




Number of bags : 441    Number of single instances: 625

2016-04-28 14:18:03




---------------------------------------------------------

sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.78      0.87       120
        1.0       0.10      0.60      0.18         5

avg / total       0.94      0.78      0.84       125

[[94 26]
 [ 2  3]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.56      0.71       113
        1.0       0.17      0.83      0.28        12

avg / total       0.89      0.58      0.67       125

[[63 50]
 [ 2 10]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.46      0.59       106
        1.0       0.14      0.47      0.21        19

avg / total       0.72      0.46      0.54       125

[[49 57]
 [10  9]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.79      0.88       117
        1.0       0.24      1.00      0.39         8

avg / total       0.95      0.80      0.85       125

[[92 25]
 [ 0  8]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.63      0.75       116
        1.0       0.09      0.44      0.14         9

avg / total       0.87      0.62      0.71       125

[[73 43]
 [ 5  4]]
sbMIL(C=2048.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.84      0.91       120
        1.0       0.14      0.60      0.22         5

avg / total       0.95      0.83      0.88       125

[[101  19]
 [  2   3]]
sbMIL(C=2048.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.66      0.74       106
        1.0       0.16      0.37      0.23        19

avg / total       0.75      0.62      0.67       125

[[70 36]
 [12  7]]
sbMIL(C=2048.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.82      0.89       117
        1.0       0.22      0.75      0.34         8

avg / total       0.93      0.82      0.86       125

[[96 21]
 [ 2  6]]
sbMIL(C=2048.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.65      0.77       113
        1.0       0.18      0.75      0.30        12

avg / total       0.89      0.66      0.73       125

[[73 40]
 [ 3  9]]
sbMIL(C=2048.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       116
        1.0       0.17      0.44      0.25         9

avg / total       0.90      0.81      0.84       125

[[97 19]
 [ 5  4]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.94      0.95       120
        1.0       0.12      0.20      0.15         5

avg / total       0.93      0.91      0.92       125

[[113   7]
 [  4   1]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.92      0.89       106
        1.0       0.20      0.11      0.14        19

avg / total       0.75      0.80      0.77       125

[[98  8]
 [17  2]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.83      0.87       113
        1.0       0.14      0.25      0.18        12

avg / total       0.84      0.78      0.80       125

[[94 19]
 [ 9  3]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.95      0.95       117
        1.0       0.33      0.38      0.35         8

avg / total       0.92      0.91      0.91       125

[[111   6]
 [  5   3]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.96       120
        1.0       0.17      0.20      0.18         5

avg / total       0.93      0.93      0.93       125

[[115   5]
 [  4   1]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.96      0.94       116
        1.0       0.17      0.11      0.13         9

avg / total       0.88      0.90      0.89       125

[[111   5]
 [  8   1]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.96       117
        1.0       0.44      0.50      0.47         8

avg / total       0.93      0.93      0.93       125

[[112   5]
 [  4   4]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.93      0.90       106
        1.0       0.30      0.16      0.21        19

avg / total       0.78      0.82      0.79       125

[[99  7]
 [16  3]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.87      0.89       113
        1.0       0.17      0.25      0.20        12

avg / total       0.84      0.81      0.82       125

[[98 15]
 [ 9  3]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.78      0.87       120
        1.0       0.13      0.80      0.22         5

avg / total       0.95      0.78      0.84       125

[[93 27]
 [ 1  4]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.56      0.67       106
        1.0       0.16      0.47      0.24        19

avg / total       0.75      0.54      0.61       125

[[59 47]
 [10  9]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.55      0.70       113
        1.0       0.16      0.83      0.27        12

avg / total       0.89      0.58      0.66       125

[[62 51]
 [ 2 10]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.77      0.87       117
        1.0       0.21      0.88      0.33         8

avg / total       0.94      0.78      0.83       125

[[90 27]
 [ 1  7]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.96      0.94       116
        1.0       0.17      0.11      0.13         9

avg / total       0.88      0.90      0.89       125

[[111   5]
 [  8   1]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.64      0.76       116
        1.0       0.11      0.56      0.18         9

avg / total       0.89      0.63      0.72       125

[[74 42]
 [ 4  5]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.88      0.92       120
        1.0       0.07      0.20      0.10         5

avg / total       0.93      0.86      0.89       125

[[106  14]
 [  4   1]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.83      0.87       113
        1.0       0.14      0.25      0.18        12

avg / total       0.84      0.78      0.80       125

[[94 19]
 [ 9  3]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.90      0.88       106
        1.0       0.27      0.21      0.24        19

avg / total       0.77      0.79      0.78       125

[[95 11]
 [15  4]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.85      0.90       117
        1.0       0.22      0.62      0.32         8

avg / total       0.92      0.83      0.87       125

[[99 18]
 [ 3  5]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.96      0.94       116
        1.0       0.17      0.11      0.13         9

avg / total       0.88      0.90      0.89       125

[[111   5]
 [  8   1]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.92      0.94       120
        1.0       0.09      0.20      0.13         5

avg / total       0.93      0.89      0.91       125

[[110  10]
 [  4   1]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       120
        1.0       0.00      0.00      0.00         5

avg / total       0.92      0.96      0.94       125

[[120   0]
 [  5   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       113
        1.0       0.00      0.00      0.00        12

avg / total       0.82      0.90      0.86       125

[[113   0]
 [ 12   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       117
        1.0       0.00      0.00      0.00         8

avg / total       0.88      0.94      0.91       125

[[117   0]
 [  8   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       116
        1.0       0.00      0.00      0.00         9

avg / total       0.86      0.92      0.89       125

[[115   1]
 [  9   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       106
        1.0       0.00      0.00      0.00        19

avg / total       0.72      0.85      0.78       125

[[106   0]
 [ 19   0]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.87      0.87       106
        1.0       0.26      0.26      0.26        19

avg / total       0.78      0.78      0.78       125

[[92 14]
 [14  5]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.90      0.93       117
        1.0       0.29      0.62      0.40         8

avg / total       0.93      0.88      0.90       125

[[105  12]
 [  3   5]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.75      0.83       113
        1.0       0.12      0.33      0.18        12

avg / total       0.84      0.71      0.76       125

[[85 28]
 [ 8  4]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.91      0.92       116
        1.0       0.09      0.11      0.10         9

avg / total       0.87      0.86      0.86       125

[[106  10]
 [  8   1]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.98      0.97       120
        1.0       0.00      0.00      0.00         5

avg / total       0.92      0.94      0.93       125

[[118   2]
 [  5   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.97      0.96       117
        1.0       0.40      0.25      0.31         8

avg / total       0.91      0.93      0.92       125

[[114   3]
 [  6   2]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.93      0.92       113
        1.0       0.11      0.08      0.10        12

avg / total       0.83      0.85      0.84       125

[[105   8]
 [ 11   1]]
sbMIL(C=128.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.96       120
        1.0       0.17      0.20      0.18         5

avg / total       0.93      0.93      0.93       125

[[115   5]
 [  4   1]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.99      0.91       106
        1.0       0.00      0.00      0.00        19

avg / total       0.72      0.84      0.77       125

[[105   1]
 [ 19   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.98      0.95       116
        1.0       0.00      0.00      0.00         9

avg / total       0.86      0.91      0.89       125

[[114   2]
 [  9   0]]
sbMIL(C=128.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.94      0.90       106
        1.0       0.33      0.16      0.21        19

avg / total       0.78      0.82      0.80       125

[[100   6]
 [ 16   3]]
sbMIL(C=128.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.97      0.96       117
        1.0       0.40      0.25      0.31         8

avg / total       0.91      0.93      0.92       125

[[114   3]
 [  6   2]]
sbMIL(C=128.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.98      0.94       113
        1.0       0.00      0.00      0.00        12

avg / total       0.82      0.89      0.85       125

[[111   2]
 [ 12   0]]
sbMIL(C=128.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.95      0.94       116
        1.0       0.00      0.00      0.00         9

avg / total       0.86      0.88      0.87       125

[[110   6]
 [  9   0]]
Best parameters set found on development set:

{'C': 2048.0, 'eta': 0.625}

Grid scores on development set:

0.240 (+/-0.175) for {'C': 64.0, 'eta': 0.875}
0.267 (+/-0.092) for {'C': 2048.0, 'eta': 0.625}
0.191 (+/-0.165) for {'C': 16384.0, 'eta': 0.25}
0.239 (+/-0.238) for {'C': 4096.0, 'eta': 0.25}
0.250 (+/-0.104) for {'C': 4096.0, 'eta': 0.875}
0.194 (+/-0.158) for {'C': 65536.0, 'eta': 0.25}
0.000 (+/-0.000) for {'C': 32.0, 'eta': 0.0}
0.214 (+/-0.217) for {'C': 4096.0, 'eta': 0.375}
0.081 (+/-0.239) for {'C': 1024.0, 'eta': 0.125}
0.141 (+/-0.244) for {'C': 128.0, 'eta': 0.25}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.96      0.62      0.75       676
        1.0       0.27      0.84      0.41       114

avg / total       0.86      0.65      0.70       790


Time elapsed: 8727.29 seconds.
Confusion matrix on the test data:
[[418 258]
 [ 18  96]]
Precision on the test data: 27.12%
Recall on the test data: 84.21%
F1 Score on the test data: 41.03%

Saving results to eval8/res/lopo_p0_m125_b20_i1.pickle ...
