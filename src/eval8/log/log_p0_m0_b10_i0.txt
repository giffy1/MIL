
---------------------------------------------------------




Number of bags : 877    Number of single instances: 0

2016-04-28 11:04:24




---------------------------------------------------------

sbMIL(C=4096.0, class_weight={1: 0.825, -1: 0.175}, eta=1.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.62      0.75       106
        1.0       0.62      0.96      0.75        69

avg / total       0.82      0.75      0.75       175

[[66 40]
 [ 3 66]]
sbMIL(C=256.0, class_weight={1: 0.975, -1: 0.025}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=4096.0, class_weight={1: 0.825, -1: 0.175}, eta=1.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.23      0.38       107
        1.0       0.46      1.00      0.63        69

avg / total       0.79      0.53      0.48       176

[[25 82]
 [ 0 69]]
sbMIL(C=4096.0, class_weight={1: 0.825, -1: 0.175}, eta=1.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.25      0.41       106
        1.0       0.47      1.00      0.64        69

avg / total       0.79      0.55      0.50       175

[[27 79]
 [ 0 69]]
sbMIL(C=4096.0, class_weight={1: 0.825, -1: 0.175}, eta=1.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.51      0.67       106
        1.0       0.57      1.00      0.73        69

avg / total       0.83      0.70      0.70       175

[[54 52]
 [ 0 69]]
sbMIL(C=4096.0, class_weight={1: 0.825, -1: 0.175}, eta=1.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.30      0.46       107
        1.0       0.48      1.00      0.65        69

avg / total       0.80      0.57      0.53       176

[[32 75]
 [ 0 69]]
sbMIL(C=128.0, class_weight={1: 0.875, -1: 0.125}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.60      0.92      0.72       107
        1.0       0.25      0.04      0.07        69

avg / total       0.46      0.57      0.47       176

[[98  9]
 [66  3]]
sbMIL(C=128.0, class_weight={1: 0.875, -1: 0.125}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.62      0.72       107
        1.0       0.59      0.86      0.70        69

avg / total       0.76      0.71      0.71       176

[[66 41]
 [10 59]]
sbMIL(C=256.0, class_weight={1: 0.975, -1: 0.025}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      0.99      0.76       107
        1.0       0.67      0.03      0.06        69

avg / total       0.63      0.61      0.48       176

[[106   1]
 [ 67   2]]
sbMIL(C=256.0, class_weight={1: 0.975, -1: 0.025}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.70      0.93      0.80       106
        1.0       0.79      0.38      0.51        69

avg / total       0.73      0.71      0.68       175

[[99  7]
 [43 26]]
sbMIL(C=256.0, class_weight={1: 0.975, -1: 0.025}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.63      0.98      0.77       106
        1.0       0.82      0.13      0.23        69

avg / total       0.71      0.65      0.56       175

[[104   2]
 [ 60   9]]
sbMIL(C=256.0, class_weight={1: 0.975, -1: 0.025}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.76      0.89      0.82       106
        1.0       0.77      0.58      0.66        69

avg / total       0.77      0.77      0.76       175

[[94 12]
 [29 40]]
sbMIL(C=128.0, class_weight={1: 0.875, -1: 0.125}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.54      0.66       106
        1.0       0.55      0.86      0.67        69

avg / total       0.73      0.66      0.66       175

[[57 49]
 [10 59]]
sbMIL(C=128.0, class_weight={1: 0.875, -1: 0.125}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.65      0.75       106
        1.0       0.62      0.88      0.73        69

avg / total       0.79      0.74      0.74       175

[[69 37]
 [ 8 61]]
sbMIL(C=128.0, class_weight={1: 0.875, -1: 0.125}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.66      0.77       106
        1.0       0.63      0.90      0.74        69

avg / total       0.80      0.75      0.76       175

[[70 36]
 [ 7 62]]
sbMIL(C=8192.0, class_weight={1: 0.95, -1: 0.05}, eta=0.25, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.77      0.64      0.70       107
        1.0       0.56      0.71      0.62        69

avg / total       0.69      0.66      0.67       176

[[68 39]
 [20 49]]
sbMIL(C=8192.0, class_weight={1: 0.95, -1: 0.05}, eta=0.25, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.81      0.82       107
        1.0       0.72      0.74      0.73        69

avg / total       0.79      0.78      0.78       176

[[87 20]
 [18 51]]
sbMIL(C=8192.0, class_weight={1: 0.95, -1: 0.05}, eta=0.25, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.77      0.80      0.78       106
        1.0       0.67      0.62      0.65        69

avg / total       0.73      0.73      0.73       175

[[85 21]
 [26 43]]
sbMIL(C=8192.0, class_weight={1: 0.95, -1: 0.05}, eta=0.25, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.75      0.80       106
        1.0       0.68      0.78      0.72        69

avg / total       0.78      0.77      0.77       175

[[80 26]
 [15 54]]
sbMIL(C=1024.0, class_weight={1: 0.825, -1: 0.175}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.45      0.61       107
        1.0       0.53      0.96      0.68        69

avg / total       0.78      0.65      0.64       176

[[48 59]
 [ 3 66]]
sbMIL(C=1024.0, class_weight={1: 0.825, -1: 0.175}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.54      0.69       107
        1.0       0.57      0.96      0.72        69

avg / total       0.80      0.70      0.70       176

[[58 49]
 [ 3 66]]
sbMIL(C=8192.0, class_weight={1: 0.95, -1: 0.05}, eta=0.25, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.79      0.82       106
        1.0       0.71      0.80      0.75        69

avg / total       0.80      0.79      0.80       175

[[84 22]
 [14 55]]
sbMIL(C=1024.0, class_weight={1: 0.825, -1: 0.175}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.57      0.71       106
        1.0       0.59      0.94      0.72        69

avg / total       0.80      0.71      0.71       175

[[60 46]
 [ 4 65]]
sbMIL(C=1024.0, class_weight={1: 0.825, -1: 0.175}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.70      0.81       106
        1.0       0.68      0.97      0.80        69

avg / total       0.86      0.81      0.81       175

[[74 32]
 [ 2 67]]
sbMIL(C=1024.0, class_weight={1: 0.825, -1: 0.175}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.67      0.76       106
        1.0       0.63      0.87      0.73        69

avg / total       0.79      0.75      0.75       175

[[71 35]
 [ 9 60]]
sbMIL(C=128.0, class_weight={1: 0.9, -1: 0.1}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.64      0.73       107
        1.0       0.60      0.83      0.70        69

avg / total       0.75      0.72      0.72       176

[[69 38]
 [12 57]]
sbMIL(C=128.0, class_weight={1: 0.9, -1: 0.1}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=128.0, class_weight={1: 0.9, -1: 0.1}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.56      0.67       106
        1.0       0.55      0.84      0.67        69

avg / total       0.73      0.67      0.67       175

[[59 47]
 [11 58]]
sbMIL(C=128.0, class_weight={1: 0.9, -1: 0.1}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.70      0.78       106
        1.0       0.65      0.87      0.75        69

avg / total       0.80      0.77      0.77       175

[[74 32]
 [ 9 60]]
sbMIL(C=128.0, class_weight={1: 0.9, -1: 0.1}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.66      0.76       106
        1.0       0.63      0.88      0.73        69

avg / total       0.79      0.75      0.75       175

[[70 36]
 [ 8 61]]
sbMIL(C=32768.0, class_weight={1: 0.85, -1: 0.15}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.36      0.53       107
        1.0       0.50      0.97      0.66        69

avg / total       0.77      0.60      0.58       176

[[39 68]
 [ 2 67]]
sbMIL(C=32768.0, class_weight={1: 0.85, -1: 0.15}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.55      0.70       107
        1.0       0.58      0.96      0.72        69

avg / total       0.81      0.71      0.71       176

[[59 48]
 [ 3 66]]
sbMIL(C=32768.0, class_weight={1: 0.85, -1: 0.15}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.64      0.76       106
        1.0       0.62      0.91      0.74        69

avg / total       0.80      0.75      0.75       175

[[68 38]
 [ 6 63]]
sbMIL(C=32768.0, class_weight={1: 0.85, -1: 0.15}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.61      0.76       106
        1.0       0.62      0.99      0.76        69

avg / total       0.84      0.76      0.76       175

[[65 41]
 [ 1 68]]
sbMIL(C=16384.0, class_weight={1: 0.99, -1: 0.01}, eta=1.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=32768.0, class_weight={1: 0.85, -1: 0.15}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.62      0.73       106
        1.0       0.60      0.87      0.71        69

avg / total       0.77      0.72      0.72       175

[[66 40]
 [ 9 60]]

---------------------------------------------------------




Number of bags : 877    Number of single instances: 0

2016-04-28 12:17:49




---------------------------------------------------------

sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.46      0.60       107
        1.0       0.51      0.88      0.65        69

avg / total       0.72      0.62      0.62       176

[[49 58]
 [ 8 61]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.74      0.93      0.83       106
        1.0       0.83      0.51      0.63        69

avg / total       0.78      0.77      0.75       175

[[99  7]
 [34 35]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.63      0.98      0.77       106
        1.0       0.80      0.12      0.20        69

avg / total       0.70      0.64      0.54       175

[[104   2]
 [ 61   8]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=512.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.67      0.96      0.79       106
        1.0       0.82      0.26      0.40        69

avg / total       0.73      0.69      0.63       175

[[102   4]
 [ 51  18]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.54      0.67       107
        1.0       0.55      0.87      0.67        69

avg / total       0.74      0.67      0.67       176

[[58 49]
 [ 9 60]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.53      0.69       106
        1.0       0.58      0.99      0.73        69

avg / total       0.82      0.71      0.70       175

[[56 50]
 [ 1 68]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.47      0.62       107
        1.0       0.53      0.94      0.68        69

avg / total       0.77      0.65      0.64       176

[[50 57]
 [ 4 65]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.62      0.75       106
        1.0       0.62      0.96      0.75        69

avg / total       0.82      0.75      0.75       175

[[66 40]
 [ 3 66]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.68      0.78       107
        1.0       0.65      0.91      0.76        69

avg / total       0.82      0.77      0.77       176

[[73 34]
 [ 6 63]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.68      0.79       106
        1.0       0.66      0.94      0.77        69

avg / total       0.83      0.78      0.78       175

[[72 34]
 [ 4 65]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.61      0.72       106
        1.0       0.59      0.87      0.71        69

avg / total       0.77      0.71      0.72       175

[[65 41]
 [ 9 60]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.71      0.81       106
        1.0       0.68      0.94      0.79        69

avg / total       0.84      0.80      0.80       175

[[75 31]
 [ 4 65]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.68      0.78       106
        1.0       0.65      0.90      0.75        69

avg / total       0.81      0.77      0.77       175

[[72 34]
 [ 7 62]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.34      0.50       107
        1.0       0.49      0.99      0.65        69

avg / total       0.78      0.59      0.56       176

[[36 71]
 [ 1 68]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.38      0.55       107
        1.0       0.51      0.99      0.67        69

avg / total       0.79      0.62      0.60       176

[[41 66]
 [ 1 68]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.41      0.58       106
        1.0       0.52      1.00      0.69        69

avg / total       0.81      0.64      0.62       175

[[43 63]
 [ 0 69]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.64      0.78       106
        1.0       0.64      0.99      0.78        69

avg / total       0.85      0.78      0.78       175

[[68 38]
 [ 1 68]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.61      0.73       106
        1.0       0.60      0.90      0.72        69

avg / total       0.78      0.73      0.73       175

[[65 41]
 [ 7 62]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.50      0.63       107
        1.0       0.52      0.84      0.64        69

avg / total       0.71      0.64      0.63       176

[[54 53]
 [11 58]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.51      0.67       106
        1.0       0.56      0.97      0.71        69

avg / total       0.81      0.69      0.68       175

[[54 52]
 [ 2 67]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.57      0.69       107
        1.0       0.56      0.86      0.68        69

avg / total       0.74      0.68      0.68       176

[[61 46]
 [10 59]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.60      0.75       106
        1.0       0.62      0.99      0.76        69

avg / total       0.84      0.75      0.75       175

[[64 42]
 [ 1 68]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.65      0.77       106
        1.0       0.64      0.94      0.76        69

avg / total       0.82      0.77      0.77       175

[[69 37]
 [ 4 65]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.63      0.72       107
        1.0       0.59      0.84      0.69        69

avg / total       0.75      0.71      0.71       176

[[67 40]
 [11 58]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.47      0.62       107
        1.0       0.53      0.94      0.68        69

avg / total       0.77      0.65      0.64       176

[[50 57]
 [ 4 65]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.55      0.67       106
        1.0       0.55      0.86      0.67        69

avg / total       0.73      0.67      0.67       175

[[58 48]
 [10 59]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.68      0.79       106
        1.0       0.65      0.93      0.77        69

avg / total       0.82      0.78      0.78       175

[[72 34]
 [ 5 64]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.67      0.78       106
        1.0       0.64      0.91      0.75        69

avg / total       0.81      0.77      0.77       175

[[71 35]
 [ 6 63]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.46      0.62       107
        1.0       0.53      0.96      0.68        69

avg / total       0.78      0.65      0.64       176

[[49 58]
 [ 3 66]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.68      0.76       106
        1.0       0.63      0.84      0.72        69

avg / total       0.77      0.74      0.75       175

[[72 34]
 [11 58]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.46      0.62       107
        1.0       0.54      0.97      0.69        69

avg / total       0.79      0.66      0.65       176

[[49 58]
 [ 2 67]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.61      0.74       107
        1.0       0.61      0.96      0.75        69

avg / total       0.82      0.74      0.74       176

[[65 42]
 [ 3 66]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.72      0.83       106
        1.0       0.69      0.97      0.81        69

avg / total       0.86      0.82      0.82       175

[[76 30]
 [ 2 67]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.60      0.72       106
        1.0       0.59      0.88      0.71        69

avg / total       0.77      0.71      0.72       175

[[64 42]
 [ 8 61]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.54      0.69       107
        1.0       0.57      0.96      0.72        69

avg / total       0.80      0.70      0.70       176

[[58 49]
 [ 3 66]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.71      0.82       106
        1.0       0.68      0.97      0.80        69

avg / total       0.86      0.81      0.81       175

[[75 31]
 [ 2 67]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.55      0.70       106
        1.0       0.58      0.97      0.73        69

avg / total       0.82      0.71      0.71       175

[[58 48]
 [ 2 67]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.66      0.76       106
        1.0       0.63      0.88      0.73        69

avg / total       0.79      0.75      0.75       175

[[70 36]
 [ 8 61]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.46      0.62       107
        1.0       0.53      0.96      0.68        69

avg / total       0.78      0.65      0.64       176

[[49 58]
 [ 3 66]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.76       107
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       176

[[107   0]
 [ 69   0]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.75       106
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       175

[[106   0]
 [ 69   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.63      0.75       107
        1.0       0.62      0.94      0.75        69

avg / total       0.82      0.75      0.75       176

[[67 40]
 [ 4 65]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.63      0.98      0.76       106
        1.0       0.78      0.10      0.18        69

avg / total       0.69      0.63      0.53       175

[[104   2]
 [ 62   7]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      1.00      0.75       106
        1.0       0.00      0.00      0.00        69

avg / total       0.37      0.61      0.46       175

[[106   0]
 [ 69   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.64      0.74       106
        1.0       0.61      0.87      0.72        69

avg / total       0.78      0.73      0.73       175

[[68 38]
 [ 9 60]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.71      0.82       106
        1.0       0.68      0.96      0.80        69

avg / total       0.85      0.81      0.81       175

[[75 31]
 [ 3 66]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.70      0.79       106
        1.0       0.66      0.88      0.75        69

avg / total       0.81      0.77      0.77       175

[[74 32]
 [ 8 61]]
Best parameters set found on development set:

{'C': 1024.0, 'eta': 0.625}

Grid scores on development set:

0.245 (+/-0.484) for {'C': 512.0, 'eta': 0.0}
0.716 (+/-0.095) for {'C': 32.0, 'eta': 1.0}
0.737 (+/-0.077) for {'C': 512.0, 'eta': 0.625}
0.702 (+/-0.088) for {'C': 16384.0, 'eta': 0.875}
0.711 (+/-0.091) for {'C': 32.0, 'eta': 0.875}
0.713 (+/-0.079) for {'C': 128.0, 'eta': 0.625}
0.733 (+/-0.084) for {'C': 32768.0, 'eta': 0.625}
0.735 (+/-0.074) for {'C': 512.0, 'eta': 0.75}
0.036 (+/-0.144) for {'C': 32.0, 'eta': 0.125}
0.740 (+/-0.074) for {'C': 1024.0, 'eta': 0.625}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.88      0.63      0.73       676
        1.0       0.18      0.50      0.27       114

avg / total       0.78      0.61      0.67       790


Time elapsed: 6024.04 seconds.
Confusion matrix on the test data:
[[423 253]
 [ 57  57]]
Precision on the test data: 18.39%
Recall on the test data: 50.00%
F1 Score on the test data: 26.89%

Saving results to eval8/res/lopo_p0_m0_b10_i0.pickle ...
