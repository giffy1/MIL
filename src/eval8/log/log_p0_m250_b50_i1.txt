
---------------------------------------------------------




Number of bags : 181    Number of single instances: 1250

2016-04-28 21:32:27




---------------------------------------------------------

sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.78      0.87       241
        1.0       0.10      0.67      0.17         9

avg / total       0.95      0.77      0.84       250

[[187  54]
 [  3   6]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.45      0.60       214
        1.0       0.16      0.64      0.26        36

avg / total       0.78      0.48      0.55       250

[[ 97 117]
 [ 13  23]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.99      0.98       241
        1.0       0.00      0.00      0.00         9

avg / total       0.93      0.95      0.94       250

[[238   3]
 [  9   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.97      0.93       223
        1.0       0.14      0.04      0.06        27

avg / total       0.81      0.87      0.84       250

[[217   6]
 [ 26   1]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.92      0.89       250

[[230   2]
 [ 18   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       234
        1.0       0.33      0.06      0.11        16

avg / total       0.90      0.93      0.91       250

[[232   2]
 [ 15   1]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       214
        1.0       0.00      0.00      0.00        36

avg / total       0.73      0.86      0.79       250

[[214   0]
 [ 36   0]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.69      0.81       234
        1.0       0.13      0.69      0.22        16

avg / total       0.92      0.69      0.77       250

[[162  72]
 [  5  11]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.60      0.75       232
        1.0       0.14      0.83      0.24        18

avg / total       0.92      0.62      0.71       250

[[140  92]
 [  3  15]]
sbMIL(C=8192.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.55      0.71       223
        1.0       0.21      0.96      0.34        27

avg / total       0.91      0.60      0.67       250

[[123 100]
 [  1  26]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.86      0.91       241
        1.0       0.08      0.33      0.13         9

avg / total       0.94      0.84      0.89       250

[[208  33]
 [  6   3]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.71      0.79       214
        1.0       0.22      0.47      0.30        36

avg / total       0.79      0.68      0.72       250

[[153  61]
 [ 19  17]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.85      0.90       234
        1.0       0.19      0.50      0.28        16

avg / total       0.91      0.83      0.86       250

[[200  34]
 [  8   8]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.90      0.93       241
        1.0       0.04      0.11      0.06         9

avg / total       0.93      0.88      0.90       250

[[218  23]
 [  8   1]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.72      0.82       223
        1.0       0.23      0.70      0.35        27

avg / total       0.88      0.72      0.77       250

[[161  62]
 [  8  19]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.85      0.90       232
        1.0       0.15      0.33      0.21        18

avg / total       0.89      0.82      0.85       250

[[198  34]
 [ 12   6]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.82      0.85       214
        1.0       0.28      0.42      0.33        36

avg / total       0.80      0.76      0.78       250

[[175  39]
 [ 21  15]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.88      0.92       234
        1.0       0.23      0.50      0.31        16

avg / total       0.92      0.86      0.88       250

[[207  27]
 [  8   8]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.78      0.85       223
        1.0       0.25      0.59      0.35        27

avg / total       0.87      0.76      0.80       250

[[174  49]
 [ 11  16]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.90      0.92       232
        1.0       0.14      0.22      0.17        18

avg / total       0.88      0.85      0.86       250

[[208  24]
 [ 14   4]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.93      0.92       223
        1.0       0.21      0.15      0.17        27

avg / total       0.83      0.85      0.84       250

[[208  15]
 [ 23   4]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       241
        1.0       0.25      0.11      0.15         9

avg / total       0.94      0.96      0.95       250

[[238   3]
 [  8   1]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.96      0.96       234
        1.0       0.36      0.31      0.33        16

avg / total       0.92      0.92      0.92       250

[[225   9]
 [ 11   5]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.92      0.89       250

[[229   3]
 [ 18   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.95      0.96       241
        1.0       0.08      0.11      0.10         9

avg / total       0.93      0.92      0.93       250

[[230  11]
 [  8   1]]
sbMIL(C=2048.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      1.00      0.93       214
        1.0       0.75      0.08      0.15        36

avg / total       0.85      0.86      0.81       250

[[213   1]
 [ 33   3]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.92      0.94       234
        1.0       0.25      0.38      0.30        16

avg / total       0.91      0.89      0.90       250

[[216  18]
 [ 10   6]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.83      0.87       223
        1.0       0.24      0.44      0.31        27

avg / total       0.85      0.79      0.81       250

[[185  38]
 [ 15  12]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.95      0.92       214
        1.0       0.47      0.25      0.33        36

avg / total       0.82      0.85      0.83       250

[[204  10]
 [ 27   9]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.95      0.94       232
        1.0       0.08      0.06      0.06        18

avg / total       0.87      0.88      0.88       250

[[220  12]
 [ 17   1]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.72      0.83       241
        1.0       0.08      0.67      0.15         9

avg / total       0.95      0.72      0.81       250

[[174  67]
 [  3   6]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      1.00      0.98       241
        1.0       0.00      0.00      0.00         9

avg / total       0.93      0.96      0.95       250

[[241   0]
 [  9   0]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.82      0.32      0.46       214
        1.0       0.13      0.58      0.21        36

avg / total       0.72      0.36      0.43       250

[[ 69 145]
 [ 15  21]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.68      0.80       234
        1.0       0.14      0.75      0.24        16

avg / total       0.92      0.69      0.77       250

[[160  74]
 [  4  12]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      1.00      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.93      0.89       250

[[232   0]
 [ 18   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       234
        1.0       0.00      0.00      0.00        16

avg / total       0.88      0.94      0.91       250

[[234   0]
 [ 16   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       214
        1.0       0.00      0.00      0.00        36

avg / total       0.73      0.86      0.79       250

[[214   0]
 [ 36   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       223
        1.0       0.00      0.00      0.00        27

avg / total       0.80      0.89      0.84       250

[[222   1]
 [ 27   0]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.57      0.72       223
        1.0       0.21      0.93      0.34        27

avg / total       0.90      0.61      0.68       250

[[127  96]
 [  2  25]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.56      0.71       232
        1.0       0.15      1.00      0.26        18

avg / total       0.94      0.59      0.68       250

[[129 103]
 [  0  18]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.93      0.95       241
        1.0       0.11      0.22      0.14         9

avg / total       0.94      0.90      0.92       250

[[224  17]
 [  7   2]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.81      0.85       214
        1.0       0.25      0.39      0.31        36

avg / total       0.80      0.75      0.77       250

[[173  41]
 [ 22  14]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.91      0.93       234
        1.0       0.25      0.44      0.32        16

avg / total       0.91      0.88      0.89       250

[[213  21]
 [  9   7]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.80      0.86       223
        1.0       0.23      0.48      0.31        27

avg / total       0.85      0.77      0.80       250

[[179  44]
 [ 14  13]]
sbMIL(C=256.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.88      0.91       232
        1.0       0.10      0.17      0.12        18

avg / total       0.87      0.83      0.85       250

[[205  27]
 [ 15   3]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.70      0.78       214
        1.0       0.20      0.44      0.28        36

avg / total       0.78      0.66      0.71       250

[[150  64]
 [ 20  16]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       241
        1.0       0.11      0.44      0.18         9

avg / total       0.95      0.85      0.89       250

[[209  32]
 [  5   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.84      0.90       234
        1.0       0.20      0.56      0.29        16

avg / total       0.92      0.82      0.86       250

[[197  37]
 [  7   9]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.70      0.80       223
        1.0       0.21      0.67      0.32        27

avg / total       0.87      0.69      0.75       250

[[155  68]
 [  9  18]]
sbMIL(C=65536.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.60      0.74       232
        1.0       0.13      0.78      0.23        18

avg / total       0.91      0.62      0.71       250

[[140  92]
 [  4  14]]
Best parameters set found on development set:

{'C': 65536.0, 'eta': 0.5}

Grid scores on development set:

0.033 (+/-0.086) for {'C': 65536.0, 'eta': 0.0}
0.247 (+/-0.109) for {'C': 8192.0, 'eta': 0.875}
0.253 (+/-0.152) for {'C': 2048.0, 'eta': 0.5}
0.246 (+/-0.223) for {'C': 1024.0, 'eta': 0.375}
0.162 (+/-0.212) for {'C': 2048.0, 'eta': 0.125}
0.220 (+/-0.230) for {'C': 2048.0, 'eta': 0.25}
0.000 (+/-0.000) for {'C': 1024.0, 'eta': 0.0}
0.237 (+/-0.126) for {'C': 32.0, 'eta': 1.0}
0.241 (+/-0.175) for {'C': 256.0, 'eta': 0.375}
0.258 (+/-0.100) for {'C': 65536.0, 'eta': 0.5}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.99      0.39      0.56       676
        1.0       0.21      0.96      0.35       114

avg / total       0.87      0.48      0.53       790


Time elapsed: 9675.41 seconds.
Confusion matrix on the test data:
[[266 410]
 [  4 110]]
Precision on the test data: 21.15%
Recall on the test data: 96.49%
F1 Score on the test data: 34.70%

Saving results to eval8/res/lopo_p0_m250_b50_i1.pickle ...
