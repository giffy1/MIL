
---------------------------------------------------------




Number of bags : 51    Number of single instances: 2499

2016-04-29 10:47:28




---------------------------------------------------------


---------------------------------------------------------




Number of bags : 51    Number of single instances: 2499

2016-04-29 11:15:43




---------------------------------------------------------

sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       483
        1.0       0.15      0.53      0.23        17

avg / total       0.95      0.88      0.91       500

[[430  53]
 [  8   9]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.61      0.71       427
        1.0       0.15      0.41      0.22        73

avg / total       0.76      0.58      0.64       500

[[261 166]
 [ 43  30]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.86      0.90       452
        1.0       0.28      0.52      0.37        48

avg / total       0.88      0.83      0.85       500

[[389  63]
 [ 23  25]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.72      0.82       448
        1.0       0.20      0.62      0.31        52

avg / total       0.86      0.71      0.76       500

[[323 125]
 [ 20  32]]
sbMIL(C=64.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.77      0.84       468
        1.0       0.07      0.26      0.11        31

avg / total       0.89      0.74      0.80       499

[[359 109]
 [ 23   8]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.92       483
        1.0       0.11      0.41      0.17        17

avg / total       0.95      0.86      0.90       500

[[424  59]
 [ 10   7]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.68      0.78       427
        1.0       0.23      0.56      0.33        73

avg / total       0.80      0.67      0.71       500

[[292 135]
 [ 32  41]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.76      0.85       452
        1.0       0.23      0.67      0.34        48

avg / total       0.89      0.75      0.80       500

[[343 109]
 [ 16  32]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.69      0.80       448
        1.0       0.22      0.77      0.34        52

avg / total       0.89      0.69      0.75       500

[[307 141]
 [ 12  40]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.80      0.88       468
        1.0       0.16      0.58      0.26        31

avg / total       0.92      0.79      0.84       499

[[376  92]
 [ 13  18]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.96       483
        1.0       0.05      0.06      0.05        17

avg / total       0.94      0.93      0.93       500

[[464  19]
 [ 16   1]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.92      0.89       427
        1.0       0.25      0.16      0.20        73

avg / total       0.78      0.81      0.79       500

[[391  36]
 [ 61  12]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.96      0.94       452
        1.0       0.29      0.17      0.21        48

avg / total       0.85      0.88      0.87       500

[[432  20]
 [ 40   8]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.87      0.89       448
        1.0       0.21      0.31      0.25        52

avg / total       0.84      0.81      0.82       500

[[388  60]
 [ 36  16]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.93      0.94       468
        1.0       0.11      0.13      0.12        31

avg / total       0.89      0.88      0.89       499

[[437  31]
 [ 27   4]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.79      0.88       483
        1.0       0.11      0.71      0.18        17

avg / total       0.96      0.79      0.85       500

[[382 101]
 [  5  12]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.44      0.60       427
        1.0       0.19      0.75      0.30        73

avg / total       0.81      0.49      0.56       500

[[190 237]
 [ 18  55]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.52      0.68       452
        1.0       0.17      0.90      0.28        48

avg / total       0.90      0.56      0.64       500

[[235 217]
 [  5  43]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.51      0.67       448
        1.0       0.18      0.92      0.30        52

avg / total       0.90      0.55      0.63       500

[[227 221]
 [  4  48]]
sbMIL(C=1024.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.56      0.72       468
        1.0       0.11      0.81      0.19        31

avg / total       0.92      0.58      0.68       499

[[264 204]
 [  6  25]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.95      0.96       483
        1.0       0.21      0.41      0.28        17

avg / total       0.95      0.93      0.94       500

[[457  26]
 [ 10   7]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.76      0.81       427
        1.0       0.17      0.29      0.21        73

avg / total       0.76      0.69      0.72       500

[[323 104]
 [ 52  21]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.91      0.92       452
        1.0       0.32      0.40      0.36        48

avg / total       0.88      0.86      0.87       500

[[412  40]
 [ 29  19]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.81      0.87       448
        1.0       0.24      0.52      0.33        52

avg / total       0.86      0.78      0.81       500

[[364  84]
 [ 25  27]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.84      0.88       468
        1.0       0.04      0.10      0.05        31

avg / total       0.88      0.79      0.83       499

[[391  77]
 [ 28   3]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.75      0.85       483
        1.0       0.10      0.76      0.17        17

avg / total       0.96      0.75      0.83       500

[[361 122]
 [  4  13]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.32      0.47       427
        1.0       0.17      0.82      0.28        73

avg / total       0.81      0.39      0.45       500

[[137 290]
 [ 13  60]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.37      0.54       452
        1.0       0.14      1.00      0.25        48

avg / total       0.92      0.43      0.51       500

[[166 286]
 [  0  48]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.31      0.47       448
        1.0       0.14      0.94      0.24        52

avg / total       0.89      0.38      0.45       500

[[139 309]
 [  3  49]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.46      0.63       468
        1.0       0.11      1.00      0.20        31

avg / total       0.94      0.49      0.60       499

[[214 254]
 [  0  31]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.91      0.94       483
        1.0       0.08      0.24      0.12        17

avg / total       0.94      0.88      0.91       500

[[438  45]
 [ 13   4]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.81      0.84       427
        1.0       0.23      0.33      0.27        73

avg / total       0.78      0.74      0.76       500

[[345  82]
 [ 49  24]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.88      0.91       452
        1.0       0.29      0.48      0.37        48

avg / total       0.88      0.84      0.86       500

[[397  55]
 [ 25  23]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.77      0.85       448
        1.0       0.22      0.58      0.32        52

avg / total       0.87      0.75      0.79       500

[[344 104]
 [ 22  30]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.85      0.90       468
        1.0       0.12      0.29      0.17        31

avg / total       0.90      0.82      0.85       499

[[400  68]
 [ 22   9]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.92       483
        1.0       0.10      0.41      0.17        17

avg / total       0.95      0.86      0.90       500

[[423  60]
 [ 10   7]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.67      0.77       427
        1.0       0.22      0.55      0.32        73

avg / total       0.80      0.65      0.70       500

[[287 140]
 [ 33  40]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.73      0.83       452
        1.0       0.21      0.65      0.31        48

avg / total       0.88      0.73      0.78       500

[[332 120]
 [ 17  31]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.69      0.80       448
        1.0       0.22      0.77      0.34        52

avg / total       0.89      0.70      0.75       500

[[308 140]
 [ 12  40]]
sbMIL(C=32768.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.73      0.84       468
        1.0       0.14      0.68      0.24        31

avg / total       0.92      0.73      0.80       499

[[343 125]
 [ 10  21]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.46      0.63       483
        1.0       0.05      0.88      0.10        17

avg / total       0.96      0.48      0.61       500

[[223 260]
 [  2  15]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.10      0.19       427
        1.0       0.16      1.00      0.28        73

avg / total       0.88      0.23      0.20       500

[[ 44 383]
 [  0  73]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.13      0.24       452
        1.0       0.11      1.00      0.20        48

avg / total       0.91      0.22      0.23       500

[[ 61 391]
 [  0  48]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.17      0.29       448
        1.0       0.12      1.00      0.22        52

avg / total       0.91      0.26      0.28       500

[[ 76 372]
 [  0  52]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.18      0.30       468
        1.0       0.07      1.00      0.14        31

avg / total       0.94      0.23      0.29       499

[[ 83 385]
 [  0  31]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.83      0.90       483
        1.0       0.10      0.53      0.17        17

avg / total       0.95      0.82      0.88       500

[[403  80]
 [  8   9]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.52      0.66       427
        1.0       0.19      0.66      0.30        73

avg / total       0.80      0.54      0.61       500

[[224 203]
 [ 25  48]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.63      0.77       452
        1.0       0.20      0.85      0.32        48

avg / total       0.90      0.66      0.73       500

[[287 165]
 [  7  41]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.60      0.74       448
        1.0       0.20      0.88      0.33        52

avg / total       0.90      0.63      0.70       500

[[268 180]
 [  6  46]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.66      0.79       468
        1.0       0.13      0.77      0.23        31

avg / total       0.93      0.67      0.76       499

[[311 157]
 [  7  24]]
Best parameters set found on development set:

{'C': 1024.0, 'eta': 0.375}

Grid scores on development set:

0.247 (+/-0.175) for {'C': 64.0, 'eta': 0.375}
0.287 (+/-0.135) for {'C': 1024.0, 'eta': 0.375}
0.167 (+/-0.140) for {'C': 16384.0, 'eta': 0.125}
0.251 (+/-0.104) for {'C': 1024.0, 'eta': 0.625}
0.247 (+/-0.216) for {'C': 64.0, 'eta': 0.25}
0.228 (+/-0.080) for {'C': 512.0, 'eta': 0.75}
0.249 (+/-0.184) for {'C': 16384.0, 'eta': 0.25}
0.275 (+/-0.130) for {'C': 32768.0, 'eta': 0.375}
0.187 (+/-0.121) for {'C': 32768.0, 'eta': 0.875}
0.269 (+/-0.124) for {'C': 1024.0, 'eta': 0.5}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.94      0.55      0.69       676
        1.0       0.23      0.79      0.35       114

avg / total       0.84      0.58      0.64       790


Time elapsed: 45451.44 seconds.
Confusion matrix on the test data:
[[370 306]
 [ 24  90]]
Precision on the test data: 22.73%
Recall on the test data: 78.95%
F1 Score on the test data: 35.29%

Saving results to eval8/res/lopo_p0_m500_b200_i0.pickle ...
