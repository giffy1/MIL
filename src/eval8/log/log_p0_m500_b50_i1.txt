
---------------------------------------------------------




Number of bags : 181    Number of single instances: 2499

2016-04-29 07:32:28




---------------------------------------------------------

sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.83      0.89       458
        1.0       0.23      0.55      0.32        42

avg / total       0.89      0.81      0.84       500

[[380  78]
 [ 19  23]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.74      0.83       468
        1.0       0.09      0.42      0.15        31

avg / total       0.90      0.72      0.79       499

[[344 124]
 [ 18  13]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.86      0.92       484
        1.0       0.11      0.50      0.17        16

avg / total       0.95      0.85      0.89       500

[[416  68]
 [  8   8]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.63      0.77       446
        1.0       0.22      0.85      0.35        54

avg / total       0.89      0.66      0.72       500

[[282 164]
 [  8  46]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.86      0.91       484
        1.0       0.09      0.44      0.15        16

avg / total       0.95      0.84      0.89       500

[[414  70]
 [  9   7]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.69      0.77       422
        1.0       0.23      0.50      0.31        78

avg / total       0.78      0.66      0.70       500

[[290 132]
 [ 39  39]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.83      0.89       458
        1.0       0.25      0.62      0.35        42

avg / total       0.90      0.81      0.84       500

[[378  80]
 [ 16  26]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.79      0.88       484
        1.0       0.10      0.69      0.17        16

avg / total       0.96      0.78      0.85       500

[[381 103]
 [  5  11]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.74      0.83       468
        1.0       0.10      0.45      0.17        31

avg / total       0.90      0.72      0.79       499

[[346 122]
 [ 17  14]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.46      0.60       422
        1.0       0.16      0.56      0.25        78

avg / total       0.74      0.48      0.54       500

[[194 228]
 [ 34  44]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.65      0.78       446
        1.0       0.23      0.85      0.36        54

avg / total       0.89      0.67      0.73       500

[[288 158]
 [  8  46]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.68      0.76       422
        1.0       0.21      0.46      0.29        78

avg / total       0.77      0.64      0.69       500

[[286 136]
 [ 42  36]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.72      0.83       458
        1.0       0.19      0.69      0.29        42

avg / total       0.90      0.72      0.78       500

[[331 127]
 [ 13  29]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.56      0.71       446
        1.0       0.20      0.89      0.32        54

avg / total       0.89      0.60      0.67       500

[[250 196]
 [  6  48]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.98      0.97       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.95      0.94       500

[[475   9]
 [ 16   0]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.59      0.74       468
        1.0       0.13      0.90      0.22        31

avg / total       0.94      0.61      0.71       499

[[276 192]
 [  3  28]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.98      0.91       422
        1.0       0.53      0.12      0.19        78

avg / total       0.81      0.85      0.80       500

[[414   8]
 [ 69   9]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.97      0.95       458
        1.0       0.42      0.24      0.30        42

avg / total       0.89      0.91      0.90       500

[[444  14]
 [ 32  10]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.89      0.90       446
        1.0       0.20      0.22      0.21        54

avg / total       0.83      0.82      0.82       500

[[398  48]
 [ 42  12]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.46      0.60       422
        1.0       0.16      0.58      0.26        78

avg / total       0.75      0.48      0.54       500

[[194 228]
 [ 33  45]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.79      0.88       484
        1.0       0.10      0.75      0.18        16

avg / total       0.96      0.78      0.85       500

[[380 104]
 [  4  12]]
sbMIL(C=16384.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.97      0.96       468
        1.0       0.25      0.13      0.17        31

avg / total       0.90      0.92      0.91       499

[[456  12]
 [ 27   4]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.72      0.82       458
        1.0       0.18      0.67      0.28        42

avg / total       0.89      0.72      0.78       500

[[330 128]
 [ 14  28]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.56      0.71       446
        1.0       0.20      0.94      0.34        54

avg / total       0.90      0.60      0.67       500

[[248 198]
 [  3  51]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.59      0.74       468
        1.0       0.12      0.84      0.21        31

avg / total       0.93      0.61      0.71       499

[[277 191]
 [  5  26]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.80      0.84       422
        1.0       0.27      0.40      0.32        78

avg / total       0.78      0.74      0.76       500

[[339  83]
 [ 47  31]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       484
        1.0       0.11      0.44      0.18        16

avg / total       0.95      0.87      0.91       500

[[429  55]
 [  9   7]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.75      0.84       458
        1.0       0.20      0.67      0.30        42

avg / total       0.90      0.74      0.80       500

[[343 115]
 [ 14  28]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.68      0.79       446
        1.0       0.22      0.74      0.34        54

avg / total       0.88      0.69      0.74       500

[[303 143]
 [ 14  40]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.95      0.96       484
        1.0       0.04      0.06      0.05        16

avg / total       0.94      0.92      0.93       500

[[459  25]
 [ 15   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.96      0.91       422
        1.0       0.45      0.19      0.27        78

avg / total       0.80      0.84      0.81       500

[[404  18]
 [ 63  15]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.80      0.86       446
        1.0       0.24      0.52      0.33        54

avg / total       0.86      0.77      0.80       500

[[357  89]
 [ 26  28]]

---------------------------------------------------------




Number of bags : 181    Number of single instances: 2499

2016-04-29 11:07:28




---------------------------------------------------------

sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.96      0.95       500

[[482   2]
 [ 16   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      1.00      0.92       422
        1.0       0.00      0.00      0.00        78

avg / total       0.71      0.84      0.77       500

[[422   0]
 [ 78   0]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       458
        1.0       0.50      0.14      0.22        42

avg / total       0.89      0.92      0.89       500

[[452   6]
 [ 36   6]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.91      0.91       446
        1.0       0.20      0.19      0.19        54

avg / total       0.83      0.83      0.83       500

[[407  39]
 [ 44  10]]
sbMIL(C=1024.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.91      0.94       484
        1.0       0.06      0.19      0.09        16

avg / total       0.94      0.88      0.91       500

[[439  45]
 [ 13   3]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.91      0.89       422
        1.0       0.32      0.24      0.28        78

avg / total       0.78      0.80      0.79       500

[[382  40]
 [ 59  19]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.88      0.91       458
        1.0       0.25      0.45      0.32        42

avg / total       0.89      0.84      0.86       500

[[401  57]
 [ 23  19]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.74      0.83       446
        1.0       0.24      0.67      0.35        54

avg / total       0.87      0.73      0.78       500

[[331 115]
 [ 18  36]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.91      0.93       468
        1.0       0.14      0.23      0.17        31

avg / total       0.90      0.86      0.88       499

[[424  44]
 [ 24   7]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.86      0.92       484
        1.0       0.11      0.50      0.18        16

avg / total       0.95      0.85      0.89       500

[[417  67]
 [  8   8]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.64      0.74       422
        1.0       0.21      0.51      0.30        78

avg / total       0.77      0.62      0.67       500

[[269 153]
 [ 38  40]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.82      0.88       458
        1.0       0.23      0.57      0.33        42

avg / total       0.89      0.80      0.84       500

[[377  81]
 [ 18  24]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.63      0.76       446
        1.0       0.22      0.85      0.34        54

avg / total       0.89      0.65      0.72       500

[[279 167]
 [  8  46]]
sbMIL(C=32768.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.70      0.81       468
        1.0       0.12      0.61      0.20        31

avg / total       0.91      0.70      0.77       499

[[328 140]
 [ 12  19]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[483   1]
 [ 16   0]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.97      0.90       422
        1.0       0.07      0.01      0.02        78

avg / total       0.72      0.82      0.76       500

[[409  13]
 [ 77   1]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.98      0.95       458
        1.0       0.00      0.00      0.00        42

avg / total       0.84      0.90      0.87       500

[[449   9]
 [ 42   0]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.96      0.93       446
        1.0       0.19      0.07      0.11        54

avg / total       0.82      0.87      0.84       500

[[429  17]
 [ 50   4]]
sbMIL(C=32.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.94      0.93       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.88      0.88       499

[[438  30]
 [ 31   0]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.79      0.88       484
        1.0       0.10      0.69      0.17        16

avg / total       0.96      0.78      0.85       500

[[381 103]
 [  5  11]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.46      0.60       422
        1.0       0.16      0.56      0.25        78

avg / total       0.74      0.48      0.54       500

[[194 228]
 [ 34  44]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.72      0.83       458
        1.0       0.19      0.69      0.29        42

avg / total       0.90      0.72      0.78       500

[[331 127]
 [ 13  29]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.56      0.71       446
        1.0       0.20      0.89      0.32        54

avg / total       0.89      0.60      0.67       500

[[250 196]
 [  6  48]]
sbMIL(C=65536.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.59      0.74       468
        1.0       0.13      0.90      0.22        31

avg / total       0.94      0.61      0.71       499

[[276 192]
 [  3  28]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.97      0.97       484
        1.0       0.13      0.12      0.13        16

avg / total       0.94      0.95      0.95       500

[[471  13]
 [ 14   2]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.89      0.87       422
        1.0       0.18      0.13      0.15        78

avg / total       0.74      0.77      0.76       500

[[377  45]
 [ 68  10]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.95      0.94       458
        1.0       0.25      0.17      0.20        42

avg / total       0.87      0.89      0.88       500

[[437  21]
 [ 35   7]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.89      0.90       446
        1.0       0.27      0.31      0.29        54

avg / total       0.84      0.83      0.84       500

[[399  47]
 [ 37  17]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.89      0.91       468
        1.0       0.00      0.00      0.00        31

avg / total       0.87      0.84      0.85       499

[[417  51]
 [ 31   0]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.77      0.87       484
        1.0       0.09      0.69      0.16        16

avg / total       0.96      0.77      0.85       500

[[375 109]
 [  5  11]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.81      0.36      0.50       422
        1.0       0.13      0.53      0.21        78

avg / total       0.70      0.39      0.45       500

[[153 269]
 [ 37  41]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.73      0.83       458
        1.0       0.18      0.67      0.29        42

avg / total       0.89      0.72      0.78       500

[[333 125]
 [ 14  28]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.58      0.72       446
        1.0       0.20      0.87      0.32        54

avg / total       0.89      0.61      0.68       500

[[257 189]
 [  7  47]]
sbMIL(C=256.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.59      0.74       468
        1.0       0.14      1.00      0.24        31

avg / total       0.95      0.61      0.71       499

[[275 193]
 [  0  31]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.98      0.97       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.95      0.94       500

[[475   9]
 [ 16   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.98      0.91       422
        1.0       0.44      0.10      0.17        78

avg / total       0.79      0.84      0.80       500

[[412  10]
 [ 70   8]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.97      0.95       458
        1.0       0.36      0.21      0.27        42

avg / total       0.88      0.90      0.89       500

[[442  16]
 [ 33   9]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.87      0.89       446
        1.0       0.21      0.28      0.24        54

avg / total       0.83      0.81      0.82       500

[[390  56]
 [ 39  15]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.97      0.96       468
        1.0       0.24      0.13      0.17        31

avg / total       0.90      0.92      0.91       499

[[455  13]
 [ 27   4]]
sbMIL(C=4096.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.93       484
        1.0       0.11      0.44      0.17        16

avg / total       0.95      0.87      0.90       500

[[427  57]
 [  9   7]]
sbMIL(C=4096.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.79      0.83       422
        1.0       0.27      0.41      0.32        78

avg / total       0.78      0.73      0.75       500

[[335  87]
 [ 46  32]]
sbMIL(C=4096.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.85      0.90       458
        1.0       0.23      0.50      0.32        42

avg / total       0.89      0.82      0.85       500

[[389  69]
 [ 21  21]]
sbMIL(C=4096.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.69      0.80       446
        1.0       0.22      0.72      0.34        54

avg / total       0.87      0.70      0.75       500

[[309 137]
 [ 15  39]]
sbMIL(C=4096.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.86      0.91       468
        1.0       0.15      0.35      0.21        31

avg / total       0.90      0.83      0.86       499

[[404  64]
 [ 20  11]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.93       484
        1.0       0.11      0.44      0.17        16

avg / total       0.95      0.87      0.90       500

[[426  58]
 [  9   7]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.62      0.73       422
        1.0       0.19      0.49      0.28        78

avg / total       0.76      0.60      0.66       500

[[263 159]
 [ 40  38]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.85      0.89       458
        1.0       0.22      0.45      0.29        42

avg / total       0.88      0.82      0.84       500

[[389  69]
 [ 23  19]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.69      0.79       446
        1.0       0.20      0.67      0.31        54

avg / total       0.86      0.68      0.74       500

[[306 140]
 [ 18  36]]
sbMIL(C=64.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.76      0.84       468
        1.0       0.07      0.26      0.11        31

avg / total       0.88      0.73      0.79       499

[[355 113]
 [ 23   8]]
Best parameters set found on development set:

{'C': 4096.0, 'eta': 0.5}

Grid scores on development set:

0.083 (+/-0.205) for {'C': 1024.0, 'eta': 0.125}
0.243 (+/-0.193) for {'C': 8192.0, 'eta': 0.375}
0.268 (+/-0.136) for {'C': 32768.0, 'eta': 0.625}
0.026 (+/-0.083) for {'C': 32.0, 'eta': 0.125}
0.252 (+/-0.107) for {'C': 65536.0, 'eta': 1.0}
0.154 (+/-0.189) for {'C': 64.0, 'eta': 0.25}
0.246 (+/-0.114) for {'C': 256.0, 'eta': 1.0}
0.168 (+/-0.187) for {'C': 32768.0, 'eta': 0.125}
0.273 (+/-0.136) for {'C': 4096.0, 'eta': 0.5}
0.232 (+/-0.159) for {'C': 64.0, 'eta': 0.625}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.92      0.63      0.75       676
        1.0       0.24      0.68      0.36       114

avg / total       0.82      0.64      0.69       790


Time elapsed: 45026.26 seconds.
Confusion matrix on the test data:
[[429 247]
 [ 36  78]]
Precision on the test data: 24.00%
Recall on the test data: 68.42%
F1 Score on the test data: 35.54%

Saving results to eval8/res/lopo_p0_m500_b50_i1.pickle ...
