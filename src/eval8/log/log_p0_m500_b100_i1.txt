
---------------------------------------------------------




Number of bags : 93    Number of single instances: 2499

2016-04-29 08:48:27




---------------------------------------------------------

sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.33      0.47       422
        1.0       0.15      0.63      0.24        78

avg / total       0.72      0.38      0.44       500

[[140 282]
 [ 29  49]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.66      0.79       458
        1.0       0.18      0.79      0.29        42

avg / total       0.90      0.67      0.75       500

[[304 154]
 [  9  33]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.45      0.62       468
        1.0       0.10      0.97      0.19        31

avg / total       0.94      0.48      0.59       499

[[209 259]
 [  1  30]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.55      0.70       446
        1.0       0.20      0.93      0.33        54

avg / total       0.90      0.59      0.66       500

[[244 202]
 [  4  50]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.69      0.81       484
        1.0       0.07      0.75      0.13        16

avg / total       0.96      0.69      0.79       500

[[332 152]
 [  4  12]]
sbMIL(C=16384.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.96      0.95       500

[[481   3]
 [ 16   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.74      0.84       484
        1.0       0.09      0.75      0.15        16

avg / total       0.96      0.74      0.82       500

[[357 127]
 [  4  12]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.37      0.52       422
        1.0       0.16      0.67      0.26        78

avg / total       0.75      0.42      0.48       500

[[158 264]
 [ 26  52]]
sbMIL(C=16384.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.97      0.93       446
        1.0       0.00      0.00      0.00        54

avg / total       0.79      0.86      0.83       500

[[432  14]
 [ 54   0]]
sbMIL(C=16384.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.92      0.90       499

[[461   7]
 [ 31   0]]
sbMIL(C=16384.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       458
        1.0       1.00      0.07      0.13        42

avg / total       0.93      0.92      0.89       500

[[458   0]
 [ 39   3]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.41      0.58       446
        1.0       0.16      0.96      0.28        54

avg / total       0.90      0.47      0.54       500

[[181 265]
 [  2  52]]
sbMIL(C=16384.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      1.00      0.92       422
        1.0       0.00      0.00      0.00        78

avg / total       0.71      0.84      0.77       500

[[422   0]
 [ 78   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.42      0.59       468
        1.0       0.10      1.00      0.19        31

avg / total       0.94      0.46      0.57       499

[[198 270]
 [  0  31]]
sbMIL(C=65536.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.32      0.48       458
        1.0       0.12      0.98      0.21        42

avg / total       0.92      0.37      0.46       500

[[146 312]
 [  1  41]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.96      0.97       484
        1.0       0.17      0.25      0.21        16

avg / total       0.95      0.94      0.94       500

[[465  19]
 [ 12   4]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.84      0.83       422
        1.0       0.08      0.08      0.08        78

avg / total       0.71      0.72      0.72       500

[[354  68]
 [ 72   6]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.93      0.93       458
        1.0       0.20      0.19      0.19        42

avg / total       0.86      0.87      0.87       500

[[425  33]
 [ 34   8]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.88      0.90       446
        1.0       0.26      0.35      0.30        54

avg / total       0.85      0.82      0.83       500

[[391  55]
 [ 35  19]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.88      0.90       468
        1.0       0.00      0.00      0.00        31

avg / total       0.87      0.82      0.85       499

[[411  57]
 [ 31   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[484   0]
 [ 16   0]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.92      0.95       484
        1.0       0.13      0.38      0.19        16

avg / total       0.95      0.90      0.92       500

[[444  40]
 [ 10   6]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       458
        1.0       0.00      0.00      0.00        42

avg / total       0.84      0.92      0.88       500

[[458   0]
 [ 42   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.99      0.91       422
        1.0       0.00      0.00      0.00        78

avg / total       0.71      0.84      0.77       500

[[418   4]
 [ 78   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       446
        1.0       0.00      0.00      0.00        54

avg / total       0.80      0.89      0.84       500

[[446   0]
 [ 54   0]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.76      0.81       422
        1.0       0.19      0.31      0.24        78

avg / total       0.75      0.69      0.72       500

[[321 101]
 [ 54  24]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.89      0.91       458
        1.0       0.25      0.40      0.31        42

avg / total       0.88      0.85      0.86       500

[[406  52]
 [ 25  17]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.74      0.83       446
        1.0       0.21      0.57      0.31        54

avg / total       0.86      0.72      0.77       500

[[331 115]
 [ 23  31]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.81      0.86       468
        1.0       0.02      0.06      0.03        31

avg / total       0.87      0.76      0.81       499

[[377  91]
 [ 29   2]]

---------------------------------------------------------




Number of bags : 93    Number of single instances: 2499

2016-04-29 11:10:57




---------------------------------------------------------

sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       484
        1.0       0.11      0.44      0.18        16

avg / total       0.95      0.87      0.91       500

[[429  55]
 [  9   7]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.82      0.84       422
        1.0       0.21      0.26      0.23        78

avg / total       0.76      0.74      0.75       500

[[348  74]
 [ 58  20]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       458
        1.0       0.23      0.50      0.31        42

avg / total       0.89      0.81      0.84       500

[[386  72]
 [ 21  21]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.71      0.81       446
        1.0       0.22      0.69      0.33        54

avg / total       0.87      0.70      0.76       500

[[315 131]
 [ 17  37]]
sbMIL(C=8192.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       468
        1.0       0.11      0.29      0.16        31

avg / total       0.89      0.81      0.84       499

[[393  75]
 [ 22   9]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.79      0.88       484
        1.0       0.10      0.69      0.17        16

avg / total       0.96      0.79      0.86       500

[[384 100]
 [  5  11]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.51      0.64       422
        1.0       0.17      0.53      0.25        78

avg / total       0.75      0.51      0.58       500

[[216 206]
 [ 37  41]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.78      0.86       458
        1.0       0.21      0.64      0.32        42

avg / total       0.90      0.77      0.81       500

[[357 101]
 [ 15  27]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.62      0.75       446
        1.0       0.20      0.80      0.32        54

avg / total       0.88      0.64      0.71       500

[[277 169]
 [ 11  43]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.64      0.76       468
        1.0       0.09      0.55      0.16        31

avg / total       0.90      0.63      0.73       499

[[298 170]
 [ 14  17]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.85      0.91       484
        1.0       0.11      0.56      0.18        16

avg / total       0.96      0.84      0.89       500

[[410  74]
 [  7   9]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.67      0.76       422
        1.0       0.20      0.46      0.28        78

avg / total       0.77      0.64      0.68       500

[[282 140]
 [ 42  36]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.81      0.88       458
        1.0       0.24      0.64      0.35        42

avg / total       0.90      0.80      0.83       500

[[371  87]
 [ 15  27]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.63      0.77       446
        1.0       0.22      0.83      0.34        54

avg / total       0.89      0.66      0.72       500

[[283 163]
 [  9  45]]
sbMIL(C=1024.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.71      0.81       468
        1.0       0.09      0.45      0.15        31

avg / total       0.90      0.69      0.77       499

[[332 136]
 [ 17  14]]
sbMIL(C=2048.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[484   0]
 [ 16   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      1.00      0.92       422
        1.0       0.00      0.00      0.00        78

avg / total       0.71      0.84      0.77       500

[[422   0]
 [ 78   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       458
        1.0       0.67      0.05      0.09        42

avg / total       0.90      0.92      0.88       500

[[457   1]
 [ 40   2]]
sbMIL(C=2048.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       446
        1.0       0.00      0.00      0.00        54

avg / total       0.80      0.89      0.84       500

[[446   0]
 [ 54   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.45      0.62       484
        1.0       0.05      0.94      0.10        16

avg / total       0.97      0.47      0.61       500

[[219 265]
 [  1  15]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.82      0.38      0.52       422
        1.0       0.14      0.54      0.22        78

avg / total       0.71      0.40      0.47       500

[[159 263]
 [ 36  42]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.56      0.71       458
        1.0       0.13      0.71      0.22        42

avg / total       0.89      0.57      0.66       500

[[256 202]
 [ 12  30]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.53      0.69       446
        1.0       0.19      0.89      0.31        54

avg / total       0.89      0.57      0.65       500

[[238 208]
 [  6  48]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.37      0.54       468
        1.0       0.10      1.00      0.17        31

avg / total       0.94      0.41      0.52       499

[[175 293]
 [  0  31]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.79      0.88       484
        1.0       0.10      0.69      0.17        16

avg / total       0.96      0.79      0.85       500

[[382 102]
 [  5  11]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.44      0.58       422
        1.0       0.17      0.64      0.27        78

avg / total       0.76      0.47      0.53       500

[[184 238]
 [ 28  50]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.67      0.79       458
        1.0       0.18      0.79      0.29        42

avg / total       0.91      0.68      0.75       500

[[308 150]
 [  9  33]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.55      0.71       446
        1.0       0.20      0.94      0.33        54

avg / total       0.90      0.59      0.67       500

[[245 201]
 [  3  51]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.56      0.72       468
        1.0       0.12      0.90      0.21        31

avg / total       0.93      0.59      0.69       499

[[264 204]
 [  3  28]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.82      0.90       484
        1.0       0.11      0.69      0.19        16

avg / total       0.96      0.82      0.87       500

[[398  86]
 [  5  11]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.56      0.68       422
        1.0       0.18      0.53      0.27        78

avg / total       0.76      0.56      0.62       500

[[238 184]
 [ 37  41]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.74      0.84       458
        1.0       0.20      0.69      0.31        42

avg / total       0.90      0.74      0.80       500

[[341 117]
 [ 13  29]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.59      0.74       446
        1.0       0.21      0.91      0.34        54

avg / total       0.90      0.63      0.70       500

[[264 182]
 [  5  49]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.63      0.76       468
        1.0       0.12      0.77      0.21        31

avg / total       0.92      0.64      0.73       499

[[294 174]
 [  7  24]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.82      0.90       484
        1.0       0.11      0.69      0.19        16

avg / total       0.96      0.82      0.87       500

[[398  86]
 [  5  11]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.54      0.66       422
        1.0       0.17      0.53      0.26        78

avg / total       0.75      0.54      0.60       500

[[228 194]
 [ 37  41]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.74      0.84       458
        1.0       0.20      0.69      0.31        42

avg / total       0.90      0.74      0.80       500

[[341 117]
 [ 13  29]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.57      0.73       446
        1.0       0.21      0.93      0.34        54

avg / total       0.90      0.61      0.68       500

[[256 190]
 [  4  50]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.63      0.77       468
        1.0       0.12      0.74      0.20        31

avg / total       0.92      0.64      0.73       499

[[297 171]
 [  8  23]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       484
        1.0       0.29      0.12      0.17        16

avg / total       0.95      0.96      0.95       500

[[479   5]
 [ 14   2]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.95      0.89       422
        1.0       0.09      0.03      0.04        78

avg / total       0.72      0.81      0.76       500

[[401  21]
 [ 76   2]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.98      0.95       458
        1.0       0.25      0.07      0.11        42

avg / total       0.86      0.90      0.88       500

[[449   9]
 [ 39   3]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.95      0.92       446
        1.0       0.26      0.15      0.19        54

avg / total       0.83      0.86      0.85       500

[[423  23]
 [ 46   8]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.92      0.93       468
        1.0       0.00      0.00      0.00        31

avg / total       0.87      0.86      0.87       499

[[430  38]
 [ 31   0]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.81      0.89       484
        1.0       0.09      0.56      0.16        16

avg / total       0.95      0.81      0.87       500

[[394  90]
 [  7   9]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.54      0.66       422
        1.0       0.17      0.53      0.26        78

avg / total       0.75      0.54      0.60       500

[[227 195]
 [ 37  41]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.76      0.85       458
        1.0       0.22      0.74      0.34        42

avg / total       0.91      0.75      0.81       500

[[346 112]
 [ 11  31]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.58      0.73       446
        1.0       0.21      0.91      0.34        54

avg / total       0.90      0.62      0.69       500

[[260 186]
 [  5  49]]
sbMIL(C=256.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.63      0.77       468
        1.0       0.11      0.71      0.20        31

avg / total       0.92      0.64      0.73       499

[[297 171]
 [  9  22]]
Best parameters set found on development set:

{'C': 4096.0, 'eta': 0.625}

Grid scores on development set:

0.243 (+/-0.140) for {'C': 8192.0, 'eta': 0.375}
0.245 (+/-0.140) for {'C': 32.0, 'eta': 0.625}
0.262 (+/-0.160) for {'C': 1024.0, 'eta': 0.5}
0.018 (+/-0.071) for {'C': 2048.0, 'eta': 0.0}
0.205 (+/-0.136) for {'C': 8192.0, 'eta': 1.0}
0.257 (+/-0.116) for {'C': 1024.0, 'eta': 0.75}
0.265 (+/-0.114) for {'C': 4096.0, 'eta': 0.625}
0.262 (+/-0.114) for {'C': 512.0, 'eta': 0.625}
0.103 (+/-0.147) for {'C': 64.0, 'eta': 0.125}
0.258 (+/-0.146) for {'C': 256.0, 'eta': 0.625}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.98      0.45      0.62       676
        1.0       0.23      0.96      0.37       114

avg / total       0.87      0.52      0.58       790


Time elapsed: 48389.10 seconds.
Confusion matrix on the test data:
[[305 371]
 [  5 109]]
Precision on the test data: 22.71%
Recall on the test data: 95.61%
F1 Score on the test data: 36.70%

Saving results to eval8/res/lopo_p0_m500_b100_i1.pickle ...
