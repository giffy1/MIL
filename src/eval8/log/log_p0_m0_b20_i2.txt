
---------------------------------------------------------




Number of bags : 441    Number of single instances: 0

2016-04-28 11:04:24




---------------------------------------------------------

sbMIL(C=2048.0, class_weight={1: 0.9, -1: 0.1}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.41      0.58        46
        1.0       0.61      1.00      0.76        42

avg / total       0.81      0.69      0.67        88

[[19 27]
 [ 0 42]]
sbMIL(C=2048.0, class_weight={1: 0.9, -1: 0.1}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.46      0.59        46
        1.0       0.60      0.90      0.72        42

avg / total       0.73      0.67      0.65        88

[[21 25]
 [ 4 38]]
sbMIL(C=4096.0, class_weight={1: 0.925, -1: 0.075}, eta=0.125, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.75      0.45      0.56        47
        1.0       0.57      0.83      0.68        42

avg / total       0.67      0.63      0.62        89

[[21 26]
 [ 7 35]]
sbMIL(C=2048.0, class_weight={1: 0.9, -1: 0.1}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.77      0.50      0.61        46
        1.0       0.60      0.83      0.70        42

avg / total       0.69      0.66      0.65        88

[[23 23]
 [ 7 35]]
sbMIL(C=2048.0, class_weight={1: 0.9, -1: 0.1}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.34      0.49        47
        1.0       0.56      0.95      0.71        42

avg / total       0.74      0.63      0.59        89

[[16 31]
 [ 2 40]]
sbMIL(C=2048.0, class_weight={1: 0.9, -1: 0.1}, eta=0.75, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.28      0.43        46
        1.0       0.55      0.98      0.71        42

avg / total       0.75      0.61      0.56        88

[[13 33]
 [ 1 41]]
sbMIL(C=32768.0, class_weight={1: 0.825, -1: 0.175}, eta=0.5, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.32      0.47        47
        1.0       0.56      0.95      0.70        42

avg / total       0.73      0.62      0.58        89

[[15 32]
 [ 2 40]]
sbMIL(C=4096.0, class_weight={1: 0.925, -1: 0.075}, eta=0.125, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.75      0.52      0.62        46
        1.0       0.61      0.81      0.69        42

avg / total       0.68      0.66      0.65        88

[[24 22]
 [ 8 34]]
sbMIL(C=32768.0, class_weight={1: 0.825, -1: 0.175}, eta=0.5, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.33      0.48        46
        1.0       0.56      0.95      0.71        42

avg / total       0.73      0.62      0.59        88

[[15 31]
 [ 2 40]]
sbMIL(C=4096.0, class_weight={1: 0.925, -1: 0.075}, eta=0.125, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.74      0.63      0.68        46
        1.0       0.65      0.76      0.70        42

avg / total       0.70      0.69      0.69        88

[[29 17]
 [10 32]]
sbMIL(C=4096.0, class_weight={1: 0.925, -1: 0.075}, eta=0.125, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.64      0.70      0.67        46
        1.0       0.63      0.57      0.60        42

avg / total       0.64      0.64      0.63        88

[[32 14]
 [18 24]]
sbMIL(C=4096.0, class_weight={1: 0.925, -1: 0.075}, eta=0.125, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.70      0.67      0.69        46
        1.0       0.66      0.69      0.67        42

avg / total       0.68      0.68      0.68        88

[[31 15]
 [13 29]]
sbMIL(C=32768.0, class_weight={1: 0.825, -1: 0.175}, eta=0.5, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.41      0.58        46
        1.0       0.60      0.98      0.75        42

avg / total       0.78      0.68      0.66        88

[[19 27]
 [ 1 41]]
sbMIL(C=32768.0, class_weight={1: 0.825, -1: 0.175}, eta=0.5, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.74      0.50      0.60        46
        1.0       0.60      0.81      0.69        42

avg / total       0.67      0.65      0.64        88

[[23 23]
 [ 8 34]]
sbMIL(C=32768.0, class_weight={1: 0.825, -1: 0.175}, eta=0.5, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.75      0.52      0.62        46
        1.0       0.61      0.81      0.69        42

avg / total       0.68      0.66      0.65        88

[[24 22]
 [ 8 34]]
sbMIL(C=2048.0, class_weight={1: 0.85, -1: 0.15}, eta=0.875, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.32      0.46        47
        1.0       0.55      0.93      0.69        42

avg / total       0.70      0.61      0.57        89

[[15 32]
 [ 3 39]]
sbMIL(C=2048.0, class_weight={1: 0.85, -1: 0.15}, eta=0.875, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.37      0.52        46
        1.0       0.58      0.95      0.72        42

avg / total       0.74      0.65      0.62        88

[[17 29]
 [ 2 40]]
sbMIL(C=2048.0, class_weight={1: 0.85, -1: 0.15}, eta=0.875, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.43      0.61        46
        1.0       0.62      1.00      0.76        42

avg / total       0.82      0.70      0.68        88

[[20 26]
 [ 0 42]]
sbMIL(C=2048.0, class_weight={1: 0.85, -1: 0.15}, eta=0.875, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.54      0.68        46
        1.0       0.65      0.93      0.76        42

avg / total       0.78      0.73      0.72        88

[[25 21]
 [ 3 39]]
sbMIL(C=2048.0, class_weight={1: 0.85, -1: 0.15}, eta=0.875, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.54      0.66        46
        1.0       0.64      0.88      0.74        42

avg / total       0.74      0.70      0.70        88

[[25 21]
 [ 5 37]]
sbMIL(C=2048.0, class_weight={1: 0.8, -1: 0.2}, eta=0.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.47      0.66      0.55        47
        1.0       0.30      0.17      0.22        42

avg / total       0.39      0.43      0.39        89

[[31 16]
 [35  7]]
sbMIL(C=2048.0, class_weight={1: 0.8, -1: 0.2}, eta=0.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.63      0.80      0.70        46
        1.0       0.69      0.48      0.56        42

avg / total       0.66      0.65      0.64        88

[[37  9]
 [22 20]]
sbMIL(C=2048.0, class_weight={1: 0.8, -1: 0.2}, eta=0.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.53      0.74      0.62        46
        1.0       0.50      0.29      0.36        42

avg / total       0.52      0.52      0.50        88

[[34 12]
 [30 12]]
sbMIL(C=2048.0, class_weight={1: 0.8, -1: 0.2}, eta=0.0, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.52      0.78      0.63        46
        1.0       0.47      0.21      0.30        42

avg / total       0.50      0.51      0.47        88

[[36 10]
 [33  9]]
sbMIL(C=8192.0, class_weight={1: 0.8, -1: 0.2}, eta=0.625, gamma=1.0,
   kernel='linear', p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.32      0.47        47
        1.0       0.56      0.95      0.70        42

avg / total       0.73      0.62      0.58        89

[[15 32]
 [ 2 40]]

---------------------------------------------------------




Number of bags : 441    Number of single instances: 0

2016-04-28 12:17:49




---------------------------------------------------------

sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.30      0.44        47
        1.0       0.55      0.95      0.70        42

avg / total       0.72      0.61      0.56        89

[[14 33]
 [ 2 40]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.57      0.69        46
        1.0       0.66      0.93      0.77        42

avg / total       0.78      0.74      0.73        88

[[26 20]
 [ 3 39]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.41      0.57        46
        1.0       0.60      0.95      0.73        42

avg / total       0.76      0.67      0.65        88

[[19 27]
 [ 2 40]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.68      0.54      0.60        46
        1.0       0.59      0.71      0.65        42

avg / total       0.63      0.62      0.62        88

[[25 21]
 [12 30]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.67      0.61      0.64        46
        1.0       0.61      0.67      0.64        42

avg / total       0.64      0.64      0.64        88

[[28 18]
 [14 28]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.53      0.83      0.64        47
        1.0       0.47      0.17      0.25        42

avg / total       0.50      0.52      0.46        89

[[39  8]
 [35  7]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.55      0.76      0.64        46
        1.0       0.54      0.31      0.39        42

avg / total       0.54      0.55      0.52        88

[[35 11]
 [29 13]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.53      1.00      0.69        47
        1.0       0.00      0.00      0.00        42

avg / total       0.28      0.53      0.37        89

[[47  0]
 [42  0]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.60      0.96      0.74        46
        1.0       0.87      0.31      0.46        42

avg / total       0.73      0.65      0.60        88

[[44  2]
 [29 13]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.50      0.78      0.61        46
        1.0       0.38      0.14      0.21        42

avg / total       0.44      0.48      0.42        88

[[36 10]
 [36  6]]
sbMIL(C=4096.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      0.89      0.73        46
        1.0       0.76      0.38      0.51        42

avg / total       0.68      0.65      0.62        88

[[41  5]
 [26 16]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.51      0.76      0.61        46
        1.0       0.42      0.19      0.26        42

avg / total       0.47      0.49      0.44        88

[[35 11]
 [34  8]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.28      0.43        47
        1.0       0.55      0.98      0.70        42

avg / total       0.75      0.61      0.56        89

[[13 34]
 [ 1 41]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.30      0.46        46
        1.0       0.56      0.98      0.71        42

avg / total       0.76      0.62      0.58        88

[[14 32]
 [ 1 41]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.48      0.65        46
        1.0       0.64      1.00      0.78        42

avg / total       0.83      0.73      0.71        88

[[22 24]
 [ 0 42]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.81      0.48      0.60        46
        1.0       0.61      0.88      0.72        42

avg / total       0.72      0.67      0.66        88

[[22 24]
 [ 5 37]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.46      0.59        46
        1.0       0.60      0.90      0.72        42

avg / total       0.73      0.67      0.65        88

[[21 25]
 [ 4 38]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.52      1.00      0.69        46
        1.0       0.00      0.00      0.00        42

avg / total       0.27      0.52      0.36        88

[[46  0]
 [42  0]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.80      0.34      0.48        47
        1.0       0.55      0.90      0.68        42

avg / total       0.68      0.61      0.58        89

[[16 31]
 [ 4 38]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.51      0.91      0.65        46
        1.0       0.20      0.02      0.04        42

avg / total       0.36      0.49      0.36        88

[[42  4]
 [41  1]]
sbMIL(C=32.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.54      0.98      0.69        46
        1.0       0.75      0.07      0.13        42

avg / total       0.64      0.55      0.42        88

[[45  1]
 [39  3]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.41      0.56        46
        1.0       0.59      0.93      0.72        42

avg / total       0.73      0.66      0.64        88

[[19 27]
 [ 3 39]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.54      0.68        46
        1.0       0.65      0.93      0.76        42

avg / total       0.78      0.73      0.72        88

[[25 21]
 [ 3 39]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.66      0.63      0.64        46
        1.0       0.61      0.64      0.63        42

avg / total       0.64      0.64      0.64        88

[[29 17]
 [15 27]]
sbMIL(C=4096.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.66      0.54      0.60        46
        1.0       0.58      0.69      0.63        42

avg / total       0.62      0.61      0.61        88

[[25 21]
 [13 29]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.19      0.32        47
        1.0       0.53      1.00      0.69        42

avg / total       0.78      0.57      0.49        89

[[ 9 38]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.22      0.36        46
        1.0       0.54      1.00      0.70        42

avg / total       0.78      0.59      0.52        88

[[10 36]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.30      0.47        46
        1.0       0.57      1.00      0.72        42

avg / total       0.79      0.64      0.59        88

[[14 32]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.46      0.63        46
        1.0       0.63      1.00      0.77        42

avg / total       0.82      0.72      0.70        88

[[21 25]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.48      0.64        46
        1.0       0.63      0.98      0.77        42

avg / total       0.80      0.72      0.70        88

[[22 24]
 [ 1 41]]
sbMIL(C=32768.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.74      0.43      0.54        47
        1.0       0.56      0.83      0.67        42

avg / total       0.66      0.62      0.60        89

[[20 27]
 [ 7 35]]
sbMIL(C=32768.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.35      0.50        46
        1.0       0.57      0.95      0.71        42

avg / total       0.74      0.64      0.60        88

[[16 30]
 [ 2 40]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.23      0.37        47
        1.0       0.53      0.95      0.68        42

avg / total       0.70      0.57      0.51        89

[[11 36]
 [ 2 40]]
sbMIL(C=32768.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.59      0.71        46
        1.0       0.67      0.93      0.78        42

avg / total       0.79      0.75      0.74        88

[[27 19]
 [ 3 39]]
sbMIL(C=32768.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.64      0.70      0.67        46
        1.0       0.63      0.57      0.60        42

avg / total       0.64      0.64      0.63        88

[[32 14]
 [18 24]]
sbMIL(C=32768.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.65      0.57      0.60        46
        1.0       0.58      0.67      0.62        42

avg / total       0.62      0.61      0.61        88

[[26 20]
 [14 28]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.76      0.41      0.54        46
        1.0       0.57      0.86      0.69        42

avg / total       0.67      0.62      0.61        88

[[19 27]
 [ 6 36]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.28      0.43        46
        1.0       0.55      0.95      0.70        42

avg / total       0.71      0.60      0.55        88

[[13 33]
 [ 2 40]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.22      0.36        46
        1.0       0.54      1.00      0.70        42

avg / total       0.78      0.59      0.52        88

[[10 36]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.37      0.52        46
        1.0       0.57      0.93      0.71        42

avg / total       0.72      0.64      0.61        88

[[17 29]
 [ 3 39]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.83      0.21      0.34        47
        1.0       0.52      0.95      0.67        42

avg / total       0.69      0.56      0.50        89

[[10 37]
 [ 2 40]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.22      0.36        46
        1.0       0.54      1.00      0.70        42

avg / total       0.78      0.59      0.52        88

[[10 36]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.30      0.47        46
        1.0       0.57      1.00      0.72        42

avg / total       0.79      0.64      0.59        88

[[14 32]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.46      0.63        46
        1.0       0.63      1.00      0.77        42

avg / total       0.82      0.72      0.70        88

[[21 25]
 [ 0 42]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.50      0.66        46
        1.0       0.64      0.98      0.77        42

avg / total       0.81      0.73      0.71        88

[[23 23]
 [ 1 41]]
sbMIL(C=512.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.61      0.60      0.60        47
        1.0       0.56      0.57      0.56        42

avg / total       0.58      0.58      0.58        89

[[28 19]
 [18 24]]
sbMIL(C=512.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.70      0.65      0.67        46
        1.0       0.64      0.69      0.67        42

avg / total       0.67      0.67      0.67        88

[[30 16]
 [13 29]]
sbMIL(C=512.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.69      0.67      0.68        46
        1.0       0.65      0.67      0.66        42

avg / total       0.67      0.67      0.67        88

[[31 15]
 [14 28]]
sbMIL(C=512.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.59      0.74      0.65        46
        1.0       0.60      0.43      0.50        42

avg / total       0.59      0.59      0.58        88

[[34 12]
 [24 18]]
sbMIL(C=512.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.63      0.83      0.72        46
        1.0       0.71      0.48      0.57        42

avg / total       0.67      0.66      0.65        88

[[38  8]
 [22 20]]
Best parameters set found on development set:

{'C': 32.0, 'eta': 1.0}

Grid scores on development set:

0.697 (+/-0.104) for {'C': 65536.0, 'eta': 0.375}
0.362 (+/-0.235) for {'C': 4096.0, 'eta': 0.0}
0.087 (+/-0.199) for {'C': 32.0, 'eta': 0.0}
0.727 (+/-0.053) for {'C': 2048.0, 'eta': 0.75}
0.686 (+/-0.106) for {'C': 4096.0, 'eta': 0.375}
0.730 (+/-0.067) for {'C': 32.0, 'eta': 1.0}
0.678 (+/-0.129) for {'C': 32768.0, 'eta': 0.25}
0.694 (+/-0.022) for {'C': 32.0, 'eta': 0.625}
0.728 (+/-0.079) for {'C': 32.0, 'eta': 0.875}
0.592 (+/-0.125) for {'C': 512.0, 'eta': 0.125}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       1.00      0.35      0.51       676
        1.0       0.20      0.99      0.34       114

avg / total       0.88      0.44      0.49       790


Time elapsed: 5670.99 seconds.
Confusion matrix on the test data:
[[234 442]
 [  1 113]]
Precision on the test data: 20.36%
Recall on the test data: 99.12%
F1 Score on the test data: 33.78%

Saving results to eval8/res/lopo_p0_m0_b20_i2.pickle ...
