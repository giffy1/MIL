
---------------------------------------------------------




Number of bags : 93    Number of single instances: 625

2016-04-28 16:16:12




---------------------------------------------------------

sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.90      0.93       120
        1.0       0.08      0.20      0.11         5

avg / total       0.93      0.87      0.90       125

[[108  12]
 [  4   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.97      0.97       120
        1.0       0.20      0.20      0.20         5

avg / total       0.94      0.94      0.94       125

[[116   4]
 [  4   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.93      0.94       117
        1.0       0.27      0.38      0.32         8

avg / total       0.91      0.90      0.90       125

[[109   8]
 [  5   3]]
sbMIL(C=8192.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.96      0.94       116
        1.0       0.17      0.11      0.13         9

avg / total       0.88      0.90      0.89       125

[[111   5]
 [  8   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.94      0.90       106
        1.0       0.33      0.16      0.21        19

avg / total       0.78      0.82      0.80       125

[[100   6]
 [ 16   3]]
sbMIL(C=8192.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.90      0.91       113
        1.0       0.27      0.33      0.30        12

avg / total       0.86      0.85      0.86       125

[[102  11]
 [  8   4]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.93       117
        1.0       0.30      0.75      0.43         8

avg / total       0.94      0.87      0.90       125

[[103  14]
 [  2   6]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.84      0.85       106
        1.0       0.23      0.26      0.24        19

avg / total       0.77      0.75      0.76       125

[[89 17]
 [14  5]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.44      0.59       106
        1.0       0.17      0.63      0.27        19

avg / total       0.76      0.47      0.54       125

[[47 59]
 [ 7 12]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.80      0.86       113
        1.0       0.21      0.50      0.29        12

avg / total       0.87      0.77      0.81       125

[[90 23]
 [ 6  6]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.93      0.94       116
        1.0       0.20      0.22      0.21         9

avg / total       0.89      0.88      0.88       125

[[108   8]
 [  7   2]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.74      0.85       120
        1.0       0.11      0.80      0.20         5

avg / total       0.95      0.74      0.82       125

[[89 31]
 [ 1  4]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.49      0.66       117
        1.0       0.12      1.00      0.21         8

avg / total       0.94      0.52      0.63       125

[[57 60]
 [ 0  8]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.51      0.67       116
        1.0       0.11      0.78      0.19         9

avg / total       0.91      0.53      0.63       125

[[59 57]
 [ 2  7]]
sbMIL(C=1024.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.51      0.68       113
        1.0       0.18      1.00      0.30        12

avg / total       0.92      0.56      0.64       125

[[58 55]
 [ 0 12]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.86      0.92       117
        1.0       0.27      0.75      0.40         8

avg / total       0.94      0.86      0.89       125

[[101  16]
 [  2   6]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.91      0.94       120
        1.0       0.08      0.20      0.12         5

avg / total       0.93      0.88      0.90       125

[[109  11]
 [  4   1]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.85      0.86       106
        1.0       0.24      0.26      0.25        19

avg / total       0.77      0.76      0.76       125

[[90 16]
 [14  5]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.78      0.85       113
        1.0       0.19      0.50      0.28        12

avg / total       0.86      0.75      0.80       125

[[88 25]
 [ 6  6]]
sbMIL(C=4096.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.91      0.93       116
        1.0       0.17      0.22      0.19         9

avg / total       0.88      0.86      0.87       125

[[106  10]
 [  7   2]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.81      0.89       120
        1.0       0.12      0.60      0.19         5

avg / total       0.95      0.80      0.86       125

[[97 23]
 [ 2  3]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.54      0.66       106
        1.0       0.16      0.47      0.23        19

avg / total       0.75      0.53      0.59       125

[[57 49]
 [10  9]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.65      0.77       113
        1.0       0.17      0.67      0.27        12

avg / total       0.87      0.65      0.72       125

[[73 40]
 [ 4  8]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.76      0.86       117
        1.0       0.20      0.88      0.33         8

avg / total       0.94      0.77      0.83       125

[[89 28]
 [ 1  7]]
sbMIL(C=32768.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.69      0.80       116
        1.0       0.12      0.56      0.20         9

avg / total       0.89      0.68      0.76       125

[[80 36]
 [ 4  5]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.03      0.05       117
        1.0       0.07      1.00      0.12         8

avg / total       0.94      0.09      0.05       125

[[  3 114]
 [  0   8]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.03      0.05       120
        1.0       0.04      1.00      0.08         5

avg / total       0.96      0.06      0.05       125

[[  3 117]
 [  0   5]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.01      0.02       113
        1.0       0.10      1.00      0.18        12

avg / total       0.91      0.10      0.03       125

[[  1 112]
 [  0  12]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.11      0.20       106
        1.0       0.17      1.00      0.29        19

avg / total       0.87      0.25      0.22       125

[[12 94]
 [ 0 19]]
sbMIL(C=8192.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       116
        1.0       0.07      1.00      0.13         9

avg / total       0.01      0.07      0.01       125

[[  0 116]
 [  0   9]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.03      0.05       120
        1.0       0.04      1.00      0.08         5

avg / total       0.96      0.06      0.05       125

[[  3 117]
 [  0   5]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.81      0.89       120
        1.0       0.12      0.60      0.19         5

avg / total       0.95      0.80      0.86       125

[[97 23]
 [ 2  3]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.57      0.68       106
        1.0       0.15      0.42      0.22        19

avg / total       0.74      0.54      0.61       125

[[60 46]
 [11  8]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.01      0.02       113
        1.0       0.10      1.00      0.18        12

avg / total       0.91      0.10      0.03       125

[[  1 112]
 [  0  12]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.11      0.20       106
        1.0       0.17      1.00      0.29        19

avg / total       0.87      0.25      0.22       125

[[12 94]
 [ 0 19]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.03      0.05       117
        1.0       0.07      1.00      0.12         8

avg / total       0.94      0.09      0.05       125

[[  3 114]
 [  0   8]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.76      0.86       117
        1.0       0.20      0.88      0.33         8

avg / total       0.94      0.77      0.83       125

[[89 28]
 [ 1  7]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       116
        1.0       0.07      1.00      0.13         9

avg / total       0.01      0.07      0.01       125

[[  0 116]
 [  0   9]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.64      0.76       113
        1.0       0.16      0.67      0.26        12

avg / total       0.87      0.64      0.71       125

[[72 41]
 [ 4  8]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.42      0.57       106
        1.0       0.16      0.63      0.26        19

avg / total       0.76      0.46      0.52       125

[[45 61]
 [ 7 12]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.71      0.81       116
        1.0       0.13      0.56      0.21         9

avg / total       0.89      0.70      0.77       125

[[82 34]
 [ 4  5]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.75      0.85       120
        1.0       0.12      0.80      0.21         5

avg / total       0.95      0.75      0.83       125

[[90 30]
 [ 1  4]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.45      0.62       117
        1.0       0.11      1.00      0.20         8

avg / total       0.94      0.49      0.60       125

[[53 64]
 [ 0  8]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.50      0.66       113
        1.0       0.17      1.00      0.30        12

avg / total       0.92      0.54      0.63       125

[[56 57]
 [ 0 12]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.50      0.66       116
        1.0       0.11      0.78      0.19         9

avg / total       0.90      0.52      0.63       125

[[58 58]
 [ 2  7]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.99      0.98       120
        1.0       0.00      0.00      0.00         5

avg / total       0.92      0.95      0.94       125

[[119   1]
 [  5   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       117
        1.0       0.00      0.00      0.00         8

avg / total       0.88      0.94      0.91       125

[[117   0]
 [  8   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.99      0.95       113
        1.0       0.00      0.00      0.00        12

avg / total       0.82      0.90      0.85       125

[[112   1]
 [ 12   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       106
        1.0       0.00      0.00      0.00        19

avg / total       0.72      0.85      0.78       125

[[106   0]
 [ 19   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      1.00      0.96       116
        1.0       0.00      0.00      0.00         9

avg / total       0.86      0.93      0.89       125

[[116   0]
 [  9   0]]
Best parameters set found on development set:

{'C': 2048.0, 'eta': 0.25}

Grid scores on development set:

0.232 (+/-0.133) for {'C': 8192.0, 'eta': 0.125}
0.257 (+/-0.208) for {'C': 2048.0, 'eta': 0.25}
0.235 (+/-0.087) for {'C': 1024.0, 'eta': 0.75}
0.247 (+/-0.188) for {'C': 4096.0, 'eta': 0.25}
0.244 (+/-0.097) for {'C': 32768.0, 'eta': 0.5}
0.160 (+/-0.142) for {'C': 8192.0, 'eta': 1.0}
0.160 (+/-0.142) for {'C': 4096.0, 'eta': 1.0}
0.242 (+/-0.095) for {'C': 16384.0, 'eta': 0.5}
0.230 (+/-0.083) for {'C': 2048.0, 'eta': 0.75}
0.000 (+/-0.000) for {'C': 65536.0, 'eta': 0.0}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.94      0.78      0.85       676
        1.0       0.35      0.72      0.47       114

avg / total       0.86      0.77      0.80       790


Time elapsed: 8988.23 seconds.
Confusion matrix on the test data:
[[526 150]
 [ 32  82]]
Precision on the test data: 35.34%
Recall on the test data: 71.93%
F1 Score on the test data: 47.40%

Saving results to eval8/res/lopo_p0_m125_b100_i1.pickle ...
