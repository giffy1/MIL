
---------------------------------------------------------




Number of bags : 93    Number of single instances: 1250

2016-04-28 22:02:42




---------------------------------------------------------

sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.91      0.92       232
        1.0       0.04      0.06      0.05        18

avg / total       0.86      0.84      0.85       250

[[210  22]
 [ 17   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.78      0.85       223
        1.0       0.23      0.56      0.33        27

avg / total       0.86      0.75      0.79       250

[[173  50]
 [ 12  15]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.91      0.94       241
        1.0       0.05      0.11      0.06         9

avg / total       0.93      0.88      0.91       250

[[220  21]
 [  8   1]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.91      0.93       234
        1.0       0.25      0.44      0.32        16

avg / total       0.91      0.88      0.89       250

[[213  21]
 [  9   7]]
sbMIL(C=8192.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.92      0.91       214
        1.0       0.41      0.33      0.37        36

avg / total       0.82      0.84      0.83       250

[[197  17]
 [ 24  12]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.67      0.80       241
        1.0       0.07      0.67      0.13         9

avg / total       0.95      0.67      0.77       250

[[161  80]
 [  3   6]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.36      0.51       214
        1.0       0.16      0.72      0.26        36

avg / total       0.78      0.41      0.47       250

[[ 76 138]
 [ 10  26]]
sbMIL(C=512.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.93      0.95       241
        1.0       0.10      0.22      0.14         9

avg / total       0.94      0.90      0.92       250

[[223  18]
 [  7   2]]
sbMIL(C=512.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.83      0.85       214
        1.0       0.24      0.33      0.28        36

avg / total       0.79      0.76      0.77       250

[[177  37]
 [ 24  12]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.31      0.48       234
        1.0       0.09      1.00      0.17        16

avg / total       0.94      0.36      0.46       250

[[ 73 161]
 [  0  16]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.28      0.44       223
        1.0       0.14      1.00      0.25        27

avg / total       0.91      0.36      0.42       250

[[ 62 161]
 [  0  27]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.38      0.55       232
        1.0       0.11      1.00      0.20        18

avg / total       0.94      0.43      0.53       250

[[ 89 143]
 [  0  18]]
sbMIL(C=512.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.92      0.94       234
        1.0       0.27      0.44      0.33        16

avg / total       0.92      0.89      0.90       250

[[215  19]
 [  9   7]]
sbMIL(C=512.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.83      0.88       223
        1.0       0.26      0.48      0.34        27

avg / total       0.86      0.80      0.82       250

[[186  37]
 [ 14  13]]
sbMIL(C=512.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.93      0.93       232
        1.0       0.11      0.11      0.11        18

avg / total       0.87      0.87      0.87       250

[[215  17]
 [ 16   2]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.79      0.88       241
        1.0       0.11      0.67      0.18         9

avg / total       0.95      0.78      0.85       250

[[190  51]
 [  3   6]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.47      0.61       214
        1.0       0.16      0.58      0.25        36

avg / total       0.77      0.49      0.56       250

[[101 113]
 [ 15  21]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.75      0.85       234
        1.0       0.16      0.69      0.26        16

avg / total       0.92      0.74      0.81       250

[[175  59]
 [  5  11]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.61      0.74       223
        1.0       0.19      0.74      0.30        27

avg / total       0.87      0.62      0.69       250

[[135  88]
 [  7  20]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.66      0.78       232
        1.0       0.10      0.50      0.17        18

avg / total       0.88      0.65      0.74       250

[[154  78]
 [  9   9]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.73      0.84       241
        1.0       0.08      0.67      0.15         9

avg / total       0.95      0.72      0.81       250

[[175  66]
 [  3   6]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.43      0.58       214
        1.0       0.18      0.72      0.28        36

avg / total       0.80      0.47      0.54       250

[[ 92 122]
 [ 10  26]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.50      0.66       234
        1.0       0.10      0.81      0.18        16

avg / total       0.92      0.52      0.63       250

[[116 118]
 [  3  13]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.50      0.66       232
        1.0       0.13      0.94      0.22        18

avg / total       0.93      0.53      0.63       250

[[115 117]
 [  1  17]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.52      0.68       223
        1.0       0.20      1.00      0.33        27

avg / total       0.91      0.57      0.64       250

[[115 108]
 [  0  27]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.70      0.82       241
        1.0       0.08      0.67      0.14         9

avg / total       0.95      0.70      0.79       250

[[168  73]
 [  3   6]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.29      0.43       214
        1.0       0.14      0.69      0.23        36

avg / total       0.75      0.34      0.40       250

[[ 61 153]
 [ 11  25]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.53      0.69       234
        1.0       0.11      0.88      0.20        16

avg / total       0.93      0.55      0.65       250

[[123 111]
 [  2  14]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.53      0.69       223
        1.0       0.18      0.85      0.30        27

avg / total       0.88      0.57      0.65       250

[[119 104]
 [  4  23]]
sbMIL(C=64.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.48      0.65       232
        1.0       0.13      1.00      0.23        18

avg / total       0.94      0.52      0.62       250

[[111 121]
 [  0  18]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.88      0.92       241
        1.0       0.09      0.33      0.14         9

avg / total       0.94      0.86      0.89       250

[[211  30]
 [  6   3]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.70      0.78       214
        1.0       0.20      0.44      0.27        36

avg / total       0.78      0.66      0.71       250

[[149  65]
 [ 20  16]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.86      0.91       234
        1.0       0.17      0.44      0.25        16

avg / total       0.91      0.83      0.86       250

[[201  33]
 [  9   7]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.77      0.85       223
        1.0       0.24      0.59      0.34        27

avg / total       0.86      0.75      0.79       250

[[172  51]
 [ 11  16]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.83      0.89       232
        1.0       0.15      0.39      0.22        18

avg / total       0.89      0.80      0.84       250

[[193  39]
 [ 11   7]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.76      0.85       241
        1.0       0.09      0.67      0.16         9

avg / total       0.95      0.75      0.83       250

[[182  59]
 [  3   6]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.04      0.07       234
        1.0       0.07      1.00      0.12        16

avg / total       0.94      0.10      0.08       250

[[  9 225]
 [  0  16]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.02      0.05       241
        1.0       0.04      1.00      0.07         9

avg / total       0.97      0.06      0.05       250

[[  6 235]
 [  0   9]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.45      0.60       214
        1.0       0.18      0.69      0.28        36

avg / total       0.79      0.49      0.56       250

[[ 97 117]
 [ 11  25]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.01      0.03       223
        1.0       0.11      1.00      0.20        27

avg / total       0.90      0.12      0.04       250

[[  3 220]
 [  0  27]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.01      0.03       232
        1.0       0.07      1.00      0.14        18

avg / total       0.93      0.08      0.03       250

[[  3 229]
 [  0  18]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.25       214
        1.0       0.16      1.00      0.28        36

avg / total       0.88      0.26      0.25       250

[[ 30 184]
 [  0  36]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.54      0.69       234
        1.0       0.10      0.75      0.18        16

avg / total       0.91      0.55      0.66       250

[[126 108]
 [  4  12]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.50      0.66       232
        1.0       0.12      0.89      0.21        18

avg / total       0.92      0.53      0.63       250

[[116 116]
 [  2  16]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.54      0.70       223
        1.0       0.20      0.96      0.34        27

avg / total       0.91      0.59      0.66       250

[[121 102]
 [  1  26]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.99      0.98       241
        1.0       0.00      0.00      0.00         9

avg / total       0.93      0.95      0.94       250

[[238   3]
 [  9   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      1.00      0.92       214
        1.0       0.00      0.00      0.00        36

avg / total       0.73      0.86      0.79       250

[[214   0]
 [ 36   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       234
        1.0       0.33      0.06      0.11        16

avg / total       0.90      0.93      0.91       250

[[232   2]
 [ 15   1]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.98      0.93       223
        1.0       0.00      0.00      0.00        27

avg / total       0.79      0.88      0.83       250

[[219   4]
 [ 27   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.99      0.96       232
        1.0       0.00      0.00      0.00        18

avg / total       0.86      0.92      0.89       250

[[230   2]
 [ 18   0]]
Best parameters set found on development set:

{'C': 128.0, 'eta': 0.375}

Grid scores on development set:

0.225 (+/-0.278) for {'C': 8192.0, 'eta': 0.25}
0.201 (+/-0.101) for {'C': 32768.0, 'eta': 0.875}
0.240 (+/-0.196) for {'C': 512.0, 'eta': 0.25}
0.230 (+/-0.094) for {'C': 128.0, 'eta': 0.625}
0.233 (+/-0.136) for {'C': 32768.0, 'eta': 0.75}
0.219 (+/-0.106) for {'C': 64.0, 'eta': 0.875}
0.245 (+/-0.130) for {'C': 128.0, 'eta': 0.375}
0.162 (+/-0.144) for {'C': 32768.0, 'eta': 1.0}
0.234 (+/-0.131) for {'C': 4096.0, 'eta': 0.75}
0.021 (+/-0.084) for {'C': 65536.0, 'eta': 0.0}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.94      0.73      0.82       676
        1.0       0.32      0.74      0.44       114

avg / total       0.85      0.73      0.77       790


Time elapsed: 8860.80 seconds.
Confusion matrix on the test data:
[[495 181]
 [ 30  84]]
Precision on the test data: 31.70%
Recall on the test data: 73.68%
F1 Score on the test data: 44.33%

Saving results to eval8/res/lopo_p0_m250_b100_i1.pickle ...
