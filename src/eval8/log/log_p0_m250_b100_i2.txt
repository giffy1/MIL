
---------------------------------------------------------




Number of bags : 93    Number of single instances: 1250

2016-04-28 22:14:12




---------------------------------------------------------

sbMIL(C=32.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.77      0.87       246
        1.0       0.07      1.00      0.12         4

avg / total       0.99      0.77      0.86       250

[[189  57]
 [  0   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.80      0.89       246
        1.0       0.07      1.00      0.14         4

avg / total       0.99      0.80      0.87       250

[[196  50]
 [  0   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.28      0.43       206
        1.0       0.22      0.93      0.35        44

avg / total       0.82      0.39      0.41       250

[[ 57 149]
 [  3  41]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.33      0.49       221
        1.0       0.14      0.83      0.24        29

avg / total       0.84      0.39      0.46       250

[[ 73 148]
 [  5  24]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.45      0.62       239
        1.0       0.08      1.00      0.14        11

avg / total       0.96      0.48      0.60       250

[[108 131]
 [  0  11]]
sbMIL(C=32.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.35      0.51       206
        1.0       0.21      0.80      0.33        44

avg / total       0.77      0.43      0.48       250

[[ 73 133]
 [  9  35]]
sbMIL(C=65536.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.37      0.54       231
        1.0       0.12      1.00      0.21        19

avg / total       0.93      0.42      0.51       250

[[ 85 146]
 [  0  19]]
sbMIL(C=32.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.65      0.77       231
        1.0       0.14      0.68      0.23        19

avg / total       0.90      0.65      0.73       250

[[149  82]
 [  6  13]]
sbMIL(C=32.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.50      0.67       239
        1.0       0.08      1.00      0.16        11

avg / total       0.96      0.52      0.65       250

[[120 119]
 [  0  11]]
sbMIL(C=32.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.55      0.70       221
        1.0       0.18      0.76      0.29        29

avg / total       0.86      0.58      0.65       250

[[122  99]
 [  7  22]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.79      0.88       246
        1.0       0.07      1.00      0.13         4

avg / total       0.99      0.79      0.87       250

[[194  52]
 [  0   4]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.42      0.58       206
        1.0       0.24      0.84      0.37        44

avg / total       0.80      0.50      0.54       250

[[ 87 119]
 [  7  37]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.82      0.90       246
        1.0       0.06      0.75      0.12         4

avg / total       0.98      0.82      0.89       250

[[202  44]
 [  1   3]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.33      0.49       221
        1.0       0.14      0.83      0.24        29

avg / total       0.84      0.39      0.46       250

[[ 73 148]
 [  5  24]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.41      0.58       231
        1.0       0.12      0.95      0.21        19

avg / total       0.92      0.45      0.55       250

[[ 94 137]
 [  1  18]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.54      0.68       206
        1.0       0.27      0.77      0.40        44

avg / total       0.80      0.58      0.63       250

[[112  94]
 [ 10  34]]
sbMIL(C=32768.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.46      0.63       239
        1.0       0.08      1.00      0.14        11

avg / total       0.96      0.48      0.61       250

[[109 130]
 [  0  11]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.71      0.82       231
        1.0       0.16      0.68      0.26        19

avg / total       0.90      0.71      0.78       250

[[164  67]
 [  6  13]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.58      0.72       221
        1.0       0.19      0.72      0.30        29

avg / total       0.85      0.60      0.67       250

[[129  92]
 [  8  21]]
sbMIL(C=512.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.56      0.72       239
        1.0       0.09      0.91      0.16        11

avg / total       0.95      0.58      0.69       250

[[134 105]
 [  1  10]]
sbMIL(C=128.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.33      0.49       206
        1.0       0.21      0.82      0.33        44

avg / total       0.78      0.42      0.46       250

[[ 69 137]
 [  8  36]]
sbMIL(C=128.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.72      0.84       246
        1.0       0.06      1.00      0.11         4

avg / total       0.98      0.73      0.83       250

[[178  68]
 [  0   4]]
sbMIL(C=128.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.53      0.68       221
        1.0       0.19      0.83      0.31        29

avg / total       0.87      0.56      0.64       250

[[117 104]
 [  5  24]]
sbMIL(C=128.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.45      0.62       231
        1.0       0.12      0.89      0.21        19

avg / total       0.92      0.48      0.59       250

[[104 127]
 [  2  17]]
sbMIL(C=128.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.43      0.60       239
        1.0       0.07      1.00      0.14        11

avg / total       0.96      0.46      0.58       250

[[103 136]
 [  0  11]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.86      0.91       250

[[215  31]
 [  4   0]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.91      0.95       246
        1.0       0.08      0.50      0.14         4

avg / total       0.98      0.90      0.93       250

[[223  23]
 [  2   2]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.79      0.86       231
        1.0       0.16      0.47      0.23        19

avg / total       0.89      0.76      0.81       250

[[182  49]
 [ 10   9]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.81      0.84       206
        1.0       0.32      0.43      0.37        44

avg / total       0.77      0.74      0.75       250

[[166  40]
 [ 25  19]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.82      0.89       239
        1.0       0.11      0.45      0.17        11

avg / total       0.93      0.81      0.86       250

[[197  42]
 [  6   5]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.70      0.80       221
        1.0       0.20      0.59      0.30        29

avg / total       0.84      0.69      0.74       250

[[155  66]
 [ 12  17]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.73      0.79       206
        1.0       0.26      0.43      0.32        44

avg / total       0.75      0.68      0.71       250

[[151  55]
 [ 25  19]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.87      0.90       231
        1.0       0.17      0.32      0.22        19

avg / total       0.88      0.83      0.85       250

[[201  30]
 [ 13   6]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.73      0.82       221
        1.0       0.22      0.59      0.32        29

avg / total       0.85      0.72      0.76       250

[[162  59]
 [ 12  17]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.77      0.86       239
        1.0       0.10      0.55      0.17        11

avg / total       0.94      0.76      0.83       250

[[184  55]
 [  5   6]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.97      0.98       246
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       250

[[239   7]
 [  4   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.94      0.94       231
        1.0       0.24      0.21      0.22        19

avg / total       0.88      0.89      0.89       250

[[218  13]
 [ 15   4]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.95      0.89       206
        1.0       0.41      0.16      0.23        44

avg / total       0.77      0.81      0.78       250

[[196  10]
 [ 37   7]]
sbMIL(C=256.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.84      0.91       246
        1.0       0.07      0.75      0.13         4

avg / total       0.98      0.84      0.90       250

[[206  40]
 [  1   3]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.95      0.95       239
        1.0       0.08      0.09      0.08        11

avg / total       0.92      0.91      0.92       250

[[227  12]
 [ 10   1]]
sbMIL(C=256.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.64      0.74       206
        1.0       0.27      0.61      0.37        44

avg / total       0.78      0.64      0.68       250

[[132  74]
 [ 17  27]]
sbMIL(C=32768.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.86      0.88       221
        1.0       0.18      0.24      0.21        29

avg / total       0.81      0.78      0.80       250

[[189  32]
 [ 22   7]]
sbMIL(C=256.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.79      0.86       231
        1.0       0.14      0.42      0.21        19

avg / total       0.88      0.76      0.81       250

[[183  48]
 [ 11   8]]
sbMIL(C=256.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.65      0.77       221
        1.0       0.20      0.69      0.31        29

avg / total       0.86      0.65      0.71       250

[[143  78]
 [  9  20]]
sbMIL(C=256.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.65      0.78       239
        1.0       0.09      0.73      0.16        11

avg / total       0.94      0.66      0.76       250

[[156  83]
 [  3   8]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.69      0.76       206
        1.0       0.21      0.39      0.27        44

avg / total       0.73      0.64      0.67       250

[[142  64]
 [ 27  17]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.92      0.96       246
        1.0       0.10      0.50      0.16         4

avg / total       0.98      0.92      0.94       250

[[227  19]
 [  2   2]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.87      0.90       231
        1.0       0.14      0.26      0.19        19

avg / total       0.87      0.82      0.85       250

[[201  30]
 [ 14   5]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.76      0.83       221
        1.0       0.19      0.45      0.27        29

avg / total       0.83      0.72      0.76       250

[[167  54]
 [ 16  13]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.76      0.85       239
        1.0       0.05      0.27      0.08        11

avg / total       0.92      0.74      0.81       250

[[181  58]
 [  8   3]]
Best parameters set found on development set:

{'C': 512.0, 'eta': 0.625}

Grid scores on development set:

0.215 (+/-0.155) for {'C': 65536.0, 'eta': 0.75}
0.226 (+/-0.157) for {'C': 32.0, 'eta': 0.75}
0.219 (+/-0.170) for {'C': 32768.0, 'eta': 0.75}
0.246 (+/-0.198) for {'C': 512.0, 'eta': 0.625}
0.218 (+/-0.178) for {'C': 128.0, 'eta': 0.875}
0.216 (+/-0.253) for {'C': 65536.0, 'eta': 0.375}
0.234 (+/-0.154) for {'C': 128.0, 'eta': 0.375}
0.148 (+/-0.182) for {'C': 32768.0, 'eta': 0.125}
0.237 (+/-0.186) for {'C': 256.0, 'eta': 0.5}
0.194 (+/-0.143) for {'C': 32.0, 'eta': 0.375}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.98      0.38      0.55       676
        1.0       0.21      0.96      0.34       114

avg / total       0.87      0.46      0.52       790


Time elapsed: 7515.37 seconds.
Confusion matrix on the test data:
[[257 419]
 [  5 109]]
Precision on the test data: 20.64%
Recall on the test data: 95.61%
F1 Score on the test data: 33.96%

Saving results to eval8/res/lopo_p0_m250_b100_i2.pickle ...
