
---------------------------------------------------------




Number of bags : 51    Number of single instances: 625

2016-04-28 16:23:57




---------------------------------------------------------

sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       114
        1.0       0.09      1.00      0.16        11

avg / total       0.01      0.09      0.01       125

[[  0 114]
 [  0  11]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       123
        1.0       0.02      1.00      0.03         2

avg / total       0.00      0.02      0.00       125

[[  0 123]
 [  0   2]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       116
        1.0       0.07      1.00      0.13         9

avg / total       0.01      0.07      0.01       125

[[  0 116]
 [  0   9]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       113
        1.0       0.10      1.00      0.18        12

avg / total       0.01      0.10      0.02       125

[[  0 113]
 [  0  12]]
sbMIL(C=512.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       111
        1.0       0.11      1.00      0.20        14

avg / total       0.01      0.11      0.02       125

[[  0 111]
 [  0  14]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.60      0.75       123
        1.0       0.04      1.00      0.08         2

avg / total       0.98      0.61      0.74       125

[[74 49]
 [ 0  2]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.23      0.37       114
        1.0       0.10      0.91      0.18        11

avg / total       0.89      0.29      0.35       125

[[26 88]
 [ 1 10]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.41      0.58       113
        1.0       0.15      1.00      0.26        12

avg / total       0.92      0.46      0.55       125

[[46 67]
 [ 0 12]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.22      0.37       116
        1.0       0.09      1.00      0.17         9

avg / total       0.93      0.28      0.35       125

[[26 90]
 [ 0  9]]
sbMIL(C=512.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.26      0.41       111
        1.0       0.12      0.79      0.21        14

avg / total       0.82      0.32      0.38       125

[[29 82]
 [ 3 11]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       123
        1.0       0.02      1.00      0.03         2

avg / total       0.00      0.02      0.00       125

[[  0 123]
 [  0   2]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.83      0.90       123
        1.0       0.00      0.00      0.00         2

avg / total       0.97      0.82      0.88       125

[[102  21]
 [  2   0]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       116
        1.0       0.07      1.00      0.13         9

avg / total       0.01      0.07      0.01       125

[[  0 116]
 [  0   9]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       111
        1.0       0.11      1.00      0.20        14

avg / total       0.01      0.11      0.02       125

[[  0 111]
 [  0  14]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.68      0.78       111
        1.0       0.17      0.50      0.25        14

avg / total       0.83      0.66      0.72       125

[[76 35]
 [ 7  7]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       114
        1.0       0.09      1.00      0.16        11

avg / total       0.01      0.09      0.01       125

[[  0 114]
 [  0  11]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       113
        1.0       0.10      1.00      0.18        12

avg / total       0.01      0.10      0.02       125

[[  0 113]
 [  0  12]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.77      0.84       113
        1.0       0.19      0.50      0.27        12

avg / total       0.86      0.74      0.79       125

[[87 26]
 [ 6  6]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.61      0.73       114
        1.0       0.12      0.55      0.19        11

avg / total       0.86      0.60      0.69       125

[[69 45]
 [ 5  6]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.65      0.77       116
        1.0       0.09      0.44      0.15         9

avg / total       0.88      0.63      0.72       125

[[75 41]
 [ 5  4]]
sbMIL(C=65536.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.73      0.84       123
        1.0       0.03      0.50      0.06         2

avg / total       0.97      0.73      0.83       125

[[90 33]
 [ 1  1]]
sbMIL(C=65536.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.44      0.59       111
        1.0       0.13      0.64      0.21        14

avg / total       0.82      0.46      0.55       125

[[49 62]
 [ 5  9]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.69      0.81       123
        1.0       0.03      0.50      0.05         2

avg / total       0.97      0.69      0.80       125

[[85 38]
 [ 1  1]]
sbMIL(C=65536.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.36      0.53       116
        1.0       0.11      1.00      0.20         9

avg / total       0.94      0.41      0.51       125

[[42 74]
 [ 0  9]]
sbMIL(C=65536.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.35      0.51       114
        1.0       0.11      0.82      0.19        11

avg / total       0.88      0.39      0.48       125

[[40 74]
 [ 2  9]]
sbMIL(C=65536.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.58      0.73       113
        1.0       0.19      0.92      0.31        12

avg / total       0.91      0.62      0.69       125

[[66 47]
 [ 1 11]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.41      0.57       111
        1.0       0.13      0.71      0.22        14

avg / total       0.83      0.45      0.53       125

[[46 65]
 [ 4 10]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.35      0.52       116
        1.0       0.11      1.00      0.19         9

avg / total       0.94      0.40      0.50       125

[[41 75]
 [ 0  9]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.33      0.49       114
        1.0       0.10      0.73      0.17        11

avg / total       0.85      0.37      0.46       125

[[38 76]
 [ 3  8]]
sbMIL(C=4096.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.56      0.71       113
        1.0       0.18      0.92      0.30        12

avg / total       0.91      0.59      0.67       125

[[63 50]
 [ 1 11]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.43      0.60       123
        1.0       0.03      1.00      0.05         2

avg / total       0.98      0.44      0.59       125

[[53 70]
 [ 0  2]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.10      0.18       111
        1.0       0.12      0.93      0.20        14

avg / total       0.83      0.19      0.18       125

[[ 11 100]
 [  1  13]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.13      0.23       116
        1.0       0.08      1.00      0.15         9

avg / total       0.93      0.19      0.22       125

[[ 15 101]
 [  0   9]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.25       114
        1.0       0.10      1.00      0.18        11

avg / total       0.92      0.22      0.24       125

[[16 98]
 [ 0 11]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.59      0.74       123
        1.0       0.02      0.50      0.04         2

avg / total       0.97      0.59      0.73       125

[[73 50]
 [ 1  1]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.21      0.35       113
        1.0       0.12      1.00      0.21        12

avg / total       0.92      0.29      0.34       125

[[24 89]
 [ 0 12]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.26      0.41       111
        1.0       0.13      0.86      0.22        14

avg / total       0.85      0.33      0.39       125

[[29 82]
 [ 2 12]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.21      0.34       116
        1.0       0.09      1.00      0.16         9

avg / total       0.93      0.26      0.33       125

[[24 92]
 [ 0  9]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.22      0.36       114
        1.0       0.10      0.91      0.18        11

avg / total       0.89      0.28      0.34       125

[[25 89]
 [ 1 10]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.44      0.61       113
        1.0       0.16      1.00      0.28        12

avg / total       0.92      0.50      0.58       125

[[50 63]
 [ 0 12]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.93      0.95       123
        1.0       0.00      0.00      0.00         2

avg / total       0.97      0.91      0.94       125

[[114   9]
 [  2   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.84      0.86       111
        1.0       0.10      0.14      0.12        14

avg / total       0.80      0.76      0.78       125

[[93 18]
 [12  2]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.78      0.85       116
        1.0       0.07      0.22      0.11         9

avg / total       0.87      0.74      0.80       125

[[91 25]
 [ 7  2]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.79      0.85       114
        1.0       0.14      0.36      0.21        11

avg / total       0.86      0.75      0.80       125

[[90 24]
 [ 7  4]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.65      0.78       123
        1.0       0.02      0.50      0.04         2

avg / total       0.97      0.65      0.77       125

[[80 43]
 [ 1  1]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.88      0.89       113
        1.0       0.00      0.00      0.00        12

avg / total       0.81      0.80      0.80       125

[[100  13]
 [ 12   0]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.32      0.48       111
        1.0       0.13      0.79      0.22        14

avg / total       0.83      0.38      0.45       125

[[36 75]
 [ 3 11]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.33      0.49       116
        1.0       0.09      0.89      0.17         9

avg / total       0.91      0.37      0.47       125

[[38 78]
 [ 1  8]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.33      0.49       114
        1.0       0.10      0.73      0.17        11

avg / total       0.85      0.37      0.46       125

[[38 76]
 [ 3  8]]
sbMIL(C=128.0, class_weight=None, eta=0.625, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.50      0.67       113
        1.0       0.16      0.92      0.28        12

avg / total       0.90      0.54      0.63       125

[[57 56]
 [ 1 11]]
Best parameters set found on development set:

{'C': 65536.0, 'eta': 0.625}

Grid scores on development set:

0.141 (+/-0.118) for {'C': 512.0, 'eta': 1.0}
0.179 (+/-0.123) for {'C': 512.0, 'eta': 0.75}
0.173 (+/-0.194) for {'C': 65536.0, 'eta': 0.375}
0.141 (+/-0.118) for {'C': 4096.0, 'eta': 1.0}
0.194 (+/-0.165) for {'C': 65536.0, 'eta': 0.625}
0.187 (+/-0.165) for {'C': 4096.0, 'eta': 0.625}
0.161 (+/-0.115) for {'C': 32.0, 'eta': 0.875}
0.176 (+/-0.159) for {'C': 2048.0, 'eta': 0.75}
0.087 (+/-0.156) for {'C': 64.0, 'eta': 0.25}
0.176 (+/-0.155) for {'C': 128.0, 'eta': 0.625}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       1.00      0.21      0.35       676
        1.0       0.18      1.00      0.30       114

avg / total       0.88      0.33      0.35       790


Time elapsed: 4520.07 seconds.
Confusion matrix on the test data:
[[145 531]
 [  0 114]]
Precision on the test data: 17.67%
Recall on the test data: 100.00%
F1 Score on the test data: 30.04%

Saving results to eval8/res/lopo_p0_m125_b200_i0.pickle ...
