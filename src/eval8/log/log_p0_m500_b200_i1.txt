
---------------------------------------------------------




Number of bags : 51    Number of single instances: 2499

2016-04-29 11:15:57




---------------------------------------------------------

sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.50      0.66       484
        1.0       0.05      0.75      0.09        16

avg / total       0.95      0.50      0.64       500

[[240 244]
 [  4  12]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.17      0.29       422
        1.0       0.18      0.97      0.30        78

avg / total       0.85      0.29      0.29       500

[[ 71 351]
 [  2  76]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.14      0.24       458
        1.0       0.10      1.00      0.17        42

avg / total       0.92      0.21      0.23       500

[[ 62 396]
 [  0  42]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.16      0.27       446
        1.0       0.13      1.00      0.22        54

avg / total       0.91      0.25      0.27       500

[[ 70 376]
 [  0  54]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.23      0.37       468
        1.0       0.08      1.00      0.15        31

avg / total       0.94      0.27      0.36       499

[[106 362]
 [  0  31]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.92       484
        1.0       0.09      0.38      0.15        16

avg / total       0.95      0.86      0.90       500

[[424  60]
 [ 10   6]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.68      0.76       422
        1.0       0.19      0.41      0.26        78

avg / total       0.76      0.64      0.68       500

[[287 135]
 [ 46  32]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.82      0.88       458
        1.0       0.22      0.55      0.32        42

avg / total       0.89      0.80      0.84       500

[[377  81]
 [ 19  23]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.68      0.79       446
        1.0       0.20      0.67      0.31        54

avg / total       0.86      0.68      0.74       500

[[305 141]
 [ 18  36]]
sbMIL(C=128.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.75      0.83       468
        1.0       0.08      0.32      0.12        31

avg / total       0.89      0.72      0.79       499

[[349 119]
 [ 21  10]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       484
        1.0       0.03      1.00      0.06        16

avg / total       0.00      0.03      0.00       500

[[  0 484]
 [  0  16]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       422
        1.0       0.16      1.00      0.27        78

avg / total       0.02      0.16      0.04       500

[[  0 422]
 [  0  78]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       458
        1.0       0.08      1.00      0.15        42

avg / total       0.01      0.08      0.01       500

[[  0 458]
 [  0  42]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       446
        1.0       0.11      1.00      0.19        54

avg / total       0.01      0.11      0.02       500

[[  0 446]
 [  0  54]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.00      0.00      0.00       468
        1.0       0.06      1.00      0.12        31

avg / total       0.00      0.06      0.01       499

[[  0 468]
 [  0  31]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.46      0.63       484
        1.0       0.05      0.81      0.09        16

avg / total       0.96      0.47      0.61       500

[[223 261]
 [  3  13]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.14      0.25       422
        1.0       0.17      0.97      0.30        78

avg / total       0.84      0.27      0.26       500

[[ 61 361]
 [  2  76]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.13      0.24       458
        1.0       0.10      1.00      0.17        42

avg / total       0.92      0.21      0.23       500

[[ 61 397]
 [  0  42]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.15      0.26       446
        1.0       0.12      1.00      0.22        54

avg / total       0.91      0.24      0.26       500

[[ 67 379]
 [  0  54]]
sbMIL(C=4096.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.18      0.30       468
        1.0       0.07      1.00      0.14        31

avg / total       0.94      0.23      0.29       499

[[ 83 385]
 [  0  31]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.75      0.85       484
        1.0       0.09      0.75      0.16        16

avg / total       0.96      0.75      0.83       500

[[363 121]
 [  4  12]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.35      0.50       422
        1.0       0.19      0.85      0.31        78

avg / total       0.81      0.42      0.47       500

[[146 276]
 [ 12  66]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.35      0.52       458
        1.0       0.12      0.95      0.21        42

avg / total       0.91      0.40      0.49       500

[[161 297]
 [  2  40]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.28      0.43       446
        1.0       0.14      0.96      0.24        54

avg / total       0.89      0.35      0.41       500

[[124 322]
 [  2  52]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.43      0.61       468
        1.0       0.10      1.00      0.19        31

avg / total       0.94      0.47      0.58       499

[[203 265]
 [  0  31]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.45      0.62       484
        1.0       0.05      0.81      0.09        16

avg / total       0.96      0.46      0.60       500

[[219 265]
 [  3  13]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.10      0.19       422
        1.0       0.17      1.00      0.29        78

avg / total       0.87      0.24      0.20       500

[[ 44 378]
 [  0  78]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.13      0.24       458
        1.0       0.10      1.00      0.17        42

avg / total       0.92      0.21      0.23       500

[[ 61 397]
 [  0  42]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.16      0.27       446
        1.0       0.13      1.00      0.22        54

avg / total       0.91      0.25      0.27       500

[[ 70 376]
 [  0  54]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.18      0.30       468
        1.0       0.07      1.00      0.14        31

avg / total       0.94      0.23      0.29       499

[[ 83 385]
 [  0  31]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.91      0.94       484
        1.0       0.07      0.19      0.10        16

avg / total       0.94      0.89      0.91       500

[[441  43]
 [ 13   3]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.84      0.84       422
        1.0       0.19      0.21      0.20        78

avg / total       0.75      0.74      0.74       500

[[354  68]
 [ 62  16]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.88      0.91       458
        1.0       0.26      0.48      0.34        42

avg / total       0.89      0.84      0.86       500

[[401  57]
 [ 22  20]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.75      0.84       446
        1.0       0.23      0.63      0.34        54

avg / total       0.87      0.74      0.78       500

[[335 111]
 [ 20  34]]
sbMIL(C=16384.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.87      0.91       468
        1.0       0.13      0.29      0.18        31

avg / total       0.90      0.84      0.86       499

[[409  59]
 [ 22   9]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.99      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.96      0.95       500

[[479   5]
 [ 16   0]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.96      0.90       422
        1.0       0.16      0.04      0.06        78

avg / total       0.74      0.82      0.77       500

[[406  16]
 [ 75   3]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.96      0.94       458
        1.0       0.28      0.17      0.21        42

avg / total       0.87      0.89      0.88       500

[[440  18]
 [ 35   7]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.91      0.91       446
        1.0       0.19      0.17      0.18        54

avg / total       0.82      0.83      0.83       500

[[408  38]
 [ 45   9]]
sbMIL(C=256.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.96       468
        1.0       0.20      0.03      0.06        31

avg / total       0.89      0.93      0.91       499

[[464   4]
 [ 30   1]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.86      0.92       484
        1.0       0.10      0.44      0.16        16

avg / total       0.95      0.85      0.89       500

[[418  66]
 [  9   7]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.69      0.77       422
        1.0       0.21      0.46      0.29        78

avg / total       0.77      0.65      0.69       500

[[290 132]
 [ 42  36]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.76      0.85       458
        1.0       0.19      0.62      0.29        42

avg / total       0.89      0.75      0.80       500

[[347 111]
 [ 16  26]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.66      0.79       446
        1.0       0.23      0.85      0.37        54

avg / total       0.89      0.68      0.74       500

[[295 151]
 [  8  46]]
sbMIL(C=1024.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.78      0.86       468
        1.0       0.13      0.52      0.21        31

avg / total       0.91      0.76      0.82       499

[[364 104]
 [ 15  16]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.88      0.93       484
        1.0       0.12      0.50      0.19        16

avg / total       0.95      0.86      0.90       500

[[424  60]
 [  8   8]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.64      0.73       422
        1.0       0.16      0.36      0.22        78

avg / total       0.74      0.60      0.65       500

[[270 152]
 [ 50  28]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.84      0.89       458
        1.0       0.22      0.48      0.30        42

avg / total       0.88      0.81      0.84       500

[[386  72]
 [ 22  20]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.74      0.82       446
        1.0       0.21      0.57      0.31        54

avg / total       0.86      0.72      0.77       500

[[328 118]
 [ 23  31]]
sbMIL(C=32.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.76      0.84       468
        1.0       0.07      0.29      0.12        31

avg / total       0.89      0.73      0.80       499

[[357 111]
 [ 22   9]]
Best parameters set found on development set:

{'C': 1024.0, 'eta': 0.375}

Grid scores on development set:

0.187 (+/-0.144) for {'C': 1024.0, 'eta': 0.875}
0.232 (+/-0.162) for {'C': 128.0, 'eta': 0.375}
0.160 (+/-0.141) for {'C': 4096.0, 'eta': 1.0}
0.184 (+/-0.141) for {'C': 4096.0, 'eta': 0.875}
0.224 (+/-0.105) for {'C': 2048.0, 'eta': 0.75}
0.183 (+/-0.140) for {'C': 16384.0, 'eta': 0.875}
0.231 (+/-0.189) for {'C': 16384.0, 'eta': 0.25}
0.101 (+/-0.159) for {'C': 256.0, 'eta': 0.125}
0.264 (+/-0.145) for {'C': 1024.0, 'eta': 0.375}
0.226 (+/-0.139) for {'C': 32.0, 'eta': 0.375}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.93      0.55      0.69       676
        1.0       0.22      0.77      0.35       114

avg / total       0.83      0.58      0.64       790


Time elapsed: 49010.02 seconds.
Confusion matrix on the test data:
[[371 305]
 [ 26  88]]
Precision on the test data: 22.39%
Recall on the test data: 77.19%
F1 Score on the test data: 34.71%

Saving results to eval8/res/lopo_p0_m500_b200_i1.pickle ...
