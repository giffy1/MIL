
---------------------------------------------------------




Number of bags : 181    Number of single instances: 625

2016-04-28 14:28:03




---------------------------------------------------------

sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.80      0.89       123
        1.0       0.04      0.50      0.07         2

avg / total       0.97      0.80      0.87       125

[[99 24]
 [ 1  1]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.97      0.94       113
        1.0       0.25      0.08      0.12        12

avg / total       0.85      0.89      0.86       125

[[110   3]
 [ 11   1]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.95      0.97       123
        1.0       0.00      0.00      0.00         2

avg / total       0.97      0.94      0.95       125

[[117   6]
 [  2   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.78      0.85       114
        1.0       0.17      0.45      0.24        11

avg / total       0.87      0.75      0.80       125

[[89 25]
 [ 6  5]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.94      0.94       116
        1.0       0.30      0.33      0.32         9

avg / total       0.90      0.90      0.90       125

[[109   7]
 [  6   3]]
sbMIL(C=2048.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.90      0.89       111
        1.0       0.08      0.07      0.08        14

avg / total       0.80      0.81      0.80       125

[[100  11]
 [ 13   1]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.84      0.29      0.43       111
        1.0       0.09      0.57      0.16        14

avg / total       0.76      0.32      0.40       125

[[32 79]
 [ 6  8]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.49      0.62       111
        1.0       0.10      0.43      0.16        14

avg / total       0.78      0.48      0.57       125

[[54 57]
 [ 8  6]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.76      0.87       123
        1.0       0.06      1.00      0.12         2

avg / total       0.99      0.77      0.85       125

[[94 29]
 [ 0  2]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.83      0.89       116
        1.0       0.23      0.67      0.34         9

avg / total       0.92      0.82      0.85       125

[[96 20]
 [ 3  6]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.55      0.70       114
        1.0       0.14      0.73      0.23        11

avg / total       0.88      0.57      0.66       125

[[63 51]
 [ 3  8]]
sbMIL(C=4096.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.73      0.83       113
        1.0       0.23      0.75      0.35        12

avg / total       0.89      0.74      0.79       125

[[83 30]
 [ 3  9]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.63      0.77       116
        1.0       0.16      0.89      0.27         9

avg / total       0.93      0.65      0.73       125

[[73 43]
 [ 1  8]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.51      0.67       114
        1.0       0.15      0.91      0.26        11

avg / total       0.91      0.54      0.63       125

[[58 56]
 [ 1 10]]
sbMIL(C=32.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.68      0.80       113
        1.0       0.20      0.75      0.32        12

avg / total       0.89      0.69      0.75       125

[[77 36]
 [ 3  9]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.80      0.89       123
        1.0       0.07      1.00      0.14         2

avg / total       0.99      0.80      0.87       125

[[98 25]
 [ 0  2]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.66      0.79       116
        1.0       0.15      0.78      0.25         9

avg / total       0.92      0.67      0.75       125

[[77 39]
 [ 2  7]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.39      0.54       111
        1.0       0.12      0.64      0.20        14

avg / total       0.81      0.42      0.50       125

[[43 68]
 [ 5  9]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.66      0.79       113
        1.0       0.22      0.92      0.36        12

avg / total       0.91      0.69      0.75       125

[[75 38]
 [ 1 11]]
sbMIL(C=2048.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.50      0.66       114
        1.0       0.15      0.91      0.26        11

avg / total       0.91      0.54      0.63       125

[[57 57]
 [ 1 10]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.85      0.91       123
        1.0       0.00      0.00      0.00         2

avg / total       0.97      0.84      0.90       125

[[105  18]
 [  2   0]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.91      0.93       116
        1.0       0.29      0.44      0.35         9

avg / total       0.91      0.88      0.89       125

[[106  10]
 [  5   4]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.71      0.79       111
        1.0       0.09      0.21      0.12        14

avg / total       0.79      0.66      0.71       125

[[79 32]
 [11  3]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.68      0.79       114
        1.0       0.16      0.64      0.25        11

avg / total       0.88      0.67      0.74       125

[[77 37]
 [ 4  7]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.80      0.89       123
        1.0       0.08      1.00      0.14         2

avg / total       0.99      0.81      0.88       125

[[99 24]
 [ 0  2]]
sbMIL(C=2048.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.87      0.89       113
        1.0       0.17      0.25      0.20        12

avg / total       0.84      0.81      0.82       125

[[98 15]
 [ 9  3]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.88      0.38      0.53       111
        1.0       0.10      0.57      0.18        14

avg / total       0.79      0.40      0.49       125

[[42 69]
 [ 6  8]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.50      0.66       114
        1.0       0.15      0.91      0.26        11

avg / total       0.91      0.54      0.63       125

[[57 57]
 [ 1 10]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.66      0.78       116
        1.0       0.13      0.67      0.22         9

avg / total       0.90      0.66      0.74       125

[[76 40]
 [ 3  6]]
sbMIL(C=4096.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.66      0.80       113
        1.0       0.24      1.00      0.39        12

avg / total       0.93      0.70      0.76       125

[[75 38]
 [ 0 12]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       1.00      0.78      0.88       123
        1.0       0.07      1.00      0.13         2

avg / total       0.99      0.78      0.86       125

[[96 27]
 [ 0  2]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      1.00      0.99       123
        1.0       0.00      0.00      0.00         2

avg / total       0.97      0.98      0.98       125

[[123   0]
 [  2   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      1.00      0.96       116
        1.0       0.00      0.00      0.00         9

avg / total       0.86      0.93      0.89       125

[[116   0]
 [  9   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      1.00      0.95       114
        1.0       0.00      0.00      0.00        11

avg / total       0.83      0.91      0.87       125

[[114   0]
 [ 11   0]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      1.00      0.95       113
        1.0       0.00      0.00      0.00        12

avg / total       0.82      0.90      0.86       125

[[113   0]
 [ 12   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.90      0.34      0.50       111
        1.0       0.12      0.71      0.21        14

avg / total       0.82      0.38      0.46       125

[[38 73]
 [ 4 10]]
sbMIL(C=64.0, class_weight=None, eta=0.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       111
        1.0       0.00      0.00      0.00        14

avg / total       0.79      0.89      0.84       125

[[111   0]
 [ 14   0]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.46      0.63       114
        1.0       0.14      0.91      0.24        11

avg / total       0.91      0.50      0.60       125

[[53 61]
 [ 1 10]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.57      0.72       116
        1.0       0.12      0.78      0.21         9

avg / total       0.91      0.58      0.68       125

[[66 50]
 [ 2  7]]
sbMIL(C=32768.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.64      0.77       113
        1.0       0.21      0.92      0.34        12

avg / total       0.91      0.66      0.73       125

[[72 41]
 [ 1 11]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       123
        1.0       0.00      0.00      0.00         2

avg / total       0.97      0.86      0.91       125

[[107  16]
 [  2   0]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.92      0.90       111
        1.0       0.10      0.07      0.08        14

avg / total       0.80      0.82      0.81       125

[[102   9]
 [ 13   1]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.80      0.89       123
        1.0       0.04      0.50      0.07         2

avg / total       0.97      0.80      0.87       125

[[99 24]
 [ 1  1]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.92      0.94       116
        1.0       0.31      0.44      0.36         9

avg / total       0.91      0.89      0.90       125

[[107   9]
 [  5   4]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      0.92      0.92       113
        1.0       0.25      0.25      0.25        12

avg / total       0.86      0.86      0.86       125

[[104   9]
 [  9   3]]
sbMIL(C=65536.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.77      0.85       114
        1.0       0.16      0.45      0.24        11

avg / total       0.87      0.74      0.79       125

[[88 26]
 [ 6  5]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.49      0.62       111
        1.0       0.10      0.43      0.16        14

avg / total       0.78      0.48      0.57       125

[[54 57]
 [ 8  6]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.83      0.89       116
        1.0       0.23      0.67      0.34         9

avg / total       0.92      0.82      0.85       125

[[96 20]
 [ 3  6]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.55      0.70       114
        1.0       0.14      0.73      0.23        11

avg / total       0.88      0.57      0.66       125

[[63 51]
 [ 3  8]]
sbMIL(C=2048.0, class_weight=None, eta=0.75, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.73      0.83       113
        1.0       0.23      0.75      0.35        12

avg / total       0.89      0.74      0.79       125

[[83 30]
 [ 3  9]]
Best parameters set found on development set:

{'C': 2048.0, 'eta': 0.875}

Grid scores on development set:

0.152 (+/-0.228) for {'C': 2048.0, 'eta': 0.25}
0.231 (+/-0.215) for {'C': 4096.0, 'eta': 0.75}
0.224 (+/-0.145) for {'C': 32.0, 'eta': 0.875}
0.241 (+/-0.148) for {'C': 2048.0, 'eta': 0.875}
0.185 (+/-0.236) for {'C': 2048.0, 'eta': 0.5}
0.236 (+/-0.169) for {'C': 4096.0, 'eta': 1.0}
0.000 (+/-0.000) for {'C': 64.0, 'eta': 0.0}
0.227 (+/-0.139) for {'C': 32768.0, 'eta': 0.875}
0.187 (+/-0.258) for {'C': 65536.0, 'eta': 0.25}
0.231 (+/-0.215) for {'C': 2048.0, 'eta': 0.75}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.99      0.33      0.50       676
        1.0       0.20      0.98      0.33       114

avg / total       0.88      0.43      0.48       790


Time elapsed: 7945.27 seconds.
Confusion matrix on the test data:
[[226 450]
 [  2 112]]
Precision on the test data: 19.93%
Recall on the test data: 98.25%
F1 Score on the test data: 33.14%

Saving results to eval8/res/lopo_p0_m125_b50_i0.pickle ...
