
---------------------------------------------------------




Number of bags : 877    Number of single instances: 2499

2016-04-29 00:37:27




---------------------------------------------------------

sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.99      0.81      0.89       484
        1.0       0.11      0.69      0.19        16

avg / total       0.96      0.81      0.87       500

[[393  91]
 [  5  11]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.95      0.96       484
        1.0       0.17      0.31      0.22        16

avg / total       0.95      0.93      0.94       500

[[459  25]
 [ 11   5]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.97      0.96       468
        1.0       0.27      0.19      0.23        31

avg / total       0.91      0.92      0.91       499

[[452  16]
 [ 25   6]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.94      0.90       422
        1.0       0.42      0.24      0.31        78

avg / total       0.80      0.83      0.81       500

[[396  26]
 [ 59  19]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.92      0.93       458
        1.0       0.28      0.33      0.30        42

avg / total       0.88      0.87      0.88       500

[[422  36]
 [ 28  14]]
sbMIL(C=65536.0, class_weight=None, eta=0.375, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.74      0.84       446
        1.0       0.26      0.74      0.38        54

avg / total       0.88      0.74      0.79       500

[[330 116]
 [ 14  40]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.87      0.92       484
        1.0       0.11      0.50      0.19        16

avg / total       0.95      0.86      0.90       500

[[422  62]
 [  8   8]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.64      0.73       422
        1.0       0.19      0.45      0.26        78

avg / total       0.76      0.61      0.66       500

[[270 152]
 [ 43  35]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.86      0.54      0.66       422
        1.0       0.17      0.51      0.26        78

avg / total       0.75      0.54      0.60       500

[[228 194]
 [ 38  40]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.79      0.86       458
        1.0       0.20      0.57      0.29        42

avg / total       0.89      0.77      0.81       500

[[361  97]
 [ 18  24]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.63      0.76       468
        1.0       0.12      0.74      0.20        31

avg / total       0.92      0.64      0.73       499

[[294 174]
 [  8  23]]
sbMIL(C=32768.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.58      0.73       446
        1.0       0.20      0.87      0.33        54

avg / total       0.89      0.61      0.68       500

[[259 187]
 [  7  47]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.66      0.78       446
        1.0       0.21      0.74      0.33        54

avg / total       0.87      0.67      0.73       500

[[294 152]
 [ 14  40]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.86      0.89       458
        1.0       0.20      0.38      0.26        42

avg / total       0.88      0.82      0.84       500

[[392  66]
 [ 26  16]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       484
        1.0       0.13      0.50      0.21        16

avg / total       0.95      0.88      0.91       500

[[430  54]
 [  8   8]]
sbMIL(C=128.0, class_weight=None, eta=1.0, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.74      0.83       468
        1.0       0.10      0.42      0.16        31

avg / total       0.90      0.72      0.79       499

[[346 122]
 [ 18  13]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.70      0.77       422
        1.0       0.21      0.45      0.29        78

avg / total       0.77      0.66      0.70       500

[[294 128]
 [ 43  35]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.87      0.91       458
        1.0       0.28      0.52      0.36        42

avg / total       0.90      0.84      0.86       500

[[400  58]
 [ 20  22]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.65      0.78       446
        1.0       0.22      0.80      0.34        54

avg / total       0.88      0.67      0.73       500

[[292 154]
 [ 11  43]]
sbMIL(C=1024.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.76      0.85       468
        1.0       0.13      0.55      0.21        31

avg / total       0.91      0.75      0.81       499

[[357 111]
 [ 14  17]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.94      0.96       484
        1.0       0.17      0.38      0.24        16

avg / total       0.95      0.92      0.94       500

[[455  29]
 [ 10   6]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.89      0.88       422
        1.0       0.30      0.26      0.28        78

avg / total       0.78      0.79      0.78       500

[[376  46]
 [ 58  20]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.89      0.91       458
        1.0       0.25      0.40      0.31        42

avg / total       0.88      0.85      0.86       500

[[407  51]
 [ 25  17]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.78      0.85       446
        1.0       0.25      0.59      0.35        54

avg / total       0.87      0.76      0.80       500

[[349  97]
 [ 22  32]]
sbMIL(C=16384.0, class_weight=None, eta=0.5, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.93      0.94       468
        1.0       0.19      0.26      0.22        31

avg / total       0.90      0.88      0.89       499

[[433  35]
 [ 23   8]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.98      0.89      0.93       484
        1.0       0.14      0.56      0.23        16

avg / total       0.96      0.88      0.91       500

[[429  55]
 [  7   9]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.87      0.53      0.66       422
        1.0       0.18      0.56      0.28        78

avg / total       0.76      0.54      0.60       500

[[225 197]
 [ 34  44]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.95      0.88      0.91       458
        1.0       0.28      0.52      0.36        42

avg / total       0.90      0.85      0.87       500

[[401  57]
 [ 20  22]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      0.65      0.78       446
        1.0       0.22      0.81      0.35        54

avg / total       0.89      0.67      0.73       500

[[291 155]
 [ 10  44]]
sbMIL(C=16384.0, class_weight=None, eta=0.875, gamma=1.0, kernel='linear',
   p=3, scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.96      0.76      0.85       468
        1.0       0.12      0.52      0.20        31

avg / total       0.91      0.74      0.81       499

[[354 114]
 [ 15  16]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[484   0]
 [ 16   0]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       422
        1.0       0.50      0.03      0.05        78

avg / total       0.79      0.84      0.78       500

[[420   2]
 [ 76   2]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       458
        1.0       0.00      0.00      0.00        42

avg / total       0.84      0.91      0.87       500

[[457   1]
 [ 42   0]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       446
        1.0       0.00      0.00      0.00        54

avg / total       0.80      0.89      0.84       500

[[446   0]
 [ 54   0]]
sbMIL(C=32.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.96      0.95       500

[[482   2]
 [ 16   0]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       422
        1.0       0.60      0.04      0.07        78

avg / total       0.81      0.85      0.78       500

[[420   2]
 [ 75   3]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.93      0.98      0.95       458
        1.0       0.45      0.21      0.29        42

avg / total       0.89      0.91      0.90       500

[[447  11]
 [ 33   9]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.91      0.97      0.94       446
        1.0       0.43      0.19      0.26        54

avg / total       0.86      0.89      0.86       500

[[433  13]
 [ 44  10]]
sbMIL(C=256.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      0.99      0.97       468
        1.0       0.43      0.10      0.16        31

avg / total       0.91      0.94      0.92       499

[[464   4]
 [ 28   3]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[484   0]
 [ 16   0]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      1.00      0.92       422
        1.0       0.50      0.01      0.03        78

avg / total       0.79      0.84      0.78       500

[[421   1]
 [ 77   1]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       458
        1.0       0.00      0.00      0.00        42

avg / total       0.84      0.91      0.87       500

[[457   1]
 [ 42   0]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      1.00      0.94       446
        1.0       0.00      0.00      0.00        54

avg / total       0.80      0.89      0.84       500

[[446   0]
 [ 54   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.97      1.00      0.98       484
        1.0       0.00      0.00      0.00        16

avg / total       0.94      0.97      0.95       500

[[484   0]
 [ 16   0]]
sbMIL(C=64.0, class_weight=None, eta=0.125, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.85      0.99      0.91       422
        1.0       0.43      0.04      0.07        78

avg / total       0.78      0.84      0.78       500

[[418   4]
 [ 75   3]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.92      1.00      0.96       458
        1.0       0.00      0.00      0.00        42

avg / total       0.84      0.91      0.87       500

[[457   1]
 [ 42   0]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.89      0.99      0.94       446
        1.0       0.40      0.04      0.07        54

avg / total       0.84      0.89      0.85       500

[[443   3]
 [ 52   2]]
sbMIL(C=64.0, class_weight=None, eta=0.25, gamma=1.0, kernel='linear', p=3,
   scale_C=True, sv_cutoff=1e-07, verbose=0)
             precision    recall  f1-score   support

       -1.0       0.94      1.00      0.97       468
        1.0       0.00      0.00      0.00        31

avg / total       0.88      0.94      0.91       499

[[468   0]
 [ 31   0]]
Best parameters set found on development set:

{'C': 65536.0, 'eta': 0.375}

Grid scores on development set:

0.288 (+/-0.120) for {'C': 65536.0, 'eta': 0.375}
0.253 (+/-0.106) for {'C': 32768.0, 'eta': 1.0}
0.238 (+/-0.120) for {'C': 128.0, 'eta': 1.0}
0.283 (+/-0.128) for {'C': 1024.0, 'eta': 0.875}
0.278 (+/-0.097) for {'C': 16384.0, 'eta': 0.5}
0.282 (+/-0.130) for {'C': 16384.0, 'eta': 0.875}
0.010 (+/-0.039) for {'C': 32.0, 'eta': 0.25}
0.156 (+/-0.219) for {'C': 256.0, 'eta': 0.25}
0.005 (+/-0.020) for {'C': 64.0, 'eta': 0.125}
0.028 (+/-0.068) for {'C': 64.0, 'eta': 0.25}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

       -1.0       0.94      0.80      0.86       676
        1.0       0.36      0.68      0.47       114

avg / total       0.85      0.78      0.80       790


Time elapsed: 21579.81 seconds.
Confusion matrix on the test data:
[[538 138]
 [ 36  78]]
Precision on the test data: 36.11%
Recall on the test data: 68.42%
F1 Score on the test data: 47.27%

Saving results to eval8/res/lopo_p0_m500_b10_i1.pickle ...
